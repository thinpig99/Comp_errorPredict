{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 팀 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 노트북은 지금까지 했던 과정을 간략히 정리한 것입니다. 참고용으로 보시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 기록\n",
    "\n",
    "1. D-6\n",
    " - 파생 변수 생성 확인\n",
    "    1. errtype을 var로 생성 : 0.83068(기각)\n",
    "    2. errtype, errcode 유니크 개수: 0.83235(기각)\n",
    "    3. errtype 유니크 개수: 0.83261(기각)\n",
    "    \n",
    "\n",
    "2. D-5\n",
    " - 파생 변수 생성 확인\n",
    "    1. err, qual의 time을 second으로 하고 std 로 groupby : 0.83490(상승)\n",
    "    2. 혜인이가 추천한 중요도 높은 errcode 추가: 0.83447(기각)\n",
    "    3. quality-groupby-sum: 0.83518(상승)\n",
    "\n",
    "3. D-4\n",
    " - 베스트 모델 확인\n",
    "    1. catb: 0.83552(상승)(2위)\n",
    "    2. gbc: 0.82778(기각)(3위)\n",
    "    3. ~~lgbm-1: 0.83239(기각)~~\n",
    "\n",
    "4. D-3\n",
    " - 베스트 모델 확인\n",
    "    1. lgbm-2: 0.83569(상승)(1위)\n",
    "    2. xtree: 0.81803(기각)(6위)\n",
    "    3. rf: 0.82260(기각)(5위)\n",
    "\n",
    "5. D-2\n",
    " - 앙상블 제출\n",
    "    1. ngb: 0.82469(기각)(4위)\n",
    "    2. 최고모델에 혜인이 변수 조정 버전: \t0.83746(상승)\n",
    "    3. best-6: \t0.83395(기각)\n",
    "\n",
    "6. D-1\n",
    " - 앙상블 제출\n",
    "    1. best-5(xtree 제외): 0.83628(기각)\n",
    "    2. best-4(xtree, rf 제외): 0.83667(기각)\n",
    "    3. best-3(xtree, rf, ngb 제외): 0.83775(상승)\n",
    "\n",
    "7. D-Day\n",
    " - 역전 재판\n",
    "    1. best-2(catb, lgbm 만 사용): 0.83645(기각)\n",
    "    2. ngb: 0.82906(기각)\n",
    "    3. 최종 best-3 앙상블(catb, lgbm, ngb): 0.83713(기각)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_dtypes as ld\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, precision_recall_curve, recall_score, precision_score\n",
    "\n",
    "from ngboost import NGBClassifier\n",
    "from ngboost.distns import k_categorical, Bernoulli\n",
    "from ngboost.scores import LogScore, CRPScore\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_P_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv'\n",
    "TRAIN_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv'\n",
    "TRAIN_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv'\n",
    "TEST_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv'\n",
    "TEST_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv'\n",
    "SUBMISSION_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = ld.load_dtypes(TRAIN_P_PATH)\n",
    "train_q = ld.load_dtypes(TRAIN_Q_PATH)\n",
    "train_e = ld.load_dtypes(TRAIN_E_PATH)\n",
    "test_q = ld.load_dtypes(TEST_Q_PATH)\n",
    "test_e = ld.load_dtypes(TEST_E_PATH)\n",
    "submission = pd.read_csv(SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5429, 2),\n",
       " (828624, 16),\n",
       " (16554663, 6),\n",
       " (747972, 16),\n",
       " (16532648, 6),\n",
       " (14999, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape, train_q.shape, train_e.shape, test_q.shape, test_e.shape, submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_problem(df, object_='binary'):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    train_problem 테이블을 받아서 target 값으로 변환\n",
    "    1. {0, 1}의 binary로 변환\n",
    "    2. {0 ~ n}의 multiclass로 변환\n",
    "    \"\"\"\n",
    "    \n",
    "    # 10001부터 24999까지의 index를 만들어줍니다.\n",
    "    user_id_idx = np.array(range(10000, 25000, 1))\n",
    "    \n",
    "    # train_new_p라는 새로운 df를 만들고 index는 위에서 만든 user_id_idx 로 지정해줍니다.\n",
    "    new_p = pd.DataFrame(index = user_id_idx)\n",
    "    new_p['target'] = 0\n",
    "    \n",
    "    if object_ == 'binary':\n",
    "        new_p.iloc[df.user_id.unique()-10000] = 1\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    elif object_ == 'multi':\n",
    "        # multi는 count()로 집계를 해줍니다.\n",
    "        new_p['target'] = df.groupby('user_id')['time'].count()\n",
    "        new_p = new_p.fillna(0)\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b_p = preprocessing_problem(train_p, 'binary')\n",
    "train_m_p = preprocessing_problem(train_p, 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_quality(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    EDA를 통해 알아낸 정보로 train_q, test_q를 정리해서 내뿜어줍니다.\n",
    "    1. qaulity_3, quality_4 를 drop 합니다.(단일 value)\n",
    "    2. qaulity_k 변수들을 정수로 encoding 합니다.\n",
    "    \"\"\"\n",
    "    # 먼저 3, 4번을 drop 합니다.\n",
    "    df.drop(['quality_3', 'quality_4'], axis=1, inplace=True)\n",
    "    \n",
    "    # qual 변수만 할당해주고, 정수로 형변환 해줍니다.\n",
    "    columns = train_q.columns[train_q.columns.str.contains('quality')]\n",
    "    # for문을 통해 각 column을 반복 작업해줍니다.\n",
    "    for col in columns:\n",
    "        try:\n",
    "            if df[col].dtype == 'float32': # 기존에 float은 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "            elif df[col].dtype == 'int8' or df[col].dtype == 'int16': # 기존에 int도 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "                #print(col)\n",
    "            else:\n",
    "                df[col] = df[col].astype('object')\n",
    "                # nan값이 있으면 float으로 갈 수 없으니 '-2' 으로 채워줍니다.\n",
    "                df[col] = df[col].fillna('-2')\n",
    "                df[col] = df[col].apply(lambda x: x.replace(',' , ''))\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # fwver 에서 null 값이 꽤 있습니다. missing으로 채우겠습니다.\n",
    "    df.fwver = df.fwver.astype('object')\n",
    "    df.fwver = df.fwver.fillna('missing')\n",
    "    df.fwver = df.fwver.astype('category')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = preprocessing_quality(train_q)\n",
    "test_q = preprocessing_quality(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fwver(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    별건 아니고, e-set에 fwver 변수에서 '10' 이라는 값이 있는데, 이게 errtype이랑 겹쳐요.\n",
    "    그래서 10을 -> 8.5.2 으로 바꿔줄 겁니다.\n",
    "    굳이 이렇게 바꾸는 이유는, 해당 fw가 8.5.3버전과 같은 model_nm을 공유하기 때문입니다.\n",
    "    \"\"\"\n",
    "    df.fwver = df.fwver.replace('10', '8.5.2')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = preprocessing_fwver(train_e)\n",
    "test_e = preprocessing_fwver(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    'time' column이 str로 되어 있으니, datetime으로 바꿔주는 함수입니다.\n",
    "    다만 'time'양식이 pandas함수에 적용이 안되니, 강제로 슬라이싱해서 만들어줘야 합니다.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df['year'] = df['time'].apply(lambda x: str(x)[:4])\n",
    "    df['month'] = df['time'].apply(lambda x: str(x)[4:6])\n",
    "    df['day'] = df['time'].apply(lambda x: str(x)[6:8])\n",
    "    df['hour'] = df['time'].apply(lambda x: str(x)[8:10])\n",
    "    df['minute'] = '00' # minute을 넣어주지 않으면 datetime이 완성이 안되니, 00으로 넣어줍니다.\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df.year + df.month + df.day + df.hour + df.minute)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = make_datetime(train_p)\n",
    "train_q = make_datetime(train_q)\n",
    "test_q = make_datetime(test_q)\n",
    "train_e = make_datetime(train_e)\n",
    "test_e = make_datetime(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 연산에서 왜 문제가 생기나 했더니 category로 되어 있어서였습니다.\n",
    "\n",
    "train_e['errtype'] = train_e.errtype.astype('object')\n",
    "test_e['errtype'] = test_e.errtype.astype('object')\n",
    "\n",
    "train_e['errcode'] = train_e.errcode.astype('object')\n",
    "test_e['errcode'] = test_e.errcode.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwver도 object로 잡아줍니다.\n",
    "\n",
    "train_q.fwver = train_q.fwver.astype('object')\n",
    "test_q.fwver = test_q.fwver.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from Error_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용한 model의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_count = train_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()\n",
    "test_model_count = test_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용한 fwver 의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fwver_count = train_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()\n",
    "test_fwver_count = test_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경험한 error 의 총 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_count = train_e.groupby('user_id')['errcode'].count()\n",
    "test_err_count = test_e.groupby('user_id')['errcode'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경험한 각 errtype의 value별 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33호\n",
    "train_errcode_33 = train_e[train_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_33 = test_e[test_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']\n",
    "test_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23호\n",
    "train_errcode_23 = train_e[train_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_23 = test_e[test_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']\n",
    "test_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34호\n",
    "train_errcode_34 = train_e[train_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_34 = test_e[test_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']\n",
    "test_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from Quality_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 quality의 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_std = train_q.groupby(['user_id']).std()\n",
    "test_qual_std = test_q.groupby(['user_id']).std()\n",
    "\n",
    "new_columns = ['q_std_0', 'q_std_1', 'q_std_2', 'q_std_5', 'q_std_6', 'q_std_7', 'q_std_8', 'q_std_9', 'q_std_10','q_std_11', 'q_std_12']\n",
    "\n",
    "train_qual_std.columns = new_columns\n",
    "test_qual_std.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기록한 quality log의 개수(12개당 1번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_log = train_q.groupby('user_id')['time'].count()/12\n",
    "test_qual_log = test_q.groupby('user_id')['time'].count()/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality당 순수 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값을 만들기 위해 새로운 df를 받아옵니다.\n",
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()\n",
    "\n",
    "# 0 값을 전부 nan 값으로 바꿔줍니다.\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "\n",
    "# 필요없는 변수들을 버려줍니다.\n",
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "\n",
    "# 그룹바이 카운트 해줍니다.\n",
    "train_qual_counts = train_q_temp.groupby('user_id').count()\n",
    "test_qual_counts = test_q_temp.groupby('user_id').count()\n",
    "\n",
    "# 겹치는 컬럼명을 바꿔줍니다.\n",
    "train_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']\n",
    "test_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality당 음수, 0에 대한 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 값만 count를 위해서 음수와 양수를 전부 nan으로 만들겠습니다.\n",
    "\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] < 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] < 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] > 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] > 0, 'quality_{}'.format(i)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_zeroCount = train_q_temp.groupby('user_id').count()\n",
    "test_qual_zeroCount = test_q_temp.groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['q_z_c_0', 'q_z_c_1', 'q_z_c_2', 'q_z_c_5', 'q_z_c_6', 'q_z_c_7', 'q_z_c_8', 'q_z_c_9', 'q_z_c_10','q_z_c_11', 'q_z_c_12']\n",
    "\n",
    "train_qual_zeroCount.columns = new_columns\n",
    "test_qual_zeroCount.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음수 값만 count를 위해서 음수와 0을 전부 nan으로 만들겠습니다.\n",
    "\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] >= 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] >= 0, 'quality_{}'.format(i)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_negaCount = train_q_temp.groupby('user_id').count()\n",
    "test_qual_negaCount = test_q_temp.groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['q_n_c_0', 'q_n_c_1', 'q_n_c_2', 'q_n_c_5', 'q_n_c_6', 'q_n_c_7', 'q_n_c_8', 'q_n_c_9', 'q_n_c_10','q_n_c_11', 'q_n_c_12']\n",
    "\n",
    "train_qual_negaCount.columns = new_columns\n",
    "test_qual_negaCount.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time에 대한 유저별 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "def time_to_seconds(x):\n",
    "    return time.mktime(x.timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_e['time_sec'] = train_e.time.apply(lambda x: time_to_seconds(x))\n",
    "test_e['time_sec'] = test_e.time.apply(lambda x: time_to_seconds(x))\n",
    "train_q['time_sec'] = train_q.time.apply(lambda x: time_to_seconds(x))\n",
    "test_q['time_sec'] = test_q.time.apply(lambda x: time_to_seconds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 481 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_err_timestd = train_e.groupby(['user_id'])['time_sec'].std()\n",
    "test_err_timestd = test_e.groupby(['user_id'])['time_sec'].std()\n",
    "train_err_timestd = train_err_timestd.rename(level = 0, index = 't_e_std') \n",
    "test_err_timestd = test_err_timestd.rename(level = 0, index = 't_e_std') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qual_timestd = (train_q[['user_id', 'time_sec']].drop_duplicates()).groupby(['user_id']).std()\n",
    "test_qual_timestd = (test_q[['user_id', 'time_sec']].drop_duplicates()).groupby(['user_id']).std()\n",
    "train_qual_timestd.columns = ['t_q_std']\n",
    "test_qual_timestd.columns = ['t_q_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality를 sum으로 groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_each_quality_sum = train_q.groupby('user_id').sum().loc[:, 'quality_0':'quality_12']\n",
    "test_each_quality_sum = test_q.groupby('user_id').sum().loc[:, 'quality_0':'quality_12']\n",
    "\n",
    "quality_sum_colnms = ['quality_0_sum', 'quality_1_sum', 'quality_2_sum', 'quality_5_sum', 'quality_6_sum', \n",
    "                      'quality_7_sum', 'quality_8_sum', 'quality_9_sum','quality_10_sum', 'quality_11_sum', \n",
    "                      'quality_12_sum']\n",
    "\n",
    "train_each_quality_sum.columns = quality_sum_colnms\n",
    "test_each_quality_sum.columns = quality_sum_colnms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 죽지도 않고 또 온 31호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혜인이 다시 제안한 조건부 31호.\n",
    "train_errcode_31 = train_e[train_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "                            groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_31 = test_e[test_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "                            groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "train_errcode_31.columns = ['err_31_0', 'err_31_1']\n",
    "test_errcode_31.columns =['err_31_0', 'err_31_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### day max를 mean으로 나눈 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_e['day_2'] = train_e['time'].apply(lambda x: str(x)[:10])\n",
    "\n",
    "train_meanDay = (train_e\n",
    "                 .groupby(['user_id','day_2'])['day_2']\n",
    "                 .count()\n",
    "                 .unstack()\n",
    "                 .fillna(0)\n",
    "                 .loc[:, '2020-11-01':'2020-11-30']\n",
    "                 .mean(axis=1))\n",
    "\n",
    "train_maxDay = (train_e\n",
    "                .groupby(['user_id','day_2'])['day_2']\n",
    "                .count()\n",
    "                .unstack()\n",
    "                .fillna(0)\n",
    "                .loc[:, '2020-11-01':'2020-11-30']\n",
    "                .max(axis=1))\n",
    "\n",
    "train_maxBymean = pd.Series(data = np.array(train_maxDay) / np.array(train_meanDay),\n",
    "                            index = train_e.user_id.unique(),\n",
    "                            name = 'mbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_e['day_2'] = test_e['time'].apply(lambda x: str(x)[:10])\n",
    "\n",
    "test_meanDay = (test_e\n",
    "                .groupby(['user_id','day_2'])['day_2']\n",
    "                .count()\n",
    "                .unstack()\n",
    "                .fillna(0)\n",
    "                .loc[:, '2020-11-01':'2020-11-30']\n",
    "                .mean(axis=1))\n",
    "\n",
    "test_maxDay = (test_e\n",
    "               .groupby(['user_id','day_2'])['day_2']\n",
    "               .count()\n",
    "               .unstack()\n",
    "               .fillna(0)\n",
    "               .loc[:, '2020-11-01':'2020-11-30']\n",
    "               .max(axis=1))\n",
    "\n",
    "test_maxBymean = pd.Series(data = np.array(test_maxDay) / np.array(test_meanDay),\n",
    "                           index = test_e.user_id.unique(),\n",
    "                           name = 'mbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제작 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 시간 타입으로 변환\n",
    "train_e.hour = train_e.hour.astype(np.int16)\n",
    "test_e.hour = test_e.hour.astype(np.int16)\n",
    "\n",
    "train_e.loc[train_e.hour < 12, 'AM'] = 'AM'\n",
    "train_e.loc[train_e.hour >= 12, 'PM'] = 'PM'\n",
    "\n",
    "test_e.loc[test_e.hour < 12, 'AM'] = 'AM'\n",
    "test_e.loc[test_e.hour >= 12, 'PM'] = 'PM'\n",
    "\n",
    "train_err_am = train_e.groupby(['user_id', 'AM'])['AM'].count().unstack()\n",
    "train_err_pm = train_e.groupby(['user_id', 'PM'])['PM'].count().unstack()\n",
    "test_err_am = test_e.groupby(['user_id', 'AM'])['AM'].count().unstack()\n",
    "test_err_pm = test_e.groupby(['user_id', 'PM'])['PM'].count().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errtype을 유저별로 카운트 해줍니다.\n",
    "\n",
    "X = train_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "y = test_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "\n",
    "X.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']\n",
    "y.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나 사라진 유저를 채워주는 코드입니다.\n",
    "y = y.reindex(pd.RangeIndex(y.index.max() + 1)).ffill(0)[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 41), (14999, 41))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 106)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,\n",
    "               train_err_count, # 유저가 기록한 총 err수\n",
    "               train_fwver_count, # 유저가 사용한 fw수\n",
    "               train_model_count, # 유저가 사용한 model 수\n",
    "               train_qual_std, # 각 퀄리티에 대한 유저별 편차\n",
    "               train_qual_log, # 유저별 퀄리티 로그의 수\n",
    "               train_errcode_23, # 23호 에러타입의 밸류별 개수\n",
    "               train_errcode_33, # 33호 상동\n",
    "               train_errcode_34, # 34호 상동\n",
    "               train_qual_counts, # 각 퀄리티에서 0을 제외한 카운트\n",
    "               train_qual_negaCount, # 각 퀄리티에 대해 음수만 카운트\n",
    "               train_qual_zeroCount # 각 퀄리티에 대해 0.만 카운트\n",
    "              ], axis=1).fillna(0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 106)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat([y,\n",
    "               test_err_count,\n",
    "               test_fwver_count,\n",
    "               test_model_count,\n",
    "               test_qual_std,\n",
    "               test_qual_log,\n",
    "               test_errcode_23,\n",
    "               test_errcode_33,\n",
    "               test_errcode_34,\n",
    "               test_qual_counts,\n",
    "               test_qual_negaCount,\n",
    "               test_qual_zeroCount\n",
    "              ], axis=1).fillna(0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3차 합격생들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 120), (14999, 120))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X, train_err_timestd, train_qual_timestd, train_each_quality_sum, train_errcode_31, train_maxBymean], axis=1).fillna(0)\n",
    "y = pd.concat([y, test_err_timestd, test_qual_timestd, test_each_quality_sum, test_errcode_31, test_maxBymean], axis=1).fillna(0)\n",
    "\n",
    "X.drop(['et_20', 'et_36'], axis=1, inplace = True)\n",
    "y.drop(['et_20', 'et_36'], axis=1, inplace = True)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3차 면접중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 122), (14999, 122))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = pd.concat([X, train_err_am, train_err_pm], axis=1).fillna(0)\n",
    "y_temp = pd.concat([y, test_err_am, test_err_pm], axis=1).fillna(0)\n",
    "\n",
    "X_temp.shape, y_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혜인이 막판 뒤집기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. [err] errtype\n",
    "train_err_unique_errtype = train_e[['user_id', 'errtype']].drop_duplicates().groupby('user_id').count()\n",
    "test_err_unique_errtype = test_e[['user_id', 'errtype']].drop_duplicates().groupby('user_id').count()\n",
    "train_err_unique_errtype.columns = ['err_unique_errtype']\n",
    "test_err_unique_errtype.columns = ['err_unique_errtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 120), (14999, 120))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp2 = pd.concat([X, train_err_unique_errtype], axis=1).fillna(0)\n",
    "y_temp2 = pd.concat([y, test_err_unique_errtype], axis=1).fillna(0)\n",
    "\n",
    "X_temp2.drop(['et_4'], axis=1, inplace = True)\n",
    "y_temp2.drop(['et_4'], axis=1, inplace = True)\n",
    "\n",
    "X_temp2.shape, y_temp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 122), (14999, 122))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp3 = pd.concat([X, train_err_am, train_err_pm, train_err_unique_errtype], axis=1).fillna(0)\n",
    "y_temp3 = pd.concat([y, test_err_am, test_err_pm, test_err_unique_errtype], axis=1).fillna(0)\n",
    "\n",
    "X_temp3.drop(['et_4'], axis=1, inplace = True)\n",
    "y_temp3.drop(['et_4'], axis=1, inplace = True)\n",
    "\n",
    "X_temp3.shape, y_temp3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et_1</th>\n",
       "      <th>et_2</th>\n",
       "      <th>et_3</th>\n",
       "      <th>et_4</th>\n",
       "      <th>et_5</th>\n",
       "      <th>et_6</th>\n",
       "      <th>et_7</th>\n",
       "      <th>et_8</th>\n",
       "      <th>et_9</th>\n",
       "      <th>et_10</th>\n",
       "      <th>et_11</th>\n",
       "      <th>et_12</th>\n",
       "      <th>et_13</th>\n",
       "      <th>et_14</th>\n",
       "      <th>et_15</th>\n",
       "      <th>et_16</th>\n",
       "      <th>et_17</th>\n",
       "      <th>et_18</th>\n",
       "      <th>et_19</th>\n",
       "      <th>et_21</th>\n",
       "      <th>et_22</th>\n",
       "      <th>et_23</th>\n",
       "      <th>et_24</th>\n",
       "      <th>et_25</th>\n",
       "      <th>et_26</th>\n",
       "      <th>et_27</th>\n",
       "      <th>et_28</th>\n",
       "      <th>et_30</th>\n",
       "      <th>et_31</th>\n",
       "      <th>et_32</th>\n",
       "      <th>et_33</th>\n",
       "      <th>et_34</th>\n",
       "      <th>et_35</th>\n",
       "      <th>et_37</th>\n",
       "      <th>et_38</th>\n",
       "      <th>et_39</th>\n",
       "      <th>et_40</th>\n",
       "      <th>et_41</th>\n",
       "      <th>et_42</th>\n",
       "      <th>errcode</th>\n",
       "      <th>fwver</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>q_std_0</th>\n",
       "      <th>q_std_1</th>\n",
       "      <th>q_std_2</th>\n",
       "      <th>q_std_5</th>\n",
       "      <th>q_std_6</th>\n",
       "      <th>q_std_7</th>\n",
       "      <th>q_std_8</th>\n",
       "      <th>q_std_9</th>\n",
       "      <th>q_std_10</th>\n",
       "      <th>q_std_11</th>\n",
       "      <th>q_std_12</th>\n",
       "      <th>time</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>connLMP</th>\n",
       "      <th>connESTA</th>\n",
       "      <th>connTO</th>\n",
       "      <th>connLOCAL</th>\n",
       "      <th>STANDBY</th>\n",
       "      <th>TERMINATE</th>\n",
       "      <th>err_33_1</th>\n",
       "      <th>err_33_2</th>\n",
       "      <th>err_33_3</th>\n",
       "      <th>err_34_1</th>\n",
       "      <th>err_34_2</th>\n",
       "      <th>err_34_3</th>\n",
       "      <th>err_34_4</th>\n",
       "      <th>err_34_5</th>\n",
       "      <th>err_34_6</th>\n",
       "      <th>q_c_0</th>\n",
       "      <th>q_c_1</th>\n",
       "      <th>q_c_2</th>\n",
       "      <th>q_c_5</th>\n",
       "      <th>q_c_6</th>\n",
       "      <th>q_c_7</th>\n",
       "      <th>q_c_8</th>\n",
       "      <th>q_c_9</th>\n",
       "      <th>q_c_10</th>\n",
       "      <th>q_c_11</th>\n",
       "      <th>q_c_12</th>\n",
       "      <th>q_n_c_0</th>\n",
       "      <th>q_n_c_1</th>\n",
       "      <th>q_n_c_2</th>\n",
       "      <th>q_n_c_5</th>\n",
       "      <th>q_n_c_6</th>\n",
       "      <th>q_n_c_7</th>\n",
       "      <th>q_n_c_8</th>\n",
       "      <th>q_n_c_9</th>\n",
       "      <th>q_n_c_10</th>\n",
       "      <th>q_n_c_11</th>\n",
       "      <th>q_n_c_12</th>\n",
       "      <th>q_z_c_0</th>\n",
       "      <th>q_z_c_1</th>\n",
       "      <th>q_z_c_2</th>\n",
       "      <th>q_z_c_5</th>\n",
       "      <th>q_z_c_6</th>\n",
       "      <th>q_z_c_7</th>\n",
       "      <th>q_z_c_8</th>\n",
       "      <th>q_z_c_9</th>\n",
       "      <th>q_z_c_10</th>\n",
       "      <th>q_z_c_11</th>\n",
       "      <th>q_z_c_12</th>\n",
       "      <th>t_e_std</th>\n",
       "      <th>t_q_std</th>\n",
       "      <th>quality_0_sum</th>\n",
       "      <th>quality_1_sum</th>\n",
       "      <th>quality_2_sum</th>\n",
       "      <th>quality_5_sum</th>\n",
       "      <th>quality_6_sum</th>\n",
       "      <th>quality_7_sum</th>\n",
       "      <th>quality_8_sum</th>\n",
       "      <th>quality_9_sum</th>\n",
       "      <th>quality_10_sum</th>\n",
       "      <th>quality_11_sum</th>\n",
       "      <th>quality_12_sum</th>\n",
       "      <th>err_31_0</th>\n",
       "      <th>err_31_1</th>\n",
       "      <th>mbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.793709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.043016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>760181.244016</td>\n",
       "      <td>91641.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.892744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2365</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696650.374750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.418605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251312</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>1.037404</td>\n",
       "      <td>4.495417</td>\n",
       "      <td>14.547924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>2.327185</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>727335.561994</td>\n",
       "      <td>842035.085798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759965.723107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>777</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.583592</td>\n",
       "      <td>17.778784</td>\n",
       "      <td>44.435591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>733973.687056</td>\n",
       "      <td>94186.623254</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.938224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>289675.976562</td>\n",
       "      <td>10182.337649</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.639175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>2.060234</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.661309</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>762270.100704</td>\n",
       "      <td>926592.726067</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.324455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694269.089593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>744259.010130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       et_1  et_2  et_3   et_4  et_5  et_6  et_7  et_8  et_9  et_10  et_11  \\\n",
       "10000   0.0   0.0   8.0  104.0   0.0   1.0   1.0   0.0   0.0    7.0   15.0   \n",
       "10001   0.0   0.0   0.0    0.0  53.0   1.0   1.0   0.0   0.0    0.0   10.0   \n",
       "10002   0.0   0.0   2.0  132.0   1.0   2.0   1.0   0.0   0.0    1.0   13.0   \n",
       "10003   0.0   0.0   0.0    0.0   2.0   1.0   1.0   0.0   0.0    0.0    9.0   \n",
       "10004   0.0   0.0   0.0    1.0   0.0   3.0   4.0   0.0   0.0    0.0   16.0   \n",
       "...     ...   ...   ...    ...   ...   ...   ...   ...   ...    ...    ...   \n",
       "24995   0.0   0.0   0.0    0.0   2.0   5.0   5.0   0.0   0.0    0.0    5.0   \n",
       "24996   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0   \n",
       "24997   0.0   0.0   0.0    1.0   8.0   1.0   1.0   0.0   0.0    0.0   16.0   \n",
       "24998   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   15.0   \n",
       "24999   0.0   0.0   4.0  192.0   7.0   5.0   4.0   0.0   0.0    0.0   15.0   \n",
       "\n",
       "       et_12  et_13  et_14  et_15  et_16  et_17  et_18  et_19  et_21  et_22  \\\n",
       "10000   16.0    1.0   10.0   59.0   61.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10001   11.0    1.0   15.0  151.0  128.0    0.0    4.0    1.0    1.0  756.0   \n",
       "10002   14.0    1.0    4.0   52.0   52.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10003    9.0    0.0    0.0   52.0   30.0    1.0    0.0    0.0    0.0   28.0   \n",
       "10004   19.0    3.0    5.0  143.0   91.0    0.0    0.0    0.0    0.0  140.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995   10.0    8.0    8.0   26.0   18.0    0.0    0.0    0.0    0.0   17.0   \n",
       "24996    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997   18.0    4.0    1.0  181.0  138.0    0.0    0.0    0.0    0.0   50.0   \n",
       "24998   15.0    0.0    1.0   51.0   12.0    0.0    0.0    0.0    0.0    7.0   \n",
       "24999   19.0    4.0   20.0  135.0  135.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_23  et_24  et_25  et_26  et_27  et_28  et_30  et_31  et_32  et_33  \\\n",
       "10000    0.0    0.0    0.0   32.0    1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "10001  751.0    5.0    1.0   22.0    0.0    0.0    0.0  250.0    0.0   10.0   \n",
       "10002    0.0    2.0    0.0   25.0    2.0    2.0    0.0    0.0    0.0    0.0   \n",
       "10003   19.0    0.0    0.0   59.0    0.0    0.0    0.0   65.0    0.0    8.0   \n",
       "10004  119.0    0.0    0.0   33.0    0.0    0.0    0.0  176.0    0.0   16.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995   12.0    0.0    0.0   22.0    0.0    0.0    0.0   31.0    0.0    5.0   \n",
       "24996    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "24997   29.0    0.0    0.0   49.0    0.0    0.0    0.0  223.0    0.0   16.0   \n",
       "24998    1.0    0.0    0.0    4.0    0.0    0.0    0.0   14.0    0.0   15.0   \n",
       "24999    0.0    0.0    0.0   30.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_34  et_35  et_37  et_38  et_39  et_40  et_41  et_42  errcode  fwver  \\\n",
       "10000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0      317      1   \n",
       "10001   18.0    0.0    1.0    0.0    0.0  113.0   56.0    1.0     2365      2   \n",
       "10002    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0      306      1   \n",
       "10003    0.0    0.0    1.0    2.0    0.0   17.0    1.0    0.0      306      2   \n",
       "10004    0.0    0.0    1.0    0.0    0.0    4.0    0.0    2.0      777      2   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...      ...    ...   \n",
       "24995    0.0    0.0    0.0    0.0    0.0    9.0    7.0    4.0      194      1   \n",
       "24996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0        4      1   \n",
       "24997   17.0    0.0    1.0    0.0    0.0   58.0    8.0    5.0      826      2   \n",
       "24998   12.0    0.0    1.0    0.0    0.0    6.0    0.0    0.0      155      2   \n",
       "24999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0      570      1   \n",
       "\n",
       "       model_nm   q_std_0   q_std_1   q_std_2   q_std_5    q_std_6    q_std_7  \\\n",
       "10000         1  0.000000  0.000000  0.000000  1.793709   0.000000   0.000000   \n",
       "10001         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10002         1  0.251312  0.143576  0.177396  1.037404   4.495417  14.547924   \n",
       "10003         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10004         1  0.282330  0.282330  0.282330  0.583592  17.778784  44.435591   \n",
       "...         ...       ...       ...       ...       ...        ...        ...   \n",
       "24995         1  0.503610  0.503610  0.503610  0.977093   0.503610   0.000000   \n",
       "24996         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24997         1  0.380693  0.380693  0.380693  2.060234   0.380693   0.000000   \n",
       "24998         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24999         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "       q_std_8   q_std_9  q_std_10  q_std_11  q_std_12  time  UNKNOWN  ACTIVE  \\\n",
       "10000      0.0  0.000000  2.043016  0.000000       0.0   2.0      0.0     0.0   \n",
       "10001      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0   126.0   \n",
       "10002      0.0  0.332455  2.327185  0.143576       0.0   8.0      0.0     0.0   \n",
       "10003      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0    12.0   \n",
       "10004      0.0  0.000000  1.021508  0.282330       0.0   2.0      0.0     7.0   \n",
       "...        ...       ...       ...       ...       ...   ...      ...     ...   \n",
       "24995      0.0  0.000000  0.510754  0.503610       0.0   2.0      0.0     4.0   \n",
       "24996      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "24997      0.0  0.000000  7.661309  0.380693       0.0   2.0      0.0     4.0   \n",
       "24998      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     1.0   \n",
       "24999      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "\n",
       "       connLMP  connESTA  connTO  connLOCAL  STANDBY  TERMINATE  err_33_1  \\\n",
       "10000      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10001      0.0       0.0     0.0        0.0    625.0        0.0       0.0   \n",
       "10002      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10003      0.0       0.0     7.0        0.0      0.0        0.0       1.0   \n",
       "10004      0.0       1.0   104.0        0.0      5.0        2.0       0.0   \n",
       "...        ...       ...     ...        ...      ...        ...       ...   \n",
       "24995      0.0       0.0     0.0        0.0      8.0        0.0       1.0   \n",
       "24996      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "24997      0.0       0.0    13.0        1.0     11.0        0.0       3.0   \n",
       "24998      0.0       0.0     0.0        0.0      0.0        0.0       2.0   \n",
       "24999      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "\n",
       "       err_33_2  err_33_3  err_34_1  err_34_2  err_34_3  err_34_4  err_34_5  \\\n",
       "10000       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10001       6.0       4.0       0.0       0.0       0.0      18.0       0.0   \n",
       "10002       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10003       3.0       4.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10004      14.0       2.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995       4.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24996       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24997      11.0       2.0       2.0       9.0       6.0       0.0       0.0   \n",
       "24998      12.0       1.0      11.0       0.0       0.0       1.0       0.0   \n",
       "24999       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       err_34_6  q_c_0  q_c_1  q_c_2  q_c_5  q_c_6  q_c_7  q_c_8  q_c_9  \\\n",
       "10000       0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0   \n",
       "10001       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10002       0.0    3.0    2.0    3.0   14.0    5.0   24.0    0.0   12.0   \n",
       "10003       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10004       0.0    2.0    2.0    2.0    5.0    3.0   12.0    0.0    0.0   \n",
       "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995       0.0   10.0   10.0   10.0   12.0   10.0    0.0    0.0    0.0   \n",
       "24996       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997       0.0    4.0    4.0    4.0   10.0    4.0    0.0    0.0    0.0   \n",
       "24998       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24999       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       q_c_10  q_c_11  q_c_12  q_n_c_0  q_n_c_1  q_n_c_2  q_n_c_5  q_n_c_6  \\\n",
       "10000    24.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10001     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002    84.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "10003     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004    24.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "...       ...     ...     ...      ...      ...      ...      ...      ...   \n",
       "24995    24.0    10.0     0.0     10.0     10.0     10.0     10.0     10.0   \n",
       "24996     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997    24.0     4.0     0.0      4.0      4.0      4.0      4.0      4.0   \n",
       "24998     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_n_c_7  q_n_c_8  q_n_c_9  q_n_c_10  q_n_c_11  q_n_c_12  q_z_c_0  \\\n",
       "10000      0.0      0.0      0.0       0.0       0.0       0.0     24.0   \n",
       "10001      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10002      0.0      0.0      0.0       0.0       2.0       0.0     93.0   \n",
       "10003      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10004      0.0      0.0      0.0       0.0       2.0       0.0     22.0   \n",
       "...        ...      ...      ...       ...       ...       ...      ...   \n",
       "24995      0.0      0.0      0.0       0.0      10.0       0.0     14.0   \n",
       "24996      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24997      0.0      0.0      0.0       0.0       4.0       0.0     20.0   \n",
       "24998      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24999      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "\n",
       "       q_z_c_1  q_z_c_2  q_z_c_5  q_z_c_6  q_z_c_7  q_z_c_8  q_z_c_9  \\\n",
       "10000     24.0     24.0     22.0     24.0     24.0     24.0     24.0   \n",
       "10001      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002     94.0     93.0     82.0     91.0     72.0     96.0     84.0   \n",
       "10003      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004     22.0     22.0     19.0     21.0     12.0     24.0     24.0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...   \n",
       "24995     14.0     14.0     12.0     14.0     24.0     24.0     24.0   \n",
       "24996      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997     20.0     20.0     14.0     20.0     24.0     24.0     24.0   \n",
       "24998      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_z_c_10  q_z_c_11  q_z_c_12        t_e_std        t_q_std  \\\n",
       "10000       0.0      24.0      24.0  760181.244016   91641.038842   \n",
       "10001       0.0       0.0       0.0  696650.374750       0.000000   \n",
       "10002      12.0      94.0      96.0  727335.561994  842035.085798   \n",
       "10003       0.0       0.0       0.0  759965.723107       0.000000   \n",
       "10004       0.0      22.0      24.0  733973.687056   94186.623254   \n",
       "...         ...       ...       ...            ...            ...   \n",
       "24995       0.0      14.0      24.0  289675.976562   10182.337649   \n",
       "24996       0.0       0.0       0.0       0.000000       0.000000   \n",
       "24997       0.0      20.0      24.0  762270.100704  926592.726067   \n",
       "24998       0.0       0.0       0.0  694269.089593       0.000000   \n",
       "24999       0.0       0.0       0.0  744259.010130       0.000000   \n",
       "\n",
       "       quality_0_sum  quality_1_sum  quality_2_sum  quality_5_sum  \\\n",
       "10000            0.0            0.0            0.0           12.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002            0.0           -2.0           -1.0           29.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           -2.0           -2.0           -2.0            2.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0          -10.0          -10.0           -5.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0           -4.0           -4.0           15.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_6_sum  quality_7_sum  quality_8_sum  quality_9_sum  \\\n",
       "10000            0.0            0.0            0.0            0.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002           44.0          552.0            0.0           12.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           85.0         1044.0            0.0            0.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0            0.0            0.0            0.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0            0.0            0.0            0.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_10_sum  quality_11_sum  quality_12_sum  err_31_0  err_31_1  \\\n",
       "10000           144.0             0.0             0.0       0.0       0.0   \n",
       "10001             0.0             0.0             0.0     126.0     124.0   \n",
       "10002           372.0            -2.0             0.0       0.0       0.0   \n",
       "10003             0.0             0.0             0.0      33.0      32.0   \n",
       "10004            48.0            -2.0             0.0      95.0      81.0   \n",
       "...               ...             ...             ...       ...       ...   \n",
       "24995            60.0           -10.0             0.0      18.0      13.0   \n",
       "24996             0.0             0.0             0.0       0.0       0.0   \n",
       "24997           228.0            -4.0             0.0     116.0     107.0   \n",
       "24998             0.0             0.0             0.0       9.0       5.0   \n",
       "24999             0.0             0.0             0.0       0.0       0.0   \n",
       "\n",
       "             mbm  \n",
       "10000   1.892744  \n",
       "10001  18.418605  \n",
       "10002   1.666667  \n",
       "10003   2.352941  \n",
       "10004   3.938224  \n",
       "...          ...  \n",
       "24995   4.639175  \n",
       "24996  30.000000  \n",
       "24997   2.324455  \n",
       "24998   7.161290  \n",
       "24999   1.578947  \n",
       "\n",
       "[15000 rows x 120 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et_1</th>\n",
       "      <th>et_2</th>\n",
       "      <th>et_3</th>\n",
       "      <th>et_4</th>\n",
       "      <th>et_5</th>\n",
       "      <th>et_6</th>\n",
       "      <th>et_7</th>\n",
       "      <th>et_8</th>\n",
       "      <th>et_9</th>\n",
       "      <th>et_10</th>\n",
       "      <th>et_11</th>\n",
       "      <th>et_12</th>\n",
       "      <th>et_13</th>\n",
       "      <th>et_14</th>\n",
       "      <th>et_15</th>\n",
       "      <th>et_16</th>\n",
       "      <th>et_17</th>\n",
       "      <th>et_18</th>\n",
       "      <th>et_19</th>\n",
       "      <th>et_21</th>\n",
       "      <th>et_22</th>\n",
       "      <th>et_23</th>\n",
       "      <th>et_24</th>\n",
       "      <th>et_25</th>\n",
       "      <th>et_26</th>\n",
       "      <th>et_27</th>\n",
       "      <th>et_28</th>\n",
       "      <th>et_30</th>\n",
       "      <th>et_31</th>\n",
       "      <th>et_32</th>\n",
       "      <th>et_33</th>\n",
       "      <th>et_34</th>\n",
       "      <th>et_35</th>\n",
       "      <th>et_37</th>\n",
       "      <th>et_38</th>\n",
       "      <th>et_39</th>\n",
       "      <th>et_40</th>\n",
       "      <th>et_41</th>\n",
       "      <th>et_42</th>\n",
       "      <th>errcode</th>\n",
       "      <th>fwver</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>q_std_0</th>\n",
       "      <th>q_std_1</th>\n",
       "      <th>q_std_2</th>\n",
       "      <th>q_std_5</th>\n",
       "      <th>q_std_6</th>\n",
       "      <th>q_std_7</th>\n",
       "      <th>q_std_8</th>\n",
       "      <th>q_std_9</th>\n",
       "      <th>q_std_10</th>\n",
       "      <th>q_std_11</th>\n",
       "      <th>q_std_12</th>\n",
       "      <th>time</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>connLMP</th>\n",
       "      <th>connESTA</th>\n",
       "      <th>connTO</th>\n",
       "      <th>connLOCAL</th>\n",
       "      <th>STANDBY</th>\n",
       "      <th>TERMINATE</th>\n",
       "      <th>err_33_1</th>\n",
       "      <th>err_33_2</th>\n",
       "      <th>err_33_3</th>\n",
       "      <th>err_34_1</th>\n",
       "      <th>err_34_2</th>\n",
       "      <th>err_34_3</th>\n",
       "      <th>err_34_4</th>\n",
       "      <th>err_34_5</th>\n",
       "      <th>err_34_6</th>\n",
       "      <th>q_c_0</th>\n",
       "      <th>q_c_1</th>\n",
       "      <th>q_c_2</th>\n",
       "      <th>q_c_5</th>\n",
       "      <th>q_c_6</th>\n",
       "      <th>q_c_7</th>\n",
       "      <th>q_c_8</th>\n",
       "      <th>q_c_9</th>\n",
       "      <th>q_c_10</th>\n",
       "      <th>q_c_11</th>\n",
       "      <th>q_c_12</th>\n",
       "      <th>q_n_c_0</th>\n",
       "      <th>q_n_c_1</th>\n",
       "      <th>q_n_c_2</th>\n",
       "      <th>q_n_c_5</th>\n",
       "      <th>q_n_c_6</th>\n",
       "      <th>q_n_c_7</th>\n",
       "      <th>q_n_c_8</th>\n",
       "      <th>q_n_c_9</th>\n",
       "      <th>q_n_c_10</th>\n",
       "      <th>q_n_c_11</th>\n",
       "      <th>q_n_c_12</th>\n",
       "      <th>q_z_c_0</th>\n",
       "      <th>q_z_c_1</th>\n",
       "      <th>q_z_c_2</th>\n",
       "      <th>q_z_c_5</th>\n",
       "      <th>q_z_c_6</th>\n",
       "      <th>q_z_c_7</th>\n",
       "      <th>q_z_c_8</th>\n",
       "      <th>q_z_c_9</th>\n",
       "      <th>q_z_c_10</th>\n",
       "      <th>q_z_c_11</th>\n",
       "      <th>q_z_c_12</th>\n",
       "      <th>t_e_std</th>\n",
       "      <th>t_q_std</th>\n",
       "      <th>quality_0_sum</th>\n",
       "      <th>quality_1_sum</th>\n",
       "      <th>quality_2_sum</th>\n",
       "      <th>quality_5_sum</th>\n",
       "      <th>quality_6_sum</th>\n",
       "      <th>quality_7_sum</th>\n",
       "      <th>quality_8_sum</th>\n",
       "      <th>quality_9_sum</th>\n",
       "      <th>quality_10_sum</th>\n",
       "      <th>quality_11_sum</th>\n",
       "      <th>quality_12_sum</th>\n",
       "      <th>err_31_0</th>\n",
       "      <th>err_31_1</th>\n",
       "      <th>mbm</th>\n",
       "      <th>AM</th>\n",
       "      <th>PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.793709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.043016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>760181.244016</td>\n",
       "      <td>91641.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.892744</td>\n",
       "      <td>224.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2365</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696650.374750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.418605</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251312</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>1.037404</td>\n",
       "      <td>4.495417</td>\n",
       "      <td>14.547924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>2.327185</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>727335.561994</td>\n",
       "      <td>842035.085798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>148.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759965.723107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>189.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>777</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.583592</td>\n",
       "      <td>17.778784</td>\n",
       "      <td>44.435591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>733973.687056</td>\n",
       "      <td>94186.623254</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.938224</td>\n",
       "      <td>321.0</td>\n",
       "      <td>456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>289675.976562</td>\n",
       "      <td>10182.337649</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.639175</td>\n",
       "      <td>68.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>2.060234</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.661309</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>762270.100704</td>\n",
       "      <td>926592.726067</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.324455</td>\n",
       "      <td>483.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694269.089593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.161290</td>\n",
       "      <td>96.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>744259.010130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>350.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       et_1  et_2  et_3   et_4  et_5  et_6  et_7  et_8  et_9  et_10  et_11  \\\n",
       "10000   0.0   0.0   8.0  104.0   0.0   1.0   1.0   0.0   0.0    7.0   15.0   \n",
       "10001   0.0   0.0   0.0    0.0  53.0   1.0   1.0   0.0   0.0    0.0   10.0   \n",
       "10002   0.0   0.0   2.0  132.0   1.0   2.0   1.0   0.0   0.0    1.0   13.0   \n",
       "10003   0.0   0.0   0.0    0.0   2.0   1.0   1.0   0.0   0.0    0.0    9.0   \n",
       "10004   0.0   0.0   0.0    1.0   0.0   3.0   4.0   0.0   0.0    0.0   16.0   \n",
       "...     ...   ...   ...    ...   ...   ...   ...   ...   ...    ...    ...   \n",
       "24995   0.0   0.0   0.0    0.0   2.0   5.0   5.0   0.0   0.0    0.0    5.0   \n",
       "24996   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0   \n",
       "24997   0.0   0.0   0.0    1.0   8.0   1.0   1.0   0.0   0.0    0.0   16.0   \n",
       "24998   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   15.0   \n",
       "24999   0.0   0.0   4.0  192.0   7.0   5.0   4.0   0.0   0.0    0.0   15.0   \n",
       "\n",
       "       et_12  et_13  et_14  et_15  et_16  et_17  et_18  et_19  et_21  et_22  \\\n",
       "10000   16.0    1.0   10.0   59.0   61.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10001   11.0    1.0   15.0  151.0  128.0    0.0    4.0    1.0    1.0  756.0   \n",
       "10002   14.0    1.0    4.0   52.0   52.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10003    9.0    0.0    0.0   52.0   30.0    1.0    0.0    0.0    0.0   28.0   \n",
       "10004   19.0    3.0    5.0  143.0   91.0    0.0    0.0    0.0    0.0  140.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995   10.0    8.0    8.0   26.0   18.0    0.0    0.0    0.0    0.0   17.0   \n",
       "24996    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997   18.0    4.0    1.0  181.0  138.0    0.0    0.0    0.0    0.0   50.0   \n",
       "24998   15.0    0.0    1.0   51.0   12.0    0.0    0.0    0.0    0.0    7.0   \n",
       "24999   19.0    4.0   20.0  135.0  135.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_23  et_24  et_25  et_26  et_27  et_28  et_30  et_31  et_32  et_33  \\\n",
       "10000    0.0    0.0    0.0   32.0    1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "10001  751.0    5.0    1.0   22.0    0.0    0.0    0.0  250.0    0.0   10.0   \n",
       "10002    0.0    2.0    0.0   25.0    2.0    2.0    0.0    0.0    0.0    0.0   \n",
       "10003   19.0    0.0    0.0   59.0    0.0    0.0    0.0   65.0    0.0    8.0   \n",
       "10004  119.0    0.0    0.0   33.0    0.0    0.0    0.0  176.0    0.0   16.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995   12.0    0.0    0.0   22.0    0.0    0.0    0.0   31.0    0.0    5.0   \n",
       "24996    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "24997   29.0    0.0    0.0   49.0    0.0    0.0    0.0  223.0    0.0   16.0   \n",
       "24998    1.0    0.0    0.0    4.0    0.0    0.0    0.0   14.0    0.0   15.0   \n",
       "24999    0.0    0.0    0.0   30.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_34  et_35  et_37  et_38  et_39  et_40  et_41  et_42  errcode  fwver  \\\n",
       "10000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0      317      1   \n",
       "10001   18.0    0.0    1.0    0.0    0.0  113.0   56.0    1.0     2365      2   \n",
       "10002    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0      306      1   \n",
       "10003    0.0    0.0    1.0    2.0    0.0   17.0    1.0    0.0      306      2   \n",
       "10004    0.0    0.0    1.0    0.0    0.0    4.0    0.0    2.0      777      2   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...      ...    ...   \n",
       "24995    0.0    0.0    0.0    0.0    0.0    9.0    7.0    4.0      194      1   \n",
       "24996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0        4      1   \n",
       "24997   17.0    0.0    1.0    0.0    0.0   58.0    8.0    5.0      826      2   \n",
       "24998   12.0    0.0    1.0    0.0    0.0    6.0    0.0    0.0      155      2   \n",
       "24999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0      570      1   \n",
       "\n",
       "       model_nm   q_std_0   q_std_1   q_std_2   q_std_5    q_std_6    q_std_7  \\\n",
       "10000         1  0.000000  0.000000  0.000000  1.793709   0.000000   0.000000   \n",
       "10001         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10002         1  0.251312  0.143576  0.177396  1.037404   4.495417  14.547924   \n",
       "10003         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10004         1  0.282330  0.282330  0.282330  0.583592  17.778784  44.435591   \n",
       "...         ...       ...       ...       ...       ...        ...        ...   \n",
       "24995         1  0.503610  0.503610  0.503610  0.977093   0.503610   0.000000   \n",
       "24996         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24997         1  0.380693  0.380693  0.380693  2.060234   0.380693   0.000000   \n",
       "24998         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24999         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "       q_std_8   q_std_9  q_std_10  q_std_11  q_std_12  time  UNKNOWN  ACTIVE  \\\n",
       "10000      0.0  0.000000  2.043016  0.000000       0.0   2.0      0.0     0.0   \n",
       "10001      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0   126.0   \n",
       "10002      0.0  0.332455  2.327185  0.143576       0.0   8.0      0.0     0.0   \n",
       "10003      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0    12.0   \n",
       "10004      0.0  0.000000  1.021508  0.282330       0.0   2.0      0.0     7.0   \n",
       "...        ...       ...       ...       ...       ...   ...      ...     ...   \n",
       "24995      0.0  0.000000  0.510754  0.503610       0.0   2.0      0.0     4.0   \n",
       "24996      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "24997      0.0  0.000000  7.661309  0.380693       0.0   2.0      0.0     4.0   \n",
       "24998      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     1.0   \n",
       "24999      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "\n",
       "       connLMP  connESTA  connTO  connLOCAL  STANDBY  TERMINATE  err_33_1  \\\n",
       "10000      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10001      0.0       0.0     0.0        0.0    625.0        0.0       0.0   \n",
       "10002      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10003      0.0       0.0     7.0        0.0      0.0        0.0       1.0   \n",
       "10004      0.0       1.0   104.0        0.0      5.0        2.0       0.0   \n",
       "...        ...       ...     ...        ...      ...        ...       ...   \n",
       "24995      0.0       0.0     0.0        0.0      8.0        0.0       1.0   \n",
       "24996      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "24997      0.0       0.0    13.0        1.0     11.0        0.0       3.0   \n",
       "24998      0.0       0.0     0.0        0.0      0.0        0.0       2.0   \n",
       "24999      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "\n",
       "       err_33_2  err_33_3  err_34_1  err_34_2  err_34_3  err_34_4  err_34_5  \\\n",
       "10000       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10001       6.0       4.0       0.0       0.0       0.0      18.0       0.0   \n",
       "10002       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10003       3.0       4.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10004      14.0       2.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995       4.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24996       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24997      11.0       2.0       2.0       9.0       6.0       0.0       0.0   \n",
       "24998      12.0       1.0      11.0       0.0       0.0       1.0       0.0   \n",
       "24999       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       err_34_6  q_c_0  q_c_1  q_c_2  q_c_5  q_c_6  q_c_7  q_c_8  q_c_9  \\\n",
       "10000       0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0   \n",
       "10001       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10002       0.0    3.0    2.0    3.0   14.0    5.0   24.0    0.0   12.0   \n",
       "10003       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10004       0.0    2.0    2.0    2.0    5.0    3.0   12.0    0.0    0.0   \n",
       "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995       0.0   10.0   10.0   10.0   12.0   10.0    0.0    0.0    0.0   \n",
       "24996       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997       0.0    4.0    4.0    4.0   10.0    4.0    0.0    0.0    0.0   \n",
       "24998       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24999       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       q_c_10  q_c_11  q_c_12  q_n_c_0  q_n_c_1  q_n_c_2  q_n_c_5  q_n_c_6  \\\n",
       "10000    24.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10001     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002    84.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "10003     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004    24.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "...       ...     ...     ...      ...      ...      ...      ...      ...   \n",
       "24995    24.0    10.0     0.0     10.0     10.0     10.0     10.0     10.0   \n",
       "24996     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997    24.0     4.0     0.0      4.0      4.0      4.0      4.0      4.0   \n",
       "24998     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_n_c_7  q_n_c_8  q_n_c_9  q_n_c_10  q_n_c_11  q_n_c_12  q_z_c_0  \\\n",
       "10000      0.0      0.0      0.0       0.0       0.0       0.0     24.0   \n",
       "10001      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10002      0.0      0.0      0.0       0.0       2.0       0.0     93.0   \n",
       "10003      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10004      0.0      0.0      0.0       0.0       2.0       0.0     22.0   \n",
       "...        ...      ...      ...       ...       ...       ...      ...   \n",
       "24995      0.0      0.0      0.0       0.0      10.0       0.0     14.0   \n",
       "24996      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24997      0.0      0.0      0.0       0.0       4.0       0.0     20.0   \n",
       "24998      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24999      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "\n",
       "       q_z_c_1  q_z_c_2  q_z_c_5  q_z_c_6  q_z_c_7  q_z_c_8  q_z_c_9  \\\n",
       "10000     24.0     24.0     22.0     24.0     24.0     24.0     24.0   \n",
       "10001      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002     94.0     93.0     82.0     91.0     72.0     96.0     84.0   \n",
       "10003      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004     22.0     22.0     19.0     21.0     12.0     24.0     24.0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...   \n",
       "24995     14.0     14.0     12.0     14.0     24.0     24.0     24.0   \n",
       "24996      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997     20.0     20.0     14.0     20.0     24.0     24.0     24.0   \n",
       "24998      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_z_c_10  q_z_c_11  q_z_c_12        t_e_std        t_q_std  \\\n",
       "10000       0.0      24.0      24.0  760181.244016   91641.038842   \n",
       "10001       0.0       0.0       0.0  696650.374750       0.000000   \n",
       "10002      12.0      94.0      96.0  727335.561994  842035.085798   \n",
       "10003       0.0       0.0       0.0  759965.723107       0.000000   \n",
       "10004       0.0      22.0      24.0  733973.687056   94186.623254   \n",
       "...         ...       ...       ...            ...            ...   \n",
       "24995       0.0      14.0      24.0  289675.976562   10182.337649   \n",
       "24996       0.0       0.0       0.0       0.000000       0.000000   \n",
       "24997       0.0      20.0      24.0  762270.100704  926592.726067   \n",
       "24998       0.0       0.0       0.0  694269.089593       0.000000   \n",
       "24999       0.0       0.0       0.0  744259.010130       0.000000   \n",
       "\n",
       "       quality_0_sum  quality_1_sum  quality_2_sum  quality_5_sum  \\\n",
       "10000            0.0            0.0            0.0           12.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002            0.0           -2.0           -1.0           29.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           -2.0           -2.0           -2.0            2.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0          -10.0          -10.0           -5.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0           -4.0           -4.0           15.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_6_sum  quality_7_sum  quality_8_sum  quality_9_sum  \\\n",
       "10000            0.0            0.0            0.0            0.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002           44.0          552.0            0.0           12.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           85.0         1044.0            0.0            0.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0            0.0            0.0            0.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0            0.0            0.0            0.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_10_sum  quality_11_sum  quality_12_sum  err_31_0  err_31_1  \\\n",
       "10000           144.0             0.0             0.0       0.0       0.0   \n",
       "10001             0.0             0.0             0.0     126.0     124.0   \n",
       "10002           372.0            -2.0             0.0       0.0       0.0   \n",
       "10003             0.0             0.0             0.0      33.0      32.0   \n",
       "10004            48.0            -2.0             0.0      95.0      81.0   \n",
       "...               ...             ...             ...       ...       ...   \n",
       "24995            60.0           -10.0             0.0      18.0      13.0   \n",
       "24996             0.0             0.0             0.0       0.0       0.0   \n",
       "24997           228.0            -4.0             0.0     116.0     107.0   \n",
       "24998             0.0             0.0             0.0       9.0       5.0   \n",
       "24999             0.0             0.0             0.0       0.0       0.0   \n",
       "\n",
       "             mbm     AM      PM  \n",
       "10000   1.892744  224.0    93.0  \n",
       "10001  18.418605  433.0  1932.0  \n",
       "10002   1.666667  148.0   158.0  \n",
       "10003   2.352941  189.0   117.0  \n",
       "10004   3.938224  321.0   456.0  \n",
       "...          ...    ...     ...  \n",
       "24995   4.639175   68.0   126.0  \n",
       "24996  30.000000    0.0     4.0  \n",
       "24997   2.324455  483.0   343.0  \n",
       "24998   7.161290   96.0    59.0  \n",
       "24999   1.578947  350.0   220.0  \n",
       "\n",
       "[15000 rows x 122 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et_1</th>\n",
       "      <th>et_2</th>\n",
       "      <th>et_3</th>\n",
       "      <th>et_5</th>\n",
       "      <th>et_6</th>\n",
       "      <th>et_7</th>\n",
       "      <th>et_8</th>\n",
       "      <th>et_9</th>\n",
       "      <th>et_10</th>\n",
       "      <th>et_11</th>\n",
       "      <th>et_12</th>\n",
       "      <th>et_13</th>\n",
       "      <th>et_14</th>\n",
       "      <th>et_15</th>\n",
       "      <th>et_16</th>\n",
       "      <th>et_17</th>\n",
       "      <th>et_18</th>\n",
       "      <th>et_19</th>\n",
       "      <th>et_21</th>\n",
       "      <th>et_22</th>\n",
       "      <th>et_23</th>\n",
       "      <th>et_24</th>\n",
       "      <th>et_25</th>\n",
       "      <th>et_26</th>\n",
       "      <th>et_27</th>\n",
       "      <th>et_28</th>\n",
       "      <th>et_30</th>\n",
       "      <th>et_31</th>\n",
       "      <th>et_32</th>\n",
       "      <th>et_33</th>\n",
       "      <th>et_34</th>\n",
       "      <th>et_35</th>\n",
       "      <th>et_37</th>\n",
       "      <th>et_38</th>\n",
       "      <th>et_39</th>\n",
       "      <th>et_40</th>\n",
       "      <th>et_41</th>\n",
       "      <th>et_42</th>\n",
       "      <th>errcode</th>\n",
       "      <th>fwver</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>q_std_0</th>\n",
       "      <th>q_std_1</th>\n",
       "      <th>q_std_2</th>\n",
       "      <th>q_std_5</th>\n",
       "      <th>q_std_6</th>\n",
       "      <th>q_std_7</th>\n",
       "      <th>q_std_8</th>\n",
       "      <th>q_std_9</th>\n",
       "      <th>q_std_10</th>\n",
       "      <th>q_std_11</th>\n",
       "      <th>q_std_12</th>\n",
       "      <th>time</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>connLMP</th>\n",
       "      <th>connESTA</th>\n",
       "      <th>connTO</th>\n",
       "      <th>connLOCAL</th>\n",
       "      <th>STANDBY</th>\n",
       "      <th>TERMINATE</th>\n",
       "      <th>err_33_1</th>\n",
       "      <th>err_33_2</th>\n",
       "      <th>err_33_3</th>\n",
       "      <th>err_34_1</th>\n",
       "      <th>err_34_2</th>\n",
       "      <th>err_34_3</th>\n",
       "      <th>err_34_4</th>\n",
       "      <th>err_34_5</th>\n",
       "      <th>err_34_6</th>\n",
       "      <th>q_c_0</th>\n",
       "      <th>q_c_1</th>\n",
       "      <th>q_c_2</th>\n",
       "      <th>q_c_5</th>\n",
       "      <th>q_c_6</th>\n",
       "      <th>q_c_7</th>\n",
       "      <th>q_c_8</th>\n",
       "      <th>q_c_9</th>\n",
       "      <th>q_c_10</th>\n",
       "      <th>q_c_11</th>\n",
       "      <th>q_c_12</th>\n",
       "      <th>q_n_c_0</th>\n",
       "      <th>q_n_c_1</th>\n",
       "      <th>q_n_c_2</th>\n",
       "      <th>q_n_c_5</th>\n",
       "      <th>q_n_c_6</th>\n",
       "      <th>q_n_c_7</th>\n",
       "      <th>q_n_c_8</th>\n",
       "      <th>q_n_c_9</th>\n",
       "      <th>q_n_c_10</th>\n",
       "      <th>q_n_c_11</th>\n",
       "      <th>q_n_c_12</th>\n",
       "      <th>q_z_c_0</th>\n",
       "      <th>q_z_c_1</th>\n",
       "      <th>q_z_c_2</th>\n",
       "      <th>q_z_c_5</th>\n",
       "      <th>q_z_c_6</th>\n",
       "      <th>q_z_c_7</th>\n",
       "      <th>q_z_c_8</th>\n",
       "      <th>q_z_c_9</th>\n",
       "      <th>q_z_c_10</th>\n",
       "      <th>q_z_c_11</th>\n",
       "      <th>q_z_c_12</th>\n",
       "      <th>t_e_std</th>\n",
       "      <th>t_q_std</th>\n",
       "      <th>quality_0_sum</th>\n",
       "      <th>quality_1_sum</th>\n",
       "      <th>quality_2_sum</th>\n",
       "      <th>quality_5_sum</th>\n",
       "      <th>quality_6_sum</th>\n",
       "      <th>quality_7_sum</th>\n",
       "      <th>quality_8_sum</th>\n",
       "      <th>quality_9_sum</th>\n",
       "      <th>quality_10_sum</th>\n",
       "      <th>quality_11_sum</th>\n",
       "      <th>quality_12_sum</th>\n",
       "      <th>err_31_0</th>\n",
       "      <th>err_31_1</th>\n",
       "      <th>mbm</th>\n",
       "      <th>err_unique_errtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.793709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.043016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>760181.244016</td>\n",
       "      <td>91641.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.892744</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2365</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696650.374750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.418605</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251312</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>1.037404</td>\n",
       "      <td>4.495417</td>\n",
       "      <td>14.547924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>2.327185</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>727335.561994</td>\n",
       "      <td>842035.085798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759965.723107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>777</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.583592</td>\n",
       "      <td>17.778784</td>\n",
       "      <td>44.435591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>733973.687056</td>\n",
       "      <td>94186.623254</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.938224</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>289675.976562</td>\n",
       "      <td>10182.337649</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.639175</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>2.060234</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.661309</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>762270.100704</td>\n",
       "      <td>926592.726067</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.324455</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694269.089593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.161290</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>744259.010130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       et_1  et_2  et_3  et_5  et_6  et_7  et_8  et_9  et_10  et_11  et_12  \\\n",
       "10000   0.0   0.0   8.0   0.0   1.0   1.0   0.0   0.0    7.0   15.0   16.0   \n",
       "10001   0.0   0.0   0.0  53.0   1.0   1.0   0.0   0.0    0.0   10.0   11.0   \n",
       "10002   0.0   0.0   2.0   1.0   2.0   1.0   0.0   0.0    1.0   13.0   14.0   \n",
       "10003   0.0   0.0   0.0   2.0   1.0   1.0   0.0   0.0    0.0    9.0    9.0   \n",
       "10004   0.0   0.0   0.0   0.0   3.0   4.0   0.0   0.0    0.0   16.0   19.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...   \n",
       "24995   0.0   0.0   0.0   2.0   5.0   5.0   0.0   0.0    0.0    5.0   10.0   \n",
       "24996   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0    1.0   \n",
       "24997   0.0   0.0   0.0   8.0   1.0   1.0   0.0   0.0    0.0   16.0   18.0   \n",
       "24998   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   15.0   15.0   \n",
       "24999   0.0   0.0   4.0   7.0   5.0   4.0   0.0   0.0    0.0   15.0   19.0   \n",
       "\n",
       "       et_13  et_14  et_15  et_16  et_17  et_18  et_19  et_21  et_22  et_23  \\\n",
       "10000    1.0   10.0   59.0   61.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10001    1.0   15.0  151.0  128.0    0.0    4.0    1.0    1.0  756.0  751.0   \n",
       "10002    1.0    4.0   52.0   52.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10003    0.0    0.0   52.0   30.0    1.0    0.0    0.0    0.0   28.0   19.0   \n",
       "10004    3.0    5.0  143.0   91.0    0.0    0.0    0.0    0.0  140.0  119.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995    8.0    8.0   26.0   18.0    0.0    0.0    0.0    0.0   17.0   12.0   \n",
       "24996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997    4.0    1.0  181.0  138.0    0.0    0.0    0.0    0.0   50.0   29.0   \n",
       "24998    0.0    1.0   51.0   12.0    0.0    0.0    0.0    0.0    7.0    1.0   \n",
       "24999    4.0   20.0  135.0  135.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_24  et_25  et_26  et_27  et_28  et_30  et_31  et_32  et_33  et_34  \\\n",
       "10000    0.0    0.0   32.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10001    5.0    1.0   22.0    0.0    0.0    0.0  250.0    0.0   10.0   18.0   \n",
       "10002    2.0    0.0   25.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10003    0.0    0.0   59.0    0.0    0.0    0.0   65.0    0.0    8.0    0.0   \n",
       "10004    0.0    0.0   33.0    0.0    0.0    0.0  176.0    0.0   16.0    0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995    0.0    0.0   22.0    0.0    0.0    0.0   31.0    0.0    5.0    0.0   \n",
       "24996    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "24997    0.0    0.0   49.0    0.0    0.0    0.0  223.0    0.0   16.0   17.0   \n",
       "24998    0.0    0.0    4.0    0.0    0.0    0.0   14.0    0.0   15.0   12.0   \n",
       "24999    0.0    0.0   30.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_35  et_37  et_38  et_39  et_40  et_41  et_42  errcode  fwver  \\\n",
       "10000    0.0    0.0    0.0    0.0    0.0    0.0    0.0      317      1   \n",
       "10001    0.0    1.0    0.0    0.0  113.0   56.0    1.0     2365      2   \n",
       "10002    0.0    0.0    0.0    0.0    0.0    0.0    0.0      306      1   \n",
       "10003    0.0    1.0    2.0    0.0   17.0    1.0    0.0      306      2   \n",
       "10004    0.0    1.0    0.0    0.0    4.0    0.0    2.0      777      2   \n",
       "...      ...    ...    ...    ...    ...    ...    ...      ...    ...   \n",
       "24995    0.0    0.0    0.0    0.0    9.0    7.0    4.0      194      1   \n",
       "24996    0.0    0.0    0.0    0.0    0.0    0.0    0.0        4      1   \n",
       "24997    0.0    1.0    0.0    0.0   58.0    8.0    5.0      826      2   \n",
       "24998    0.0    1.0    0.0    0.0    6.0    0.0    0.0      155      2   \n",
       "24999    0.0    0.0    0.0    0.0    0.0    0.0    0.0      570      1   \n",
       "\n",
       "       model_nm   q_std_0   q_std_1   q_std_2   q_std_5    q_std_6    q_std_7  \\\n",
       "10000         1  0.000000  0.000000  0.000000  1.793709   0.000000   0.000000   \n",
       "10001         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10002         1  0.251312  0.143576  0.177396  1.037404   4.495417  14.547924   \n",
       "10003         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10004         1  0.282330  0.282330  0.282330  0.583592  17.778784  44.435591   \n",
       "...         ...       ...       ...       ...       ...        ...        ...   \n",
       "24995         1  0.503610  0.503610  0.503610  0.977093   0.503610   0.000000   \n",
       "24996         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24997         1  0.380693  0.380693  0.380693  2.060234   0.380693   0.000000   \n",
       "24998         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24999         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "       q_std_8   q_std_9  q_std_10  q_std_11  q_std_12  time  UNKNOWN  ACTIVE  \\\n",
       "10000      0.0  0.000000  2.043016  0.000000       0.0   2.0      0.0     0.0   \n",
       "10001      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0   126.0   \n",
       "10002      0.0  0.332455  2.327185  0.143576       0.0   8.0      0.0     0.0   \n",
       "10003      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0    12.0   \n",
       "10004      0.0  0.000000  1.021508  0.282330       0.0   2.0      0.0     7.0   \n",
       "...        ...       ...       ...       ...       ...   ...      ...     ...   \n",
       "24995      0.0  0.000000  0.510754  0.503610       0.0   2.0      0.0     4.0   \n",
       "24996      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "24997      0.0  0.000000  7.661309  0.380693       0.0   2.0      0.0     4.0   \n",
       "24998      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     1.0   \n",
       "24999      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "\n",
       "       connLMP  connESTA  connTO  connLOCAL  STANDBY  TERMINATE  err_33_1  \\\n",
       "10000      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10001      0.0       0.0     0.0        0.0    625.0        0.0       0.0   \n",
       "10002      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10003      0.0       0.0     7.0        0.0      0.0        0.0       1.0   \n",
       "10004      0.0       1.0   104.0        0.0      5.0        2.0       0.0   \n",
       "...        ...       ...     ...        ...      ...        ...       ...   \n",
       "24995      0.0       0.0     0.0        0.0      8.0        0.0       1.0   \n",
       "24996      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "24997      0.0       0.0    13.0        1.0     11.0        0.0       3.0   \n",
       "24998      0.0       0.0     0.0        0.0      0.0        0.0       2.0   \n",
       "24999      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "\n",
       "       err_33_2  err_33_3  err_34_1  err_34_2  err_34_3  err_34_4  err_34_5  \\\n",
       "10000       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10001       6.0       4.0       0.0       0.0       0.0      18.0       0.0   \n",
       "10002       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10003       3.0       4.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10004      14.0       2.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995       4.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24996       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24997      11.0       2.0       2.0       9.0       6.0       0.0       0.0   \n",
       "24998      12.0       1.0      11.0       0.0       0.0       1.0       0.0   \n",
       "24999       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       err_34_6  q_c_0  q_c_1  q_c_2  q_c_5  q_c_6  q_c_7  q_c_8  q_c_9  \\\n",
       "10000       0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0   \n",
       "10001       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10002       0.0    3.0    2.0    3.0   14.0    5.0   24.0    0.0   12.0   \n",
       "10003       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10004       0.0    2.0    2.0    2.0    5.0    3.0   12.0    0.0    0.0   \n",
       "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995       0.0   10.0   10.0   10.0   12.0   10.0    0.0    0.0    0.0   \n",
       "24996       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997       0.0    4.0    4.0    4.0   10.0    4.0    0.0    0.0    0.0   \n",
       "24998       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24999       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       q_c_10  q_c_11  q_c_12  q_n_c_0  q_n_c_1  q_n_c_2  q_n_c_5  q_n_c_6  \\\n",
       "10000    24.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10001     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002    84.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "10003     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004    24.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "...       ...     ...     ...      ...      ...      ...      ...      ...   \n",
       "24995    24.0    10.0     0.0     10.0     10.0     10.0     10.0     10.0   \n",
       "24996     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997    24.0     4.0     0.0      4.0      4.0      4.0      4.0      4.0   \n",
       "24998     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_n_c_7  q_n_c_8  q_n_c_9  q_n_c_10  q_n_c_11  q_n_c_12  q_z_c_0  \\\n",
       "10000      0.0      0.0      0.0       0.0       0.0       0.0     24.0   \n",
       "10001      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10002      0.0      0.0      0.0       0.0       2.0       0.0     93.0   \n",
       "10003      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10004      0.0      0.0      0.0       0.0       2.0       0.0     22.0   \n",
       "...        ...      ...      ...       ...       ...       ...      ...   \n",
       "24995      0.0      0.0      0.0       0.0      10.0       0.0     14.0   \n",
       "24996      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24997      0.0      0.0      0.0       0.0       4.0       0.0     20.0   \n",
       "24998      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24999      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "\n",
       "       q_z_c_1  q_z_c_2  q_z_c_5  q_z_c_6  q_z_c_7  q_z_c_8  q_z_c_9  \\\n",
       "10000     24.0     24.0     22.0     24.0     24.0     24.0     24.0   \n",
       "10001      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002     94.0     93.0     82.0     91.0     72.0     96.0     84.0   \n",
       "10003      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004     22.0     22.0     19.0     21.0     12.0     24.0     24.0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...   \n",
       "24995     14.0     14.0     12.0     14.0     24.0     24.0     24.0   \n",
       "24996      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997     20.0     20.0     14.0     20.0     24.0     24.0     24.0   \n",
       "24998      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_z_c_10  q_z_c_11  q_z_c_12        t_e_std        t_q_std  \\\n",
       "10000       0.0      24.0      24.0  760181.244016   91641.038842   \n",
       "10001       0.0       0.0       0.0  696650.374750       0.000000   \n",
       "10002      12.0      94.0      96.0  727335.561994  842035.085798   \n",
       "10003       0.0       0.0       0.0  759965.723107       0.000000   \n",
       "10004       0.0      22.0      24.0  733973.687056   94186.623254   \n",
       "...         ...       ...       ...            ...            ...   \n",
       "24995       0.0      14.0      24.0  289675.976562   10182.337649   \n",
       "24996       0.0       0.0       0.0       0.000000       0.000000   \n",
       "24997       0.0      20.0      24.0  762270.100704  926592.726067   \n",
       "24998       0.0       0.0       0.0  694269.089593       0.000000   \n",
       "24999       0.0       0.0       0.0  744259.010130       0.000000   \n",
       "\n",
       "       quality_0_sum  quality_1_sum  quality_2_sum  quality_5_sum  \\\n",
       "10000            0.0            0.0            0.0           12.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002            0.0           -2.0           -1.0           29.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           -2.0           -2.0           -2.0            2.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0          -10.0          -10.0           -5.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0           -4.0           -4.0           15.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_6_sum  quality_7_sum  quality_8_sum  quality_9_sum  \\\n",
       "10000            0.0            0.0            0.0            0.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002           44.0          552.0            0.0           12.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           85.0         1044.0            0.0            0.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0            0.0            0.0            0.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0            0.0            0.0            0.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_10_sum  quality_11_sum  quality_12_sum  err_31_0  err_31_1  \\\n",
       "10000           144.0             0.0             0.0       0.0       0.0   \n",
       "10001             0.0             0.0             0.0     126.0     124.0   \n",
       "10002           372.0            -2.0             0.0       0.0       0.0   \n",
       "10003             0.0             0.0             0.0      33.0      32.0   \n",
       "10004            48.0            -2.0             0.0      95.0      81.0   \n",
       "...               ...             ...             ...       ...       ...   \n",
       "24995            60.0           -10.0             0.0      18.0      13.0   \n",
       "24996             0.0             0.0             0.0       0.0       0.0   \n",
       "24997           228.0            -4.0             0.0     116.0     107.0   \n",
       "24998             0.0             0.0             0.0       9.0       5.0   \n",
       "24999             0.0             0.0             0.0       0.0       0.0   \n",
       "\n",
       "             mbm  err_unique_errtype  \n",
       "10000   1.892744                  14  \n",
       "10001  18.418605                  26  \n",
       "10002   1.666667                  16  \n",
       "10003   2.352941                  18  \n",
       "10004   3.938224                  18  \n",
       "...          ...                 ...  \n",
       "24995   4.639175                  17  \n",
       "24996  30.000000                   4  \n",
       "24997   2.324455                  21  \n",
       "24998   7.161290                  14  \n",
       "24999   1.578947                  12  \n",
       "\n",
       "[15000 rows x 120 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xX_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et_1</th>\n",
       "      <th>et_2</th>\n",
       "      <th>et_3</th>\n",
       "      <th>et_5</th>\n",
       "      <th>et_6</th>\n",
       "      <th>et_7</th>\n",
       "      <th>et_8</th>\n",
       "      <th>et_9</th>\n",
       "      <th>et_10</th>\n",
       "      <th>et_11</th>\n",
       "      <th>et_12</th>\n",
       "      <th>et_13</th>\n",
       "      <th>et_14</th>\n",
       "      <th>et_15</th>\n",
       "      <th>et_16</th>\n",
       "      <th>et_17</th>\n",
       "      <th>et_18</th>\n",
       "      <th>et_19</th>\n",
       "      <th>et_21</th>\n",
       "      <th>et_22</th>\n",
       "      <th>et_23</th>\n",
       "      <th>et_24</th>\n",
       "      <th>et_25</th>\n",
       "      <th>et_26</th>\n",
       "      <th>et_27</th>\n",
       "      <th>et_28</th>\n",
       "      <th>et_30</th>\n",
       "      <th>et_31</th>\n",
       "      <th>et_32</th>\n",
       "      <th>et_33</th>\n",
       "      <th>et_34</th>\n",
       "      <th>et_35</th>\n",
       "      <th>et_37</th>\n",
       "      <th>et_38</th>\n",
       "      <th>et_39</th>\n",
       "      <th>et_40</th>\n",
       "      <th>et_41</th>\n",
       "      <th>et_42</th>\n",
       "      <th>errcode</th>\n",
       "      <th>fwver</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>q_std_0</th>\n",
       "      <th>q_std_1</th>\n",
       "      <th>q_std_2</th>\n",
       "      <th>q_std_5</th>\n",
       "      <th>q_std_6</th>\n",
       "      <th>q_std_7</th>\n",
       "      <th>q_std_8</th>\n",
       "      <th>q_std_9</th>\n",
       "      <th>q_std_10</th>\n",
       "      <th>q_std_11</th>\n",
       "      <th>q_std_12</th>\n",
       "      <th>time</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>connLMP</th>\n",
       "      <th>connESTA</th>\n",
       "      <th>connTO</th>\n",
       "      <th>connLOCAL</th>\n",
       "      <th>STANDBY</th>\n",
       "      <th>TERMINATE</th>\n",
       "      <th>err_33_1</th>\n",
       "      <th>err_33_2</th>\n",
       "      <th>err_33_3</th>\n",
       "      <th>err_34_1</th>\n",
       "      <th>err_34_2</th>\n",
       "      <th>err_34_3</th>\n",
       "      <th>err_34_4</th>\n",
       "      <th>err_34_5</th>\n",
       "      <th>err_34_6</th>\n",
       "      <th>q_c_0</th>\n",
       "      <th>q_c_1</th>\n",
       "      <th>q_c_2</th>\n",
       "      <th>q_c_5</th>\n",
       "      <th>q_c_6</th>\n",
       "      <th>q_c_7</th>\n",
       "      <th>q_c_8</th>\n",
       "      <th>q_c_9</th>\n",
       "      <th>q_c_10</th>\n",
       "      <th>q_c_11</th>\n",
       "      <th>q_c_12</th>\n",
       "      <th>q_n_c_0</th>\n",
       "      <th>q_n_c_1</th>\n",
       "      <th>q_n_c_2</th>\n",
       "      <th>q_n_c_5</th>\n",
       "      <th>q_n_c_6</th>\n",
       "      <th>q_n_c_7</th>\n",
       "      <th>q_n_c_8</th>\n",
       "      <th>q_n_c_9</th>\n",
       "      <th>q_n_c_10</th>\n",
       "      <th>q_n_c_11</th>\n",
       "      <th>q_n_c_12</th>\n",
       "      <th>q_z_c_0</th>\n",
       "      <th>q_z_c_1</th>\n",
       "      <th>q_z_c_2</th>\n",
       "      <th>q_z_c_5</th>\n",
       "      <th>q_z_c_6</th>\n",
       "      <th>q_z_c_7</th>\n",
       "      <th>q_z_c_8</th>\n",
       "      <th>q_z_c_9</th>\n",
       "      <th>q_z_c_10</th>\n",
       "      <th>q_z_c_11</th>\n",
       "      <th>q_z_c_12</th>\n",
       "      <th>t_e_std</th>\n",
       "      <th>t_q_std</th>\n",
       "      <th>quality_0_sum</th>\n",
       "      <th>quality_1_sum</th>\n",
       "      <th>quality_2_sum</th>\n",
       "      <th>quality_5_sum</th>\n",
       "      <th>quality_6_sum</th>\n",
       "      <th>quality_7_sum</th>\n",
       "      <th>quality_8_sum</th>\n",
       "      <th>quality_9_sum</th>\n",
       "      <th>quality_10_sum</th>\n",
       "      <th>quality_11_sum</th>\n",
       "      <th>quality_12_sum</th>\n",
       "      <th>err_31_0</th>\n",
       "      <th>err_31_1</th>\n",
       "      <th>mbm</th>\n",
       "      <th>AM</th>\n",
       "      <th>PM</th>\n",
       "      <th>err_unique_errtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.793709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.043016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>760181.244016</td>\n",
       "      <td>91641.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.892744</td>\n",
       "      <td>224.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2365</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696650.374750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.418605</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251312</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>1.037404</td>\n",
       "      <td>4.495417</td>\n",
       "      <td>14.547924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>2.327185</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>727335.561994</td>\n",
       "      <td>842035.085798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>148.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759965.723107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>189.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>777</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.583592</td>\n",
       "      <td>17.778784</td>\n",
       "      <td>44.435591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>733973.687056</td>\n",
       "      <td>94186.623254</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.938224</td>\n",
       "      <td>321.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>289675.976562</td>\n",
       "      <td>10182.337649</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.639175</td>\n",
       "      <td>68.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>2.060234</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.661309</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>762270.100704</td>\n",
       "      <td>926592.726067</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.324455</td>\n",
       "      <td>483.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694269.089593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.161290</td>\n",
       "      <td>96.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>744259.010130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>350.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       et_1  et_2  et_3  et_5  et_6  et_7  et_8  et_9  et_10  et_11  et_12  \\\n",
       "10000   0.0   0.0   8.0   0.0   1.0   1.0   0.0   0.0    7.0   15.0   16.0   \n",
       "10001   0.0   0.0   0.0  53.0   1.0   1.0   0.0   0.0    0.0   10.0   11.0   \n",
       "10002   0.0   0.0   2.0   1.0   2.0   1.0   0.0   0.0    1.0   13.0   14.0   \n",
       "10003   0.0   0.0   0.0   2.0   1.0   1.0   0.0   0.0    0.0    9.0    9.0   \n",
       "10004   0.0   0.0   0.0   0.0   3.0   4.0   0.0   0.0    0.0   16.0   19.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...   \n",
       "24995   0.0   0.0   0.0   2.0   5.0   5.0   0.0   0.0    0.0    5.0   10.0   \n",
       "24996   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0    1.0   \n",
       "24997   0.0   0.0   0.0   8.0   1.0   1.0   0.0   0.0    0.0   16.0   18.0   \n",
       "24998   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   15.0   15.0   \n",
       "24999   0.0   0.0   4.0   7.0   5.0   4.0   0.0   0.0    0.0   15.0   19.0   \n",
       "\n",
       "       et_13  et_14  et_15  et_16  et_17  et_18  et_19  et_21  et_22  et_23  \\\n",
       "10000    1.0   10.0   59.0   61.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10001    1.0   15.0  151.0  128.0    0.0    4.0    1.0    1.0  756.0  751.0   \n",
       "10002    1.0    4.0   52.0   52.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10003    0.0    0.0   52.0   30.0    1.0    0.0    0.0    0.0   28.0   19.0   \n",
       "10004    3.0    5.0  143.0   91.0    0.0    0.0    0.0    0.0  140.0  119.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995    8.0    8.0   26.0   18.0    0.0    0.0    0.0    0.0   17.0   12.0   \n",
       "24996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997    4.0    1.0  181.0  138.0    0.0    0.0    0.0    0.0   50.0   29.0   \n",
       "24998    0.0    1.0   51.0   12.0    0.0    0.0    0.0    0.0    7.0    1.0   \n",
       "24999    4.0   20.0  135.0  135.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_24  et_25  et_26  et_27  et_28  et_30  et_31  et_32  et_33  et_34  \\\n",
       "10000    0.0    0.0   32.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10001    5.0    1.0   22.0    0.0    0.0    0.0  250.0    0.0   10.0   18.0   \n",
       "10002    2.0    0.0   25.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10003    0.0    0.0   59.0    0.0    0.0    0.0   65.0    0.0    8.0    0.0   \n",
       "10004    0.0    0.0   33.0    0.0    0.0    0.0  176.0    0.0   16.0    0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995    0.0    0.0   22.0    0.0    0.0    0.0   31.0    0.0    5.0    0.0   \n",
       "24996    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "24997    0.0    0.0   49.0    0.0    0.0    0.0  223.0    0.0   16.0   17.0   \n",
       "24998    0.0    0.0    4.0    0.0    0.0    0.0   14.0    0.0   15.0   12.0   \n",
       "24999    0.0    0.0   30.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       et_35  et_37  et_38  et_39  et_40  et_41  et_42  errcode  fwver  \\\n",
       "10000    0.0    0.0    0.0    0.0    0.0    0.0    0.0      317      1   \n",
       "10001    0.0    1.0    0.0    0.0  113.0   56.0    1.0     2365      2   \n",
       "10002    0.0    0.0    0.0    0.0    0.0    0.0    0.0      306      1   \n",
       "10003    0.0    1.0    2.0    0.0   17.0    1.0    0.0      306      2   \n",
       "10004    0.0    1.0    0.0    0.0    4.0    0.0    2.0      777      2   \n",
       "...      ...    ...    ...    ...    ...    ...    ...      ...    ...   \n",
       "24995    0.0    0.0    0.0    0.0    9.0    7.0    4.0      194      1   \n",
       "24996    0.0    0.0    0.0    0.0    0.0    0.0    0.0        4      1   \n",
       "24997    0.0    1.0    0.0    0.0   58.0    8.0    5.0      826      2   \n",
       "24998    0.0    1.0    0.0    0.0    6.0    0.0    0.0      155      2   \n",
       "24999    0.0    0.0    0.0    0.0    0.0    0.0    0.0      570      1   \n",
       "\n",
       "       model_nm   q_std_0   q_std_1   q_std_2   q_std_5    q_std_6    q_std_7  \\\n",
       "10000         1  0.000000  0.000000  0.000000  1.793709   0.000000   0.000000   \n",
       "10001         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10002         1  0.251312  0.143576  0.177396  1.037404   4.495417  14.547924   \n",
       "10003         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10004         1  0.282330  0.282330  0.282330  0.583592  17.778784  44.435591   \n",
       "...         ...       ...       ...       ...       ...        ...        ...   \n",
       "24995         1  0.503610  0.503610  0.503610  0.977093   0.503610   0.000000   \n",
       "24996         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24997         1  0.380693  0.380693  0.380693  2.060234   0.380693   0.000000   \n",
       "24998         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "24999         1  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "       q_std_8   q_std_9  q_std_10  q_std_11  q_std_12  time  UNKNOWN  ACTIVE  \\\n",
       "10000      0.0  0.000000  2.043016  0.000000       0.0   2.0      0.0     0.0   \n",
       "10001      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0   126.0   \n",
       "10002      0.0  0.332455  2.327185  0.143576       0.0   8.0      0.0     0.0   \n",
       "10003      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0    12.0   \n",
       "10004      0.0  0.000000  1.021508  0.282330       0.0   2.0      0.0     7.0   \n",
       "...        ...       ...       ...       ...       ...   ...      ...     ...   \n",
       "24995      0.0  0.000000  0.510754  0.503610       0.0   2.0      0.0     4.0   \n",
       "24996      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "24997      0.0  0.000000  7.661309  0.380693       0.0   2.0      0.0     4.0   \n",
       "24998      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     1.0   \n",
       "24999      0.0  0.000000  0.000000  0.000000       0.0   0.0      0.0     0.0   \n",
       "\n",
       "       connLMP  connESTA  connTO  connLOCAL  STANDBY  TERMINATE  err_33_1  \\\n",
       "10000      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10001      0.0       0.0     0.0        0.0    625.0        0.0       0.0   \n",
       "10002      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "10003      0.0       0.0     7.0        0.0      0.0        0.0       1.0   \n",
       "10004      0.0       1.0   104.0        0.0      5.0        2.0       0.0   \n",
       "...        ...       ...     ...        ...      ...        ...       ...   \n",
       "24995      0.0       0.0     0.0        0.0      8.0        0.0       1.0   \n",
       "24996      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "24997      0.0       0.0    13.0        1.0     11.0        0.0       3.0   \n",
       "24998      0.0       0.0     0.0        0.0      0.0        0.0       2.0   \n",
       "24999      0.0       0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "\n",
       "       err_33_2  err_33_3  err_34_1  err_34_2  err_34_3  err_34_4  err_34_5  \\\n",
       "10000       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10001       6.0       4.0       0.0       0.0       0.0      18.0       0.0   \n",
       "10002       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10003       3.0       4.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10004      14.0       2.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995       4.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24996       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24997      11.0       2.0       2.0       9.0       6.0       0.0       0.0   \n",
       "24998      12.0       1.0      11.0       0.0       0.0       1.0       0.0   \n",
       "24999       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       err_34_6  q_c_0  q_c_1  q_c_2  q_c_5  q_c_6  q_c_7  q_c_8  q_c_9  \\\n",
       "10000       0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0   \n",
       "10001       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10002       0.0    3.0    2.0    3.0   14.0    5.0   24.0    0.0   12.0   \n",
       "10003       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10004       0.0    2.0    2.0    2.0    5.0    3.0   12.0    0.0    0.0   \n",
       "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24995       0.0   10.0   10.0   10.0   12.0   10.0    0.0    0.0    0.0   \n",
       "24996       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24997       0.0    4.0    4.0    4.0   10.0    4.0    0.0    0.0    0.0   \n",
       "24998       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24999       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       q_c_10  q_c_11  q_c_12  q_n_c_0  q_n_c_1  q_n_c_2  q_n_c_5  q_n_c_6  \\\n",
       "10000    24.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10001     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002    84.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "10003     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004    24.0     2.0     0.0      2.0      2.0      2.0      2.0      2.0   \n",
       "...       ...     ...     ...      ...      ...      ...      ...      ...   \n",
       "24995    24.0    10.0     0.0     10.0     10.0     10.0     10.0     10.0   \n",
       "24996     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997    24.0     4.0     0.0      4.0      4.0      4.0      4.0      4.0   \n",
       "24998     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_n_c_7  q_n_c_8  q_n_c_9  q_n_c_10  q_n_c_11  q_n_c_12  q_z_c_0  \\\n",
       "10000      0.0      0.0      0.0       0.0       0.0       0.0     24.0   \n",
       "10001      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10002      0.0      0.0      0.0       0.0       2.0       0.0     93.0   \n",
       "10003      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "10004      0.0      0.0      0.0       0.0       2.0       0.0     22.0   \n",
       "...        ...      ...      ...       ...       ...       ...      ...   \n",
       "24995      0.0      0.0      0.0       0.0      10.0       0.0     14.0   \n",
       "24996      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24997      0.0      0.0      0.0       0.0       4.0       0.0     20.0   \n",
       "24998      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "24999      0.0      0.0      0.0       0.0       0.0       0.0      0.0   \n",
       "\n",
       "       q_z_c_1  q_z_c_2  q_z_c_5  q_z_c_6  q_z_c_7  q_z_c_8  q_z_c_9  \\\n",
       "10000     24.0     24.0     22.0     24.0     24.0     24.0     24.0   \n",
       "10001      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10002     94.0     93.0     82.0     91.0     72.0     96.0     84.0   \n",
       "10003      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10004     22.0     22.0     19.0     21.0     12.0     24.0     24.0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...   \n",
       "24995     14.0     14.0     12.0     14.0     24.0     24.0     24.0   \n",
       "24996      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24997     20.0     20.0     14.0     20.0     24.0     24.0     24.0   \n",
       "24998      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24999      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       q_z_c_10  q_z_c_11  q_z_c_12        t_e_std        t_q_std  \\\n",
       "10000       0.0      24.0      24.0  760181.244016   91641.038842   \n",
       "10001       0.0       0.0       0.0  696650.374750       0.000000   \n",
       "10002      12.0      94.0      96.0  727335.561994  842035.085798   \n",
       "10003       0.0       0.0       0.0  759965.723107       0.000000   \n",
       "10004       0.0      22.0      24.0  733973.687056   94186.623254   \n",
       "...         ...       ...       ...            ...            ...   \n",
       "24995       0.0      14.0      24.0  289675.976562   10182.337649   \n",
       "24996       0.0       0.0       0.0       0.000000       0.000000   \n",
       "24997       0.0      20.0      24.0  762270.100704  926592.726067   \n",
       "24998       0.0       0.0       0.0  694269.089593       0.000000   \n",
       "24999       0.0       0.0       0.0  744259.010130       0.000000   \n",
       "\n",
       "       quality_0_sum  quality_1_sum  quality_2_sum  quality_5_sum  \\\n",
       "10000            0.0            0.0            0.0           12.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002            0.0           -2.0           -1.0           29.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           -2.0           -2.0           -2.0            2.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0          -10.0          -10.0           -5.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0           -4.0           -4.0           15.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_6_sum  quality_7_sum  quality_8_sum  quality_9_sum  \\\n",
       "10000            0.0            0.0            0.0            0.0   \n",
       "10001            0.0            0.0            0.0            0.0   \n",
       "10002           44.0          552.0            0.0           12.0   \n",
       "10003            0.0            0.0            0.0            0.0   \n",
       "10004           85.0         1044.0            0.0            0.0   \n",
       "...              ...            ...            ...            ...   \n",
       "24995          -10.0            0.0            0.0            0.0   \n",
       "24996            0.0            0.0            0.0            0.0   \n",
       "24997           -4.0            0.0            0.0            0.0   \n",
       "24998            0.0            0.0            0.0            0.0   \n",
       "24999            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       quality_10_sum  quality_11_sum  quality_12_sum  err_31_0  err_31_1  \\\n",
       "10000           144.0             0.0             0.0       0.0       0.0   \n",
       "10001             0.0             0.0             0.0     126.0     124.0   \n",
       "10002           372.0            -2.0             0.0       0.0       0.0   \n",
       "10003             0.0             0.0             0.0      33.0      32.0   \n",
       "10004            48.0            -2.0             0.0      95.0      81.0   \n",
       "...               ...             ...             ...       ...       ...   \n",
       "24995            60.0           -10.0             0.0      18.0      13.0   \n",
       "24996             0.0             0.0             0.0       0.0       0.0   \n",
       "24997           228.0            -4.0             0.0     116.0     107.0   \n",
       "24998             0.0             0.0             0.0       9.0       5.0   \n",
       "24999             0.0             0.0             0.0       0.0       0.0   \n",
       "\n",
       "             mbm     AM      PM  err_unique_errtype  \n",
       "10000   1.892744  224.0    93.0                  14  \n",
       "10001  18.418605  433.0  1932.0                  26  \n",
       "10002   1.666667  148.0   158.0                  16  \n",
       "10003   2.352941  189.0   117.0                  18  \n",
       "10004   3.938224  321.0   456.0                  18  \n",
       "...          ...    ...     ...                 ...  \n",
       "24995   4.639175   68.0   126.0                  17  \n",
       "24996  30.000000    0.0     4.0                   4  \n",
       "24997   2.324455  483.0   343.0                  21  \n",
       "24998   7.161290   96.0    59.0                  14  \n",
       "24999   1.578947  350.0   220.0                  12  \n",
       "\n",
       "[15000 rows x 122 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'nan_mode': 'Min',\n",
    "        'eval_metric': 'Logloss',\n",
    "        'iterations': 10000,\n",
    "        'sampling_frequency': 'PerTree',\n",
    "        'leaf_estimation_method': 'Newton',\n",
    "        'grow_policy': 'SymmetricTree',\n",
    "        'penalties_coefficient': 1,\n",
    "        'boosting_type': 'Plain',\n",
    "        'model_shrink_mode': 'Constant',\n",
    "        'feature_border_type': 'GreedyLogSum',\n",
    "        'l2_leaf_reg': 3,\n",
    "        'random_strength': 1,\n",
    "        'rsm': 1,\n",
    "        'boost_from_average': False,\n",
    "        'model_size_reg': 0.5,\n",
    "        'subsample': 0.800000011920929,\n",
    "        'use_best_model': False,\n",
    "        'class_names': [0, 1],\n",
    "        'random_seed': 2584,\n",
    "        'depth': 6,\n",
    "        'posterior_sampling': False,\n",
    "        'border_count': 254,\n",
    "        'classes_count': 0,\n",
    "        'auto_class_weights': 'None',\n",
    "        'sparse_features_conflict_fraction': 0,\n",
    "        'leaf_estimation_backtracking': 'AnyImprovement',\n",
    "        'best_model_min_trees': 1,\n",
    "        'model_shrink_rate': 0,\n",
    "        'min_data_in_leaf': 1,\n",
    "        'loss_function': 'Logloss',\n",
    "        'learning_rate': 0.028116999194025993,\n",
    "        'score_function': 'Cosine',\n",
    "        'task_type': 'CPU',\n",
    "        'leaf_estimation_iterations': 10,\n",
    "        'bootstrap_type': 'MVS',\n",
    "        'max_leaves': 64\n",
    "        }\n",
    "\n",
    "catb = CatBoostClassifier(**params, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catb_fold_train_pred(train_x, train_y, N_SPLIT=5):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=N_SPLIT, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = catb\n",
    "        model.fit(X, y,\n",
    "                  eval_set=(valid_x, valid_y),\n",
    "                  early_stopping_rounds = 300)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이터레이션 10000, 얼리스토핑 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7338\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = catb_fold_train_pred(X_temp, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y_temp)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_catb = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91969449],\n",
       "       [0.23163335],\n",
       "       [0.51476496],\n",
       "       ...,\n",
       "       [0.68887411],\n",
       "       [0.9339568 ],\n",
       "       [0.41309126]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_catb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 lgbm\n",
    "def lgbm_fold_train_pred(train_x, train_y, N_SPLIT=5):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'boosting_type':'gbdt', \n",
    "                    'class_weight':None,\n",
    "                    'colsample_bytree':1.0,\n",
    "                    'importance_type':'split',\n",
    "                    'learning_rate':0.1,\n",
    "                    'max_depth':-1,\n",
    "                    'min_child_samples':20,\n",
    "                    'min_child_weight':0.001,\n",
    "                    'min_split_gain':0.0,\n",
    "                    'n_estimators':100,\n",
    "                    'n_jobs':-1,\n",
    "                    'num_leaves':31,\n",
    "                    'objective':None,\n",
    "                    'random_state':2584,\n",
    "                    'reg_alpha':0.0,\n",
    "                    'reg_lambda':0.0,\n",
    "                    'silent':True,\n",
    "                    'subsample':1.0,\n",
    "                    'subsample_for_bin':200000,\n",
    "                    'subsample_freq':0\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=N_SPLIT, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73565\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = lgbm_fold_train_pred(X, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_lgbm = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93819144],\n",
       "       [0.24549661],\n",
       "       [0.44315962],\n",
       "       ...,\n",
       "       [0.76825373],\n",
       "       [0.90830821],\n",
       "       [0.42843415]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned NGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngbc = NGBClassifier(\n",
    "                        Dist = k_categorical(2),\n",
    "                        n_estimators = 10000,\n",
    "                        learning_rate = 0.027,\n",
    "                        random_state=42\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngb_fold_train_pred(train_x, train_y, N_SPLIT=5):\n",
    "\n",
    "    models = []\n",
    "    recalls = []\n",
    "    precisions =[]\n",
    "    auc_scores = []\n",
    "    threshold = 0.5\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=42)\n",
    "    \n",
    "    ngbc = NGBClassifier(\n",
    "                        Dist = k_categorical(2),\n",
    "                        n_estimators = 10000,\n",
    "                        learning_rate = 0.027,\n",
    "                        random_state = 42,\n",
    "                        col_sample = 0.6780,\n",
    "                        minibatch_frac = 0.92069\n",
    "                    )\n",
    "    \n",
    "    for train_idx, val_idx in k_fold.split(train_x, train_y):\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx].astype(np.int)\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx].astype(np.int)\n",
    "\n",
    "        model = ngbc\n",
    "        \n",
    "        model.fit(X, y,\n",
    "                  X_val=valid_x, Y_val = valid_y,\n",
    "                  early_stopping_rounds = 100)\n",
    "        \n",
    "        valid_prob = model.predict_proba(valid_x)[:,1]\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        recall = recall_score(valid_y, valid_pred)\n",
    "        precision = precision_score(valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(valid_y, valid_prob)\n",
    "\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ngb_fold_train_pred(train_x, train_y, N_SPLIT=5):\n",
    "\n",
    "    models = []\n",
    "    recalls = []\n",
    "    precisions =[]\n",
    "    auc_scores = []\n",
    "    threshold = 0.5\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=42)\n",
    "    \n",
    "    ngbc = NGBClassifier(\n",
    "                        Dist = k_categorical(2),\n",
    "                        n_estimators = 1000,\n",
    "                        learning_rate = 0.02,\n",
    "                        random_state = 41\n",
    "                    )\n",
    "    \n",
    "    for train_idx, val_idx in k_fold.split(train_x, train_y):\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx].astype(np.int)\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx].astype(np.int)\n",
    "\n",
    "        model = ngbc\n",
    "        \n",
    "        model.fit(X, y,\n",
    "                  X_val=valid_x, Y_val = valid_y,\n",
    "                  early_stopping_rounds = 3)\n",
    "        \n",
    "        valid_prob = model.predict_proba(valid_x)[:,1]\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        recall = recall_score(valid_y, valid_pred)\n",
    "        precision = precision_score(valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(valid_y, valid_prob)\n",
    "\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6217 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4556 val_loss=0.4607 scale=2.0000 norm=3.7075\n",
      "[iter 200] loss=0.4453 val_loss=0.4605 scale=1.0000 norm=1.8792\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL138 (val_loss=0.4590)\n",
      "[iter 0] loss=0.4450 val_loss=0.4535 scale=0.2500 norm=0.4829\n",
      "[iter 100] loss=0.4395 val_loss=0.4545 scale=2.0000 norm=3.8185\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1 (val_loss=0.4535)\n",
      "[iter 0] loss=0.4434 val_loss=0.4183 scale=2.0000 norm=3.8558\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4183)\n",
      "[iter 0] loss=0.4399 val_loss=0.4312 scale=1.0000 norm=1.9124\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4312)\n",
      "[iter 0] loss=0.4370 val_loss=0.4327 scale=0.5000 norm=0.9676\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4327)\n",
      "[iter 0] loss=0.4354 val_loss=0.4294 scale=1.0000 norm=1.9080\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4294)\n",
      "[iter 0] loss=0.4349 val_loss=0.4235 scale=1.0000 norm=1.9077\n",
      "[iter 100] loss=0.4347 val_loss=0.4236 scale=0.0020 norm=0.0037\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL3 (val_loss=0.4234)\n",
      "[iter 0] loss=0.4339 val_loss=0.4308 scale=1.0000 norm=1.9046\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4308)\n",
      "[iter 0] loss=0.4305 val_loss=0.4577 scale=1.0000 norm=1.8920\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4577)\n",
      "[iter 0] loss=0.4324 val_loss=0.4354 scale=1.0000 norm=1.9046\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4354)\n",
      "0.8397829000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp2, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6218 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4563 val_loss=0.4633 scale=1.0000 norm=1.8548\n",
      "[iter 200] loss=0.4474 val_loss=0.4631 scale=1.0000 norm=1.8769\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL133 (val_loss=0.4621)\n",
      "[iter 0] loss=0.4477 val_loss=0.4540 scale=1.0000 norm=1.9126\n",
      "[iter 100] loss=0.4410 val_loss=0.4535 scale=0.5000 norm=0.9495\n",
      "[iter 200] loss=0.4382 val_loss=0.4541 scale=0.5000 norm=0.9494\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL109 (val_loss=0.4534)\n",
      "[iter 0] loss=0.4421 val_loss=0.4182 scale=1.0000 norm=1.9185\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4182)\n",
      "[iter 0] loss=0.4394 val_loss=0.4294 scale=0.2500 norm=0.4789\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4294)\n",
      "[iter 0] loss=0.4366 val_loss=0.4365 scale=1.0000 norm=1.9179\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4365)\n",
      "[iter 0] loss=0.4361 val_loss=0.4294 scale=0.5000 norm=0.9564\n",
      "[iter 100] loss=0.4351 val_loss=0.4301 scale=0.1250 norm=0.2378\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL4 (val_loss=0.4294)\n",
      "[iter 0] loss=0.4358 val_loss=0.4235 scale=1.0000 norm=1.9021\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4235)\n",
      "[iter 0] loss=0.4345 val_loss=0.4325 scale=1.0000 norm=1.8999\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4325)\n",
      "[iter 0] loss=0.4314 val_loss=0.4591 scale=1.0000 norm=1.8917\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4591)\n",
      "[iter 0] loss=0.4333 val_loss=0.4351 scale=4.0000 norm=7.6329\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4351)\n",
      "0.8392508\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp3, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6226 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4556 val_loss=0.4722 scale=2.0000 norm=3.7185\n",
      "[iter 200] loss=0.4452 val_loss=0.4724 scale=2.0000 norm=3.7581\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL148 (val_loss=0.4713)\n",
      "[iter 0] loss=0.4533 val_loss=0.4336 scale=1.0000 norm=2.0958\n",
      "[iter 100] loss=0.4435 val_loss=0.4349 scale=1.0000 norm=1.9048\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL30 (val_loss=0.4330)\n",
      "[iter 0] loss=0.4430 val_loss=0.4335 scale=0.2500 norm=0.5009\n",
      "[iter 100] loss=0.4378 val_loss=0.4363 scale=0.5000 norm=0.9514\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL14 (val_loss=0.4334)\n",
      "[iter 0] loss=0.4395 val_loss=0.4291 scale=0.5000 norm=0.9660\n",
      "[iter 100] loss=0.4366 val_loss=0.4295 scale=0.0010 norm=0.0019\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL5 (val_loss=0.4291)\n",
      "[iter 0] loss=0.4326 val_loss=0.4456 scale=1.0000 norm=1.9054\n",
      "[iter 100] loss=0.4306 val_loss=0.4462 scale=0.0010 norm=0.0019\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL2 (val_loss=0.4456)\n",
      "0.8365167000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp2, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6227 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4547 val_loss=0.4730 scale=1.0000 norm=1.8514\n",
      "[iter 200] loss=0.4465 val_loss=0.4724 scale=0.0010 norm=0.0018\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL138 (val_loss=0.4716)\n",
      "[iter 0] loss=0.4555 val_loss=0.4361 scale=0.5000 norm=0.9728\n",
      "[iter 100] loss=0.4456 val_loss=0.4371 scale=1.0000 norm=1.9028\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL39 (val_loss=0.4356)\n",
      "[iter 0] loss=0.4450 val_loss=0.4365 scale=0.1250 norm=0.2607\n",
      "[iter 100] loss=0.4395 val_loss=0.4405 scale=0.5000 norm=0.9533\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL16 (val_loss=0.4364)\n",
      "[iter 0] loss=0.4415 val_loss=0.4296 scale=0.2500 norm=0.4861\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4296)\n",
      "[iter 0] loss=0.4339 val_loss=0.4465 scale=1.0000 norm=1.9034\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4465)\n",
      "0.8350595000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp3, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이터레이션 증가, 얼리스토핑 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6366 val_loss=0.6225 scale=2.0000 norm=4.0002\n",
      "[iter 100] loss=0.4543 val_loss=0.4596 scale=1.0000 norm=1.8490\n",
      "[iter 200] loss=0.4426 val_loss=0.4563 scale=1.0000 norm=1.8717\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL179 (val_loss=0.4561)\n",
      "[iter 0] loss=0.4417 val_loss=0.4442 scale=0.2500 norm=0.4854\n",
      "[iter 100] loss=0.4330 val_loss=0.4441 scale=1.0000 norm=1.8900\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL59 (val_loss=0.4440)\n",
      "[iter 0] loss=0.4375 val_loss=0.4093 scale=0.5000 norm=0.9573\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4093)\n",
      "[iter 0] loss=0.4277 val_loss=0.4194 scale=0.5000 norm=0.9386\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4194)\n",
      "[iter 0] loss=0.4265 val_loss=0.4263 scale=0.1250 norm=0.2388\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4263)\n",
      "[iter 0] loss=0.4281 val_loss=0.4214 scale=0.5000 norm=0.9495\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4214)\n",
      "[iter 0] loss=0.4276 val_loss=0.4152 scale=0.5000 norm=0.9478\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4152)\n",
      "[iter 0] loss=0.4230 val_loss=0.4222 scale=1.0000 norm=1.8891\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4222)\n",
      "[iter 0] loss=0.4190 val_loss=0.4441 scale=0.5000 norm=0.9380\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4441)\n",
      "[iter 0] loss=0.4218 val_loss=0.4259 scale=1.0000 norm=1.8854\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4259)\n",
      "0.8465338000000001\n"
     ]
    }
   ],
   "source": [
    "# 최고최고최고최괴최괴ㅚ괴최괴고치ㅚ괴최괴\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6366 val_loss=0.6226 scale=2.0000 norm=4.0002\n",
      "[iter 100] loss=0.4551 val_loss=0.4609 scale=1.0000 norm=1.8467\n",
      "[iter 200] loss=0.4415 val_loss=0.4578 scale=0.5000 norm=0.9347\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL172 (val_loss=0.4571)\n",
      "[iter 0] loss=0.4386 val_loss=0.4447 scale=0.2500 norm=0.4736\n",
      "[iter 100] loss=0.4323 val_loss=0.4445 scale=2.0000 norm=3.7631\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL33 (val_loss=0.4439)\n",
      "[iter 0] loss=0.4353 val_loss=0.4120 scale=0.5000 norm=0.9468\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4120)\n",
      "[iter 0] loss=0.4329 val_loss=0.4205 scale=1.0000 norm=1.8872\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4205)\n",
      "[iter 0] loss=0.4281 val_loss=0.4292 scale=0.2500 norm=0.4760\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4292)\n",
      "[iter 0] loss=0.4274 val_loss=0.4215 scale=0.5000 norm=0.9407\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4215)\n",
      "[iter 0] loss=0.4253 val_loss=0.4151 scale=0.5000 norm=0.9414\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4151)\n",
      "[iter 0] loss=0.4257 val_loss=0.4227 scale=0.5000 norm=0.9453\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4227)\n",
      "[iter 0] loss=0.4208 val_loss=0.4459 scale=1.0000 norm=1.8724\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4459)\n",
      "[iter 0] loss=0.4223 val_loss=0.4259 scale=0.5000 norm=0.9415\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4259)\n",
      "0.8452387\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6232 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4544 val_loss=0.4690 scale=1.0000 norm=1.8452\n",
      "[iter 200] loss=0.4437 val_loss=0.4680 scale=1.0000 norm=1.8708\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL144 (val_loss=0.4673)\n",
      "[iter 0] loss=0.4515 val_loss=0.4300 scale=0.2500 norm=0.5121\n",
      "[iter 100] loss=0.4428 val_loss=0.4320 scale=0.5000 norm=0.9536\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL11 (val_loss=0.4300)\n",
      "[iter 0] loss=0.4416 val_loss=0.4351 scale=0.2500 norm=0.4923\n",
      "[iter 100] loss=0.4368 val_loss=0.4379 scale=0.5000 norm=0.9513\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL3 (val_loss=0.4351)\n",
      "[iter 0] loss=0.4391 val_loss=0.4287 scale=1.0000 norm=1.9265\n",
      "[iter 100] loss=0.4357 val_loss=0.4295 scale=0.5000 norm=0.9594\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1 (val_loss=0.4287)\n",
      "[iter 0] loss=0.4321 val_loss=0.4440 scale=1.0000 norm=1.9078\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4440)\n",
      "0.83831095\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6233 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4532 val_loss=0.4680 scale=1.0000 norm=1.8431\n",
      "[iter 200] loss=0.4448 val_loss=0.4671 scale=0.0020 norm=0.0036\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL136 (val_loss=0.4661)\n",
      "[iter 0] loss=0.4532 val_loss=0.4335 scale=1.0000 norm=1.9267\n",
      "[iter 100] loss=0.4435 val_loss=0.4343 scale=1.0000 norm=1.8965\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL11 (val_loss=0.4333)\n",
      "[iter 0] loss=0.4426 val_loss=0.4363 scale=0.5000 norm=0.9922\n",
      "[iter 100] loss=0.4373 val_loss=0.4425 scale=0.5000 norm=0.9461\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL5 (val_loss=0.4363)\n",
      "[iter 0] loss=0.4404 val_loss=0.4299 scale=2.0000 norm=3.8692\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4299)\n",
      "[iter 0] loss=0.4327 val_loss=0.4433 scale=1.0000 norm=1.9073\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4433)\n",
      "0.8371852500000001\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6266 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4627 val_loss=0.4736 scale=1.0000 norm=1.8355\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL176 (val_loss=0.4680)\n",
      "[iter 0] loss=0.4575 val_loss=0.4394 scale=1.0000 norm=1.8965\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL44 (val_loss=0.4373)\n",
      "[iter 0] loss=0.4487 val_loss=0.4454 scale=1.0000 norm=1.8987\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL11 (val_loss=0.4451)\n",
      "[iter 0] loss=0.4480 val_loss=0.4397 scale=1.0000 norm=1.9042\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4397)\n",
      "[iter 0] loss=0.4437 val_loss=0.4544 scale=2.0000 norm=3.7880\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4544)\n",
      "0.8336748\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6267 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4632 val_loss=0.4752 scale=2.0000 norm=3.6587\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL186 (val_loss=0.4675)\n",
      "[iter 0] loss=0.4557 val_loss=0.4362 scale=1.0000 norm=1.8963\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL12 (val_loss=0.4360)\n",
      "[iter 0] loss=0.4506 val_loss=0.4478 scale=1.0000 norm=1.8841\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=0.4474)\n",
      "[iter 0] loss=0.4495 val_loss=0.4415 scale=1.0000 norm=1.8957\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4415)\n",
      "[iter 0] loss=0.4454 val_loss=0.4560 scale=1.0000 norm=1.8850\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1 (val_loss=0.4559)\n",
      "0.8331747500000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6260 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4620 val_loss=0.4639 scale=2.0000 norm=3.6765\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL161 (val_loss=0.4603)\n",
      "[iter 0] loss=0.4523 val_loss=0.4584 scale=1.0000 norm=1.8638\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL65 (val_loss=0.4551)\n",
      "[iter 0] loss=0.4474 val_loss=0.4228 scale=1.0000 norm=1.8885\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4228)\n",
      "[iter 0] loss=0.4454 val_loss=0.4360 scale=1.0000 norm=1.8787\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4360)\n",
      "[iter 0] loss=0.4436 val_loss=0.4484 scale=1.0000 norm=1.8742\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4484)\n",
      "[iter 0] loss=0.4442 val_loss=0.4400 scale=2.0000 norm=3.7606\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4400)\n",
      "[iter 0] loss=0.4443 val_loss=0.4345 scale=1.0000 norm=1.8802\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1 (val_loss=0.4345)\n",
      "[iter 0] loss=0.4429 val_loss=0.4419 scale=1.0000 norm=1.8786\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL22 (val_loss=0.4416)\n",
      "[iter 0] loss=0.4388 val_loss=0.4619 scale=1.0000 norm=1.8678\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL11 (val_loss=0.4618)\n",
      "[iter 0] loss=0.4401 val_loss=0.4452 scale=1.0000 norm=1.8791\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4452)\n",
      "0.8366298000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6260 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4619 val_loss=0.4647 scale=2.0000 norm=3.6666\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL159 (val_loss=0.4602)\n",
      "[iter 0] loss=0.4517 val_loss=0.4570 scale=1.0000 norm=1.8625\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL47 (val_loss=0.4546)\n",
      "[iter 0] loss=0.4484 val_loss=0.4253 scale=1.0000 norm=1.8821\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL12 (val_loss=0.4250)\n",
      "[iter 0] loss=0.4458 val_loss=0.4355 scale=2.0000 norm=3.7447\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4355)\n",
      "[iter 0] loss=0.4435 val_loss=0.4514 scale=1.0000 norm=1.8657\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4514)\n",
      "[iter 0] loss=0.4446 val_loss=0.4391 scale=2.0000 norm=3.7499\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4391)\n",
      "[iter 0] loss=0.4445 val_loss=0.4345 scale=1.0000 norm=1.8750\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4345)\n",
      "[iter 0] loss=0.4433 val_loss=0.4428 scale=1.0000 norm=1.8731\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4428)\n",
      "[iter 0] loss=0.4406 val_loss=0.4644 scale=1.0000 norm=1.8636\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4644)\n",
      "[iter 0] loss=0.4421 val_loss=0.4451 scale=0.5000 norm=0.9374\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL10 (val_loss=0.4448)\n",
      "0.8365373999999999\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6262 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4613 val_loss=0.4753 scale=2.0000 norm=3.6862\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL170 (val_loss=0.4710)\n",
      "[iter 0] loss=0.4581 val_loss=0.4406 scale=2.0000 norm=3.8016\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL34 (val_loss=0.4397)\n",
      "[iter 0] loss=0.4510 val_loss=0.4445 scale=1.0000 norm=1.8956\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL8 (val_loss=0.4442)\n",
      "[iter 0] loss=0.4497 val_loss=0.4414 scale=1.0000 norm=1.8961\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL2 (val_loss=0.4414)\n",
      "[iter 0] loss=0.4452 val_loss=0.4563 scale=1.0000 norm=1.8852\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL12 (val_loss=0.4561)\n",
      "0.8322795000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp2, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6262 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4628 val_loss=0.4770 scale=2.0000 norm=3.6779\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL173 (val_loss=0.4718)\n",
      "[iter 0] loss=0.4581 val_loss=0.4402 scale=1.0000 norm=1.9022\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL23 (val_loss=0.4395)\n",
      "[iter 0] loss=0.4522 val_loss=0.4467 scale=1.0000 norm=1.8916\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL8 (val_loss=0.4466)\n",
      "[iter 0] loss=0.4517 val_loss=0.4430 scale=1.0000 norm=1.8992\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL3 (val_loss=0.4430)\n",
      "[iter 0] loss=0.4468 val_loss=0.4583 scale=1.0000 norm=1.8873\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4583)\n",
      "0.8311225500000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp3, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6254 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4627 val_loss=0.4651 scale=2.0000 norm=3.6877\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL164 (val_loss=0.4603)\n",
      "[iter 0] loss=0.4520 val_loss=0.4599 scale=1.0000 norm=1.8692\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4599)\n",
      "[iter 0] loss=0.4542 val_loss=0.4350 scale=1.0000 norm=1.8783\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4350)\n",
      "[iter 0] loss=0.4526 val_loss=0.4439 scale=2.0000 norm=3.7430\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4439)\n",
      "[iter 0] loss=0.4508 val_loss=0.4525 scale=2.0000 norm=3.7350\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4525)\n",
      "[iter 0] loss=0.4506 val_loss=0.4462 scale=1.0000 norm=1.8740\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4462)\n",
      "[iter 0] loss=0.4504 val_loss=0.4433 scale=1.0000 norm=1.8740\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL3 (val_loss=0.4433)\n",
      "[iter 0] loss=0.4493 val_loss=0.4464 scale=1.0000 norm=1.8758\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL8 (val_loss=0.4462)\n",
      "[iter 0] loss=0.4454 val_loss=0.4692 scale=1.0000 norm=1.8703\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1 (val_loss=0.4692)\n",
      "[iter 0] loss=0.4471 val_loss=0.4477 scale=1.0000 norm=1.8799\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1 (val_loss=0.4477)\n",
      "0.8323623999999998\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp2, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6255 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4627 val_loss=0.4664 scale=2.0000 norm=3.6872\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL152 (val_loss=0.4624)\n",
      "[iter 0] loss=0.4533 val_loss=0.4608 scale=1.0000 norm=1.8664\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL63 (val_loss=0.4586)\n",
      "[iter 0] loss=0.4486 val_loss=0.4280 scale=1.0000 norm=1.8914\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL20 (val_loss=0.4274)\n",
      "[iter 0] loss=0.4459 val_loss=0.4345 scale=1.0000 norm=1.8820\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4345)\n",
      "[iter 0] loss=0.4440 val_loss=0.4476 scale=1.0000 norm=1.8771\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1 (val_loss=0.4476)\n",
      "[iter 0] loss=0.4447 val_loss=0.4378 scale=1.0000 norm=1.8850\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4378)\n",
      "[iter 0] loss=0.4446 val_loss=0.4351 scale=1.0000 norm=1.8844\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4351)\n",
      "[iter 0] loss=0.4437 val_loss=0.4411 scale=1.0000 norm=1.8838\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4411)\n",
      "[iter 0] loss=0.4404 val_loss=0.4685 scale=1.0000 norm=1.8709\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4685)\n",
      "[iter 0] loss=0.4428 val_loss=0.4434 scale=1.0000 norm=1.8843\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL0 (val_loss=0.4434)\n",
      "0.8355102999999999\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp3, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_ngb = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99844489],\n",
       "       [0.22853689],\n",
       "       [0.47283505],\n",
       "       ...,\n",
       "       [0.84592395],\n",
       "       [0.9229176 ],\n",
       "       [0.34422363]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_ngb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.998445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.228537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.860387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.993916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.178637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.247501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.845924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.922918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.344224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.998445\n",
       "1        30001  0.228537\n",
       "2        30002  0.472835\n",
       "3        30003  0.860387\n",
       "4        30004  0.993916\n",
       "...        ...       ...\n",
       "14994    44994  0.178637\n",
       "14995    44995  0.247501\n",
       "14996    44996  0.845924\n",
       "14997    44997  0.922918\n",
       "14998    44998  0.344224\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble_ngb\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'./submission/team_210203_2_ngbc-tuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91969449],\n",
       "       [0.23163335],\n",
       "       [0.51476496],\n",
       "       ...,\n",
       "       [0.68887411],\n",
       "       [0.9339568 ],\n",
       "       [0.41309126]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93819144],\n",
       "       [0.24549661],\n",
       "       [0.44315962],\n",
       "       ...,\n",
       "       [0.76825373],\n",
       "       [0.90830821],\n",
       "       [0.42843415]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99844489],\n",
       "       [0.22853689],\n",
       "       [0.47283505],\n",
       "       ...,\n",
       "       [0.84592395],\n",
       "       [0.9229176 ],\n",
       "       [0.34422363]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_ngb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.952110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.235222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.476920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.827384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.939674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.181496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.274518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.767684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.921728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.395250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.952110\n",
       "1        30001  0.235222\n",
       "2        30002  0.476920\n",
       "3        30003  0.827384\n",
       "4        30004  0.939674\n",
       "...        ...       ...\n",
       "14994    44994  0.181496\n",
       "14995    44995  0.274518\n",
       "14996    44996  0.767684\n",
       "14997    44997  0.921728\n",
       "14998    44998  0.395250\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_best = (\n",
    "                            pred_ensemble_catb +\n",
    "                            pred_ensemble_lgbm  +\n",
    "                            pred_ensemble_ngb\n",
    "                        ) / 3\n",
    "\n",
    "submission.problem = pred_ensemble_best\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'./submission/team_210203_3_ensemble-best3-final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc_fold_train_pred(candidates, train_x, train_y):\n",
    "    \n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    oob_scores   = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    vc = VotingClassifier(\n",
    "                            estimators=[candidates],\n",
    "                            voting='soft'\n",
    "                        )\n",
    "    \n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "        \n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = vc.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "        \n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingClassifier(\n",
    "                        estimators=[candidates],\n",
    "                        voting='soft'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[[('lgbm',\n",
       "                               LGBMClassifier(random_state=2584, verbose=0)),\n",
       "                              ('catb',\n",
       "                               <catboost.core.CatBoostClassifier object at 0x00000211655B1F48>),\n",
       "                              ('gbc',\n",
       "                               GradientBoostingClassifier(random_state=2584)),\n",
       "                              ('ngbc',\n",
       "                               NGBClassifier(learning_rate=0.027,\n",
       "                                             n_estimators=10000,\n",
       "                                             random_state=RandomState(MT19937) at 0x20FBFD87598))]],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-2c6e11ae2921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lgbm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'catb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'gbc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgbc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'ngbc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngbc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvc_fold_train_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_b_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-b15bc9a1263e>\u001b[0m in \u001b[0;36mvc_fold_train_pred\u001b[1;34m(candidates, train_x, train_y)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m#run traning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# cal valid prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         if (self.weights is not None and\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;34m\" of (string, estimator) tuples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             )\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;31m# defined by MetaEstimatorMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "candidates = [('lgbm', lgbm), ('catb', catb), ('gbc', gbc), ('ngbc', ngbc)]\n",
    "\n",
    "models, auc_scores, _, _ = vc_fold_train_pred(candidates, X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hard'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mflatten_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Soft Voting/Majority Rule classifier for unfitted estimators.\n",
       "\n",
       ".. versionadded:: 0.17\n",
       "\n",
       "Read more in the :ref:`User Guide <voting_classifier>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "estimators : list of (str, estimator) tuples\n",
       "    Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones\n",
       "    of those original estimators that will be stored in the class attribute\n",
       "    ``self.estimators_``. An estimator can be set to ``'drop'``\n",
       "    using ``set_params``.\n",
       "\n",
       "    .. versionchanged:: 0.21\n",
       "        ``'drop'`` is accepted.\n",
       "\n",
       "    .. deprecated:: 0.22\n",
       "       Using ``None`` to drop an estimator is deprecated in 0.22 and\n",
       "       support will be dropped in 0.24. Use the string ``'drop'`` instead.\n",
       "\n",
       "voting : {'hard', 'soft'}, default='hard'\n",
       "    If 'hard', uses predicted class labels for majority rule voting.\n",
       "    Else if 'soft', predicts the class label based on the argmax of\n",
       "    the sums of the predicted probabilities, which is recommended for\n",
       "    an ensemble of well-calibrated classifiers.\n",
       "\n",
       "weights : array-like of shape (n_classifiers,), default=None\n",
       "    Sequence of weights (`float` or `int`) to weight the occurrences of\n",
       "    predicted class labels (`hard` voting) or class probabilities\n",
       "    before averaging (`soft` voting). Uses uniform weights if `None`.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to run in parallel for ``fit``.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "\n",
       "flatten_transform : bool, default=True\n",
       "    Affects shape of transform output only when voting='soft'\n",
       "    If voting='soft' and flatten_transform=True, transform method returns\n",
       "    matrix with shape (n_samples, n_classifiers * n_classes). If\n",
       "    flatten_transform=False, it returns\n",
       "    (n_classifiers, n_samples, n_classes).\n",
       "\n",
       "verbose : bool, default=False\n",
       "    If True, the time elapsed while fitting will be printed as it\n",
       "    is completed.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "estimators_ : list of classifiers\n",
       "    The collection of fitted sub-estimators as defined in ``estimators``\n",
       "    that are not 'drop'.\n",
       "\n",
       "named_estimators_ : :class:`~sklearn.utils.Bunch`\n",
       "    Attribute to access any fitted sub-estimators by name.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "classes_ : array-like of shape (n_predictions,)\n",
       "    The classes labels.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "VotingRegressor: Prediction voting regressor.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.linear_model import LogisticRegression\n",
       ">>> from sklearn.naive_bayes import GaussianNB\n",
       ">>> from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
       ">>> clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
       ">>> clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
       ">>> clf3 = GaussianNB()\n",
       ">>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
       ">>> y = np.array([1, 1, 1, 2, 2, 2])\n",
       ">>> eclf1 = VotingClassifier(estimators=[\n",
       "...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
       ">>> eclf1 = eclf1.fit(X, y)\n",
       ">>> print(eclf1.predict(X))\n",
       "[1 1 1 2 2 2]\n",
       ">>> np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
       "...                eclf1.named_estimators_['lr'].predict(X))\n",
       "True\n",
       ">>> eclf2 = VotingClassifier(estimators=[\n",
       "...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
       "...         voting='soft')\n",
       ">>> eclf2 = eclf2.fit(X, y)\n",
       ">>> print(eclf2.predict(X))\n",
       "[1 1 1 2 2 2]\n",
       ">>> eclf3 = VotingClassifier(estimators=[\n",
       "...        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
       "...        voting='soft', weights=[2,1,1],\n",
       "...        flatten_transform=True)\n",
       ">>> eclf3 = eclf3.fit(X, y)\n",
       ">>> print(eclf3.predict(X))\n",
       "[1 1 1 2 2 2]\n",
       ">>> print(eclf3.transform(X).shape)\n",
       "(6, 6)\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\wyatt\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VotingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 창고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 형록이가 제안한 var 모델\n",
    "\n",
    "# X = pd.concat([train_e.user_id, pd.get_dummies(train_e.errtype)], axis=1).groupby('user_id').var().fillna(0)\n",
    "# y = pd.concat([test_e.user_id, pd.get_dummies(test_e.errtype)], axis=1).groupby('user_id').var().fillna(0)\n",
    "\n",
    "# X.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    "#  'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    "#  'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    "#  'et_39', 'et_40', 'et_41', 'et_42']\n",
    "# y.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    "#  'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    "#  'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    "#  'et_39', 'et_40', 'et_41', 'et_42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혜인이가 제안한 errcode\n",
    "\n",
    "# # 8호\n",
    "# train_ecode_14 = train_e[train_e.errtype == 14][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_14 = test_e[test_e.errtype == 14][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_14.columns = ['err_14_1', 'err_14_13','err_14_14']\n",
    "# test_ecode_14.columns =  ['err_14_1', 'err_14_13','err_14_14']\n",
    "\n",
    "# # 30호\n",
    "# train_ecode_30 = train_e[train_e.errtype == 30][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_30 = test_e[test_e.errtype == 30][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_30.columns = ['err_30_0','err_30_1','err_30_2', 'err_30_3','err_30_4']\n",
    "# test_ecode_30.columns =  ['err_30_0','err_30_1','err_30_2', 'err_30_3','err_30_4']\n",
    "\n",
    "# # 9호\n",
    "# train_ecode_9 = train_e[train_e.errtype == 9][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_9 = test_e[test_e.errtype == 9][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_9.columns = ['err_9_1','err_9_C-11020', 'err_9_C-12032','err_9_C-13039','err_9_C-14014',\n",
    "#                           'err_9_V-21002','err_9_V-21004','err_9_V-21005','err_9_V-21008']\n",
    "# test_ecode_9.columns = ['err_9_1','err_9_C-11020', 'err_9_C-12032','err_9_C-13039','err_9_C-14014',\n",
    "#                           'err_9_V-21002','err_9_V-21004','err_9_V-21005','err_9_V-21008']\n",
    "\n",
    "# # 37호\n",
    "# train_ecode_37 = train_e[train_e.errtype == 37][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_37 = test_e[test_e.errtype == 37][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_37.columns = ['err_37_1', 'err_37_2']\n",
    "# test_ecode_37.columns = ['err_37_1', 'err_37_2']\n",
    "\n",
    "\n",
    "# # 5호\n",
    "# train_ecode_5 = train_e[train_e.errtype == 5][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)[('time', 'E-59902')]\n",
    "# test_ecode_5 = test_e[test_e.errtype == 5][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)[('time', 'E-59902')]\n",
    "# #train_ecode_5.columns = ['err_5_E-59902']\n",
    "# #test_ecode_5.columns = ['err_5_E-59902']\n",
    "# train_ecode_5 = train_ecode_5.rename(level = 0, index = 'err_5_E-59902') \n",
    "# test_ecode_5 = test_ecode_5.rename(level = 0, index = 'err_5_E-59902') \n",
    "\n",
    "# # 31호\n",
    "# train_ecode_31 = train_e[train_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_31 = test_e[test_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_31.columns = ['err_31_0', 'err_31_1']\n",
    "# test_ecode_31.columns =['err_31_0', 'err_31_1']\n",
    "\n",
    "# # 7호\n",
    "# train_ecode_7 = train_e[train_e.errtype == 7][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_7 = test_e[test_e.errtype == 7][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_7.columns = ['err_7_1', 'err_7_14']\n",
    "# test_ecode_7.columns =['err_7_1', 'err_7_14']\n",
    "\n",
    "# # 25호\n",
    "# train_ecode_25 = train_e[train_e.errtype == 25][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_25 = test_e[test_e.errtype == 25][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "# train_ecode_25.columns =  ['err_25_1', 'err_25_2', 'err_25_L2CAP connection cancelled', 'err_25_UNKNOWN', \n",
    "#                             'err_25_connection fail to establish',\n",
    "#                              'err_25_connection timeout', 'err_25_connectionterminated by local host',\n",
    "#                             'err_25_scanning timeout', 'err_25_terminate by peer user']\n",
    "\n",
    "# test_ecode_25.columns = ['err_25_1', 'err_25_2', 'err_25_L2CAP connection cancelled', 'err_25_UNKNOWN', \n",
    "#                            'connection fail for LMP response timout',\n",
    "#                             'err_25_connection fail to establish',\n",
    "#                              'err_25_connection timeout', 'err_25_connectionterminated by local host',\n",
    "#                             'err_25_scanning timeout', 'err_25_terminate by peer user']\n",
    "\n",
    "# test_ecode_25.drop('connection fail for LMP response timout', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new_scaled = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_list = [0.00001, 0.0001, 0.001, 0.01,\n",
    "#           0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ridge\n",
    "# ridge = RidgeCV(alphas=a_list)\n",
    "# ridge.fit(X_new_scaled, train_b_p.target)\n",
    "\n",
    "# print('best alpha: ', ridge.alpha_)\n",
    "# print('feature selected: ', ridge.coef_.nonzero()[0].size)\n",
    "# print('R^2 is: ', ridge.score(X_new_scaled, train_b_p.target))\n",
    "# print('auc: ', roc_auc_score(train_b_p.target, ridge.predict(X_new_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lasso\n",
    "# lasso = LassoCV(alphas=a_list)\n",
    "# lasso.fit(X_new_scaled, train_b_p.target)\n",
    "\n",
    "# print('best alpha: ', lasso.alpha_)\n",
    "# print('feature selected: ', lasso.coef_.nonzero()[0].size)\n",
    "# print('R^2 is: ', lasso.score(X_new_scaled, train_b_p.target))\n",
    "# print('auc: ', roc_auc_score(train_b_p.target, lasso.predict(X_new_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # elastic\n",
    "# elastic = ElasticNetCV(alphas=a_list)\n",
    "# elastic.fit(X_new_scaled, train_b_p.target)\n",
    "\n",
    "# print('best alpha: ', elastic.alpha_)\n",
    "# print('feature selected: ', elastic.coef_.nonzero()[0].size)\n",
    "# print('R^2 is: ', elastic.score(X_new_scaled, train_b_p.target))\n",
    "# print('auc: ', roc_auc_score(train_b_p.target, elastic.predict(X_new_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elastic.coef_.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new.iloc[:, elastic.coef_.nonzero()[0]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_selected = X_new.iloc[:, elastic.coef_.nonzero()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #------------------------------------------------------------\n",
    "# # validation auc score를 확인하기 위해 정의\n",
    "# def f_pr_auc(probas_pred, y_true):\n",
    "#     labels=y_true.get_label()\n",
    "#     p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "#     score=auc(r,p) \n",
    "#     return \"pr_auc\", score, True\n",
    "# #------------------------------------------------------------\n",
    "\n",
    "\n",
    "# def s_fold_train_pred(train_x, train_y):\n",
    "#     import lightgbm as lgb\n",
    "\n",
    "#     # Train\n",
    "#     models     = []\n",
    "#     recalls    = []\n",
    "#     precisions = []\n",
    "#     auc_scores   = []\n",
    "#     threshold = 0.5\n",
    "#     # 파라미터 설정\n",
    "#     params =      {\n",
    "#                     'boosting_type' : 'gbdt',\n",
    "#                     'objective'     : 'binary',\n",
    "#                     'metric'        : 'auc',\n",
    "#                     'learning_rate' : 0.027,\n",
    "#                     'seed': 42\n",
    "#                     }\n",
    "#     #-------------------------------------------------------------------------------------\n",
    "#     # 5 Kfold cross validation\n",
    "#     s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "#     for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "#         # split train, validation set\n",
    "#         X = train_x.iloc[train_idx]\n",
    "#         y = train_y.iloc[train_idx]\n",
    "#         valid_x = train_x.iloc[val_idx]\n",
    "#         valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "#         d_train= lgb.Dataset(X, y)\n",
    "#         d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "\n",
    "#         #run traning\n",
    "#         model = lgb.train(\n",
    "#                             params,\n",
    "#                             train_set       = d_train,\n",
    "#                             num_boost_round = 10000,\n",
    "#                             valid_sets      = d_val,\n",
    "#                             feval           = f_pr_auc,\n",
    "#                             verbose_eval    = 100, \n",
    "#                             early_stopping_rounds = 100\n",
    "#                            )\n",
    "\n",
    "#         # cal valid prediction\n",
    "#         valid_prob = model.predict(valid_x)\n",
    "#         valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "#         # cal scores\n",
    "#         recall    = recall_score(    valid_y, valid_pred)\n",
    "#         precision = precision_score( valid_y, valid_pred)\n",
    "#         auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "#         # append scores\n",
    "#         models.append(model)\n",
    "#         recalls.append(recall)\n",
    "#         precisions.append(precision)\n",
    "#         auc_scores.append(auc_score)\n",
    "\n",
    "#         print('==========================================================')\n",
    "        \n",
    "#     return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loss 비교를 위해 지우지 않습니다.\n",
    "# # 최고점 모델입니다.\n",
    "# models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "# print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습용\n",
    "# models, auc_scores, _, _ = s_fold_train_pred(X_temp, train_b_p.target)\n",
    "# print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Xtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "xtree = ExtraTreesClassifier(\n",
    "                                bootstrap=False,\n",
    "                                ccp_alpha=0.0,\n",
    "                                class_weight=None,\n",
    "                                criterion='gini',\n",
    "                                max_depth=None,\n",
    "                                max_features='auto',\n",
    "                                max_leaf_nodes=None,\n",
    "                                max_samples=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_samples_split=2,\n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                n_estimators=2000,\n",
    "                                n_jobs=-1,\n",
    "                                oob_score=False,\n",
    "                                random_state=2584,\n",
    "                                verbose=1,\n",
    "                                warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def xtree_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = xtree\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "0.7254\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = xtree_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "0.7257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = xtree_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_xtree = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9055],\n",
       "       [0.1745],\n",
       "       [0.4875],\n",
       "       ...,\n",
       "       [0.603 ],\n",
       "       [0.6785],\n",
       "       [0.458 ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_xtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=7367, verbose=0,\n",
    "                       warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_fold_train_pred(train_x, train_y):\n",
    "    \n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    oob_scores   = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "    \n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "        \n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = rfc.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "        \n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7261500000000002\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = rf_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7283000000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = rf_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_rf = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82],\n",
       "       [0.2 ],\n",
       "       [0.49],\n",
       "       ...,\n",
       "       [0.51],\n",
       "       [0.66],\n",
       "       [0.34]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(\n",
    "                                ccp_alpha=0.0,\n",
    "                                criterion='friedman_mse',\n",
    "                                init=None,\n",
    "                                learning_rate=0.1,\n",
    "                                loss='deviance',\n",
    "                                max_depth=3,\n",
    "                                max_features=None,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_samples_split=2,\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                n_estimators=1000,\n",
    "                                n_iter_no_change=None,\n",
    "                                presort='deprecated',\n",
    "                                random_state=2584,\n",
    "                                subsample=1.0,\n",
    "                                tol=0.0001,\n",
    "                                validation_fraction=0.1,\n",
    "                                verbose=0,\n",
    "                                warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbc_fold_train_pred(train_x, train_y, N_SPLIT=5):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=42)\n",
    "    for train_idx, val_idx in k_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = gbc.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "        \n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "    \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-203-192392124e06>\u001b[0m in \u001b[0;36mgbc_fold_train_pred\u001b[1;34m(train_x, train_y, N_SPLIT)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#run traning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# cal valid prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    498\u001b[0m         n_stages = self._fit_stages(\n\u001b[0;32m    499\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m    555\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[0;32m    556\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 212\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1247\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp2, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-205-70b429001bc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# loss 비교를 위해 지우지 않습니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 최고점 모델입니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbc_fold_train_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_temp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_b_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-203-192392124e06>\u001b[0m in \u001b[0;36mgbc_fold_train_pred\u001b[1;34m(train_x, train_y, N_SPLIT)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#run traning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# cal valid prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    498\u001b[0m         n_stages = self._fit_stages(\n\u001b[0;32m    499\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m    555\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[0;32m    556\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 212\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1247\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wyatt37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp3, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp2, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp3, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이터레이션 100-> 1000으로 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7314\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73225\n",
      "Wall time: 14min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp, train_b_p.target, 10)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7308999999999999\n",
      "Wall time: 5min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7323500000000001\n",
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이터레이션 100 그대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252500000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72435\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72455\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72495\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_gbc = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94729912],\n",
       "       [0.20899576],\n",
       "       [0.48470505],\n",
       "       ...,\n",
       "       [0.75559137],\n",
       "       [0.87481054],\n",
       "       [0.34822194]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
