{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노트북이 너무 쌓이면 새로운 노트북으로 갈아타줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 모으기 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT & LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_dtypes as ld\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, precision_recall_curve, recall_score, precision_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_P_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv'\n",
    "TRAIN_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv'\n",
    "TRAIN_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv'\n",
    "TEST_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv'\n",
    "TEST_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv'\n",
    "SUBMISSION_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = ld.load_dtypes(TRAIN_P_PATH)\n",
    "train_q = ld.load_dtypes(TRAIN_Q_PATH)\n",
    "train_e = ld.load_dtypes(TRAIN_E_PATH)\n",
    "test_q = ld.load_dtypes(TEST_Q_PATH)\n",
    "test_e = ld.load_dtypes(TEST_E_PATH)\n",
    "submission = pd.read_csv(SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5429, 2),\n",
       " (828624, 16),\n",
       " (16554663, 6),\n",
       " (747972, 16),\n",
       " (16532648, 6),\n",
       " (14999, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape, train_q.shape, train_e.shape, test_q.shape, test_e.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5429 entries, 0 to 5428\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   user_id  5429 non-null   int16\n",
      " 1   time     5429 non-null   int64\n",
      "dtypes: int16(1), int64(1)\n",
      "memory usage: 53.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 828624 entries, 0 to 828623\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   time        828624 non-null  int64   \n",
      " 1   user_id     828624 non-null  int16   \n",
      " 2   fwver       788544 non-null  category\n",
      " 3   quality_0   684192 non-null  float32 \n",
      " 4   quality_1   828624 non-null  int16   \n",
      " 5   quality_2   788511 non-null  float32 \n",
      " 6   quality_3   828624 non-null  int8    \n",
      " 7   quality_4   828624 non-null  int8    \n",
      " 8   quality_5   828604 non-null  category\n",
      " 9   quality_6   828624 non-null  int16   \n",
      " 10  quality_7   828624 non-null  category\n",
      " 11  quality_8   828624 non-null  category\n",
      " 12  quality_9   828624 non-null  category\n",
      " 13  quality_10  828624 non-null  category\n",
      " 14  quality_11  828624 non-null  int8    \n",
      " 15  quality_12  828624 non-null  int8    \n",
      "dtypes: category(6), float32(2), int16(3), int64(1), int8(4)\n",
      "memory usage: 28.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_q.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16554663 entries, 0 to 16554662\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype   \n",
      "---  ------    -----   \n",
      " 0   user_id   int16   \n",
      " 1   time      int64   \n",
      " 2   model_nm  category\n",
      " 3   fwver     category\n",
      " 4   errtype   int8    \n",
      " 5   errcode   category\n",
      "dtypes: category(3), int16(1), int64(1), int8(1)\n",
      "memory usage: 236.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_e.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 747972 entries, 0 to 747971\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   time        747972 non-null  int64   \n",
      " 1   user_id     747972 non-null  uint16  \n",
      " 2   fwver       725208 non-null  category\n",
      " 3   quality_0   641388 non-null  float32 \n",
      " 4   quality_1   747961 non-null  category\n",
      " 5   quality_2   726857 non-null  float32 \n",
      " 6   quality_3   747972 non-null  int8    \n",
      " 7   quality_4   747972 non-null  int8    \n",
      " 8   quality_5   747928 non-null  category\n",
      " 9   quality_6   747972 non-null  int16   \n",
      " 10  quality_7   747972 non-null  category\n",
      " 11  quality_8   747972 non-null  category\n",
      " 12  quality_9   747972 non-null  category\n",
      " 13  quality_10  747972 non-null  category\n",
      " 14  quality_11  747972 non-null  int8    \n",
      " 15  quality_12  747972 non-null  int8    \n",
      "dtypes: category(7), float32(2), int16(1), int64(1), int8(4), uint16(1)\n",
      "memory usage: 25.4 MB\n"
     ]
    }
   ],
   "source": [
    "test_q.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16532648 entries, 0 to 16532647\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype   \n",
      "---  ------    -----   \n",
      " 0   user_id   uint16  \n",
      " 1   time      int64   \n",
      " 2   model_nm  category\n",
      " 3   fwver     category\n",
      " 4   errtype   int8    \n",
      " 5   errcode   category\n",
      "dtypes: category(3), int64(1), int8(1), uint16(1)\n",
      "memory usage: 236.6 MB\n"
     ]
    }
   ],
   "source": [
    "test_e.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_problem(df, object_='binary'):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    train_problem 테이블을 받아서 target 값으로 변환\n",
    "    1. {0, 1}의 binary로 변환\n",
    "    2. {0 ~ n}의 multiclass로 변환\n",
    "    \"\"\"\n",
    "    \n",
    "    # 10001부터 24999까지의 index를 만들어줍니다.\n",
    "    user_id_idx = np.array(range(10000, 25000, 1))\n",
    "    \n",
    "    # train_new_p라는 새로운 df를 만들고 index는 위에서 만든 user_id_idx 로 지정해줍니다.\n",
    "    new_p = pd.DataFrame(index = user_id_idx)\n",
    "    new_p['target'] = 0\n",
    "    \n",
    "    if object_ == 'binary':\n",
    "        new_p.iloc[df.user_id.unique()-10000] = 1\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    elif object_ == 'multi':\n",
    "        # multi는 count()로 집계를 해줍니다.\n",
    "        new_p['target'] = df.groupby('user_id')['time'].count()\n",
    "        new_p = new_p.fillna(0)\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b_p = preprocessing_problem(train_p, 'binary')\n",
    "train_m_p = preprocessing_problem(train_p, 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_quality(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    EDA를 통해 알아낸 정보로 train_q, test_q를 정리해서 내뿜어줍니다.\n",
    "    1. qaulity_3, quality_4 를 drop 합니다.(단일 value)\n",
    "    2. qaulity_k 변수들을 정수로 encoding 합니다.\n",
    "    \"\"\"\n",
    "    # 먼저 3, 4번을 drop 합니다.\n",
    "    df.drop(['quality_3', 'quality_4'], axis=1, inplace=True)\n",
    "    \n",
    "    # qual 변수만 할당해주고, 정수로 형변환 해줍니다.\n",
    "    columns = train_q.columns[train_q.columns.str.contains('quality')]\n",
    "    # for문을 통해 각 column을 반복 작업해줍니다.\n",
    "    for col in columns:\n",
    "        try:\n",
    "            if df[col].dtype == 'float32': # 기존에 float은 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "            elif df[col].dtype == 'int8' or df[col].dtype == 'int16': # 기존에 int도 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "                #print(col)\n",
    "            else:\n",
    "                df[col] = df[col].astype('object')\n",
    "                # nan값이 있으면 float으로 갈 수 없으니 '-2' 으로 채워줍니다.\n",
    "                df[col] = df[col].fillna('-2')\n",
    "                df[col] = df[col].apply(lambda x: x.replace(',' , ''))\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # fwver 에서 null 값이 꽤 있습니다. missing으로 채우겠습니다.\n",
    "    df.fwver = df.fwver.astype('object')\n",
    "    df.fwver = df.fwver.fillna('missing')\n",
    "    df.fwver = df.fwver.astype('category')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = preprocessing_quality(train_q)\n",
    "test_q = preprocessing_quality(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fwver(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    별건 아니고, e-set에 fwver 변수에서 '10' 이라는 값이 있는데, 이게 errtype이랑 겹쳐요.\n",
    "    그래서 10을 -> 8.5.2 으로 바꿔줄 겁니다.\n",
    "    굳이 이렇게 바꾸는 이유는, 해당 fw가 8.5.3버전과 같은 model_nm을 공유하기 때문입니다.\n",
    "    \"\"\"\n",
    "    df.fwver = df.fwver.replace('10', '8.5.2')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = preprocessing_fwver(train_e)\n",
    "test_e = preprocessing_fwver(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    'time' column이 str로 되어 있으니, datetime으로 바꿔주는 함수입니다.\n",
    "    다만 'time'양식이 pandas함수에 적용이 안되니, 강제로 슬라이싱해서 만들어줘야 합니다.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df['year'] = df['time'].apply(lambda x: str(x)[:4])\n",
    "    df['month'] = df['time'].apply(lambda x: str(x)[4:6])\n",
    "    df['day'] = df['time'].apply(lambda x: str(x)[6:8])\n",
    "    df['hour'] = df['time'].apply(lambda x: str(x)[8:10])\n",
    "    df['minute'] = '00' # minute을 넣어주지 않으면 datetime이 완성이 안되니, 00으로 넣어줍니다.\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df.year + df.month + df.day + df.hour + df.minute)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = make_datetime(train_p)\n",
    "train_q = make_datetime(train_q)\n",
    "test_q = make_datetime(test_q)\n",
    "train_e = make_datetime(train_e)\n",
    "test_e = make_datetime(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 연산에서 왜 문제가 생기나 했더니 category로 되어 있어서였습니다.\n",
    "\n",
    "train_e['errtype'] = train_e.errtype.astype('object')\n",
    "test_e['errtype'] = test_e.errtype.astype('object')\n",
    "\n",
    "train_e['errcode'] = train_e.errcode.astype('object')\n",
    "test_e['errcode'] = test_e.errcode.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwver도 object로 잡아줍니다.\n",
    "\n",
    "train_q.fwver = train_q.fwver.astype('object')\n",
    "test_q.fwver = test_q.fwver.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA feature Collection 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### errcode 마무리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_e[['errtype', 'errcode']].drop_duplicates()\n",
    "count = {}\n",
    "\n",
    "for i in sorted(temp.errtype.unique()):\n",
    "    count[i] = (len(temp[temp.errtype == i]['errcode'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_type_user_counts = []\n",
    "for i in sorted(train_e.errtype.unique()):\n",
    "    err_type_user_counts.append(train_e[train_e.errtype == i].groupby('user_id').count().shape[0])\n",
    "\n",
    "train_p['target'] = 1\n",
    "temp = pd.merge(train_e, train_p, how='left', on=['user_id'])\n",
    "temp2 = temp[temp.target == 1]\n",
    "\n",
    "err_type_user_counts_origin = []\n",
    "for i in sorted(temp2.errtype.unique()):\n",
    "    err_type_user_counts_origin.append(temp2[temp2.errtype == i].groupby('user_id').count().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "etuc_1 = np.array(err_type_user_counts)\n",
    "etuc_2 = np.array(err_type_user_counts_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "errcode_df = pd.DataFrame()\n",
    "errcode_df['etuc_1'] = etuc_1\n",
    "errcode_df['etuc_2'] = etuc_2\n",
    "errcode_df['div'] = ((etuc_2 / etuc_1) * 100).round(2)\n",
    "errcode_df['unique'] = count.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "errcode_df = errcode_df.set_index([sorted(train_e.errtype.unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "errcode_df['perf'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "errcode_df.loc[errcode_df.unique == 1, 'perf'] = 'pass'\n",
    "errcode_df.loc[errcode_df.index == 31, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 41, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 17, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 23, 'perf'] = 'adopt'\n",
    "errcode_df.loc[errcode_df.index == 33, 'perf'] = 'adopt'\n",
    "errcode_df.loc[errcode_df.index == 40, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 14, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 37, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 7, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 4, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 6, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 34, 'perf'] = 'adopt'\n",
    "errcode_df.loc[errcode_df.index == 5, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 42, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 38, 'perf'] = 'reject'\n",
    "errcode_df.loc[errcode_df.index == 32, 'perf'] = 'hold' # model 성능은 올라갔으나, 리더보드 하락\n",
    "errcode_df.loc[errcode_df.index == 3, 'perf'] = 'hold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etuc_1</th>\n",
       "      <th>etuc_2</th>\n",
       "      <th>div</th>\n",
       "      <th>unique</th>\n",
       "      <th>perf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950</td>\n",
       "      <td>242</td>\n",
       "      <td>25.47</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390</td>\n",
       "      <td>168</td>\n",
       "      <td>43.08</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>20.31</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>60.32</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>420</td>\n",
       "      <td>360</td>\n",
       "      <td>85.71</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>375</td>\n",
       "      <td>260</td>\n",
       "      <td>69.33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>766</td>\n",
       "      <td>405</td>\n",
       "      <td>52.87</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    etuc_1  etuc_2    div  unique perf\n",
       "1      950     242  25.47       8  NaN\n",
       "2      390     168  43.08       2  NaN\n",
       "8       64      13  20.31       3  NaN\n",
       "9       63      38  60.32       9  NaN\n",
       "25     420     360  85.71       9  NaN\n",
       "30     375     260  69.33       5  NaN\n",
       "39     766     405  52.87       2  NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errcode_df[errcode_df.perf.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 친구들은 도전하지 않겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality 다시 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가설 세우기.\n",
    "\n",
    "1. fwver별로 퀄리티 평균을 구해서 fwver별로 차이를 구해준다면. 제일 처음 것과 제일 마지막 것의 차이를 주는 것. 1개만 쓰면 0, 음수가 될 수도 있고, 양수가 될 수도 있고.\n",
    "2. 단순히 q로그가 몇 번 있었는지를 기록했는데, 정지훈 선생의 가설 대로 0이 default 값이라면, 0이 아닌 값이 몇 번 일어났는가도 중요하지 않을까.\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quality log 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 nunique:  754\n",
      "1 번째 nunique:  31\n",
      "2 번째 nunique:  799\n",
      "5 번째 nunique:  4745\n",
      "6 번째 nunique:  549\n",
      "7 번째 nunique:  884\n",
      "8 번째 nunique:  42\n",
      "9 번째 nunique:  523\n",
      "10 번째 nunique:  4200\n",
      "11 번째 nunique:  12\n",
      "12 번째 nunique:  14\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    print(i,'번째 nunique: ' ,train_q['quality_{}'.format(i)].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 nunique:  541\n",
      "1 번째 nunique:  35\n",
      "2 번째 nunique:  597\n",
      "5 번째 nunique:  3995\n",
      "6 번째 nunique:  528\n",
      "7 번째 nunique:  839\n",
      "8 번째 nunique:  44\n",
      "9 번째 nunique:  431\n",
      "10 번째 nunique:  3515\n",
      "11 번째 nunique:  13\n",
      "12 번째 nunique:  17\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    print(i,'번째 nunique: ' ,test_q['quality_{}'.format(i)].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0    542790\n",
      "-2.0    144432\n",
      "-1.0    130828\n",
      " 1.0      2097\n",
      " 2.0      1252\n",
      " 3.0       518\n",
      " 4.0       410\n",
      " 5.0       385\n",
      " 6.0       358\n",
      " 7.0       314\n",
      "Name: quality_0, dtype: int64\n",
      " 0    670270\n",
      "-1    153649\n",
      " 1      2567\n",
      " 2      1140\n",
      " 3       391\n",
      " 4       202\n",
      " 5       134\n",
      " 6        71\n",
      " 7        50\n",
      " 8        35\n",
      "Name: quality_1, dtype: int64\n",
      " 0.0    632469\n",
      "-1.0    144392\n",
      "-2.0     40113\n",
      " 1.0      2937\n",
      " 2.0      1073\n",
      " 3.0       580\n",
      " 4.0       455\n",
      " 5.0       427\n",
      " 6.0       386\n",
      " 7.0       337\n",
      "Name: quality_2, dtype: int64\n",
      " 0.0    428096\n",
      "-1.0    153354\n",
      " 1.0     56171\n",
      " 2.0     35978\n",
      " 3.0     21596\n",
      " 4.0     11204\n",
      " 5.0      8536\n",
      " 6.0      6836\n",
      " 7.0      5506\n",
      " 8.0      4495\n",
      "Name: quality_5, dtype: int64\n",
      " 0      662217\n",
      "-1      153531\n",
      " 600      1852\n",
      " 1        1347\n",
      " 5         644\n",
      " 2         603\n",
      " 3         475\n",
      " 6         445\n",
      " 4         408\n",
      " 10        320\n",
      "Name: quality_6, dtype: int64\n",
      "0.0     757788\n",
      "1.0       6768\n",
      "2.0       3648\n",
      "5.0       3456\n",
      "6.0       2688\n",
      "3.0       2568\n",
      "4.0       2124\n",
      "10.0      1632\n",
      "11.0      1452\n",
      "7.0       1164\n",
      "Name: quality_7, dtype: int64\n",
      "0.0    787812\n",
      "1.0     19104\n",
      "2.0      8832\n",
      "3.0      4020\n",
      "4.0      2592\n",
      "5.0      1692\n",
      "6.0      1116\n",
      "7.0       744\n",
      "8.0       480\n",
      "9.0       384\n",
      "Name: quality_8, dtype: int64\n",
      "0.0    796284\n",
      "1.0      9024\n",
      "2.0      2772\n",
      "3.0      1800\n",
      "4.0      1416\n",
      "6.0      1176\n",
      "5.0      1152\n",
      "7.0       564\n",
      "8.0       420\n",
      "9.0       396\n",
      "Name: quality_9, dtype: int64\n",
      "3.0    99828\n",
      "2.0    81732\n",
      "0.0    59028\n",
      "1.0    58152\n",
      "4.0    54948\n",
      "5.0    40812\n",
      "6.0    32220\n",
      "7.0    24036\n",
      "8.0    19212\n",
      "9.0    15756\n",
      "Name: quality_10, dtype: int64\n",
      " 0     672229\n",
      "-1     153678\n",
      " 1       2428\n",
      " 2        203\n",
      " 3         50\n",
      " 4         19\n",
      " 5          8\n",
      " 6          5\n",
      " 14         1\n",
      " 9          1\n",
      "Name: quality_11, dtype: int64\n",
      "0     801156\n",
      "1      20880\n",
      "2       4524\n",
      "3       1320\n",
      "4        312\n",
      "5        192\n",
      "6        108\n",
      "8         48\n",
      "7         24\n",
      "14        12\n",
      "Name: quality_12, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    print(train_q['quality_{}'.format(i)].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0    505710\n",
      "-1.0    127001\n",
      "-2.0    106584\n",
      " 1.0      2319\n",
      " 2.0      1567\n",
      " 3.0       739\n",
      " 4.0       454\n",
      " 5.0       290\n",
      " 6.0       212\n",
      " 8.0       158\n",
      "Name: quality_0, dtype: int64\n",
      " 0.0    601265\n",
      "-1.0    141905\n",
      " 1.0      2573\n",
      " 2.0      1119\n",
      " 3.0       451\n",
      " 4.0       201\n",
      " 5.0       130\n",
      " 6.0       101\n",
      " 7.0        58\n",
      " 8.0        37\n",
      "Name: quality_1, dtype: int64\n",
      " 0.0    578838\n",
      "-1.0    136864\n",
      "-2.0     21115\n",
      " 1.0      3690\n",
      " 2.0      1629\n",
      " 3.0       962\n",
      " 4.0       625\n",
      " 5.0       391\n",
      " 6.0       295\n",
      " 7.0       203\n",
      "Name: quality_2, dtype: int64\n",
      " 0.0    399032\n",
      "-1.0    141788\n",
      " 1.0     52431\n",
      " 2.0     33814\n",
      " 3.0     20164\n",
      " 4.0     10797\n",
      " 5.0      8320\n",
      " 6.0      6500\n",
      " 7.0      4821\n",
      " 8.0      3983\n",
      "Name: quality_5, dtype: int64\n",
      " 0      594594\n",
      "-1      141866\n",
      " 600      1848\n",
      " 1        1206\n",
      " 5         548\n",
      " 2         521\n",
      " 3         418\n",
      " 4         400\n",
      " 6         393\n",
      " 10        309\n",
      "Name: quality_6, dtype: int64\n",
      "0.0     682584\n",
      "1.0       6408\n",
      "5.0       3612\n",
      "2.0       2988\n",
      "6.0       2400\n",
      "3.0       2220\n",
      "4.0       2100\n",
      "10.0      1644\n",
      "11.0      1548\n",
      "7.0       1224\n",
      "Name: quality_7, dtype: int64\n",
      "0.0    707868\n",
      "1.0     18504\n",
      "2.0      8304\n",
      "3.0      4116\n",
      "4.0      2424\n",
      "5.0      1668\n",
      "6.0      1188\n",
      "7.0       792\n",
      "8.0       480\n",
      "9.0       384\n",
      "Name: quality_8, dtype: int64\n",
      "0.0    715716\n",
      "1.0      8772\n",
      "2.0      3132\n",
      "3.0      1920\n",
      "4.0      1344\n",
      "5.0      1248\n",
      "6.0       744\n",
      "7.0       696\n",
      "8.0       684\n",
      "9.0       564\n",
      "Name: quality_9, dtype: int64\n",
      "3.0    98688\n",
      "2.0    78984\n",
      "1.0    58608\n",
      "4.0    55608\n",
      "0.0    45072\n",
      "5.0    41208\n",
      "6.0    32460\n",
      "7.0    22056\n",
      "8.0    17952\n",
      "9.0    15588\n",
      "Name: quality_10, dtype: int64\n",
      " 0     603983\n",
      "-1     141917\n",
      " 1       1816\n",
      " 2        169\n",
      " 3         45\n",
      " 4         20\n",
      " 5         10\n",
      " 6          4\n",
      " 12         2\n",
      " 9          2\n",
      "Name: quality_11, dtype: int64\n",
      "0    727188\n",
      "1     16140\n",
      "2      2976\n",
      "3       828\n",
      "4       264\n",
      "6       168\n",
      "5       132\n",
      "8        72\n",
      "9        48\n",
      "7        36\n",
      "Name: quality_12, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    print(test_q['quality_{}'.format(i)].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7, 8, 9, 10, 12 는 음수 값이 없습니다. 0, 1, 2, 5, 6, 11 은 음수 값이 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_some = train_q[['user_id', 'quality_7', 'quality_8', 'quality_9', 'quality_10', 'quality_12']]\n",
    "test_q_some = test_q[['user_id', 'quality_7', 'quality_8', 'quality_9', 'quality_10', 'quality_12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828619</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828620</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828621</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828622</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828623</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>828624 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  quality_7  quality_8  quality_9  quality_10  quality_12\n",
       "0         10000        0.0        0.0        0.0         4.0           0\n",
       "1         10000        0.0        0.0        0.0         4.0           0\n",
       "2         10000        0.0        0.0        0.0         4.0           0\n",
       "3         10000        0.0        0.0        0.0         4.0           0\n",
       "4         10000        0.0        0.0        0.0         4.0           0\n",
       "...         ...        ...        ...        ...         ...         ...\n",
       "828619    24997        0.0        0.0        0.0        17.0           0\n",
       "828620    24997        0.0        0.0        0.0        17.0           0\n",
       "828621    24997        0.0        0.0        0.0        17.0           0\n",
       "828622    24997        0.0        0.0        0.0        17.0           0\n",
       "828623    24997        0.0        0.0        0.0        17.0           0\n",
       "\n",
       "[828624 rows x 6 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q_some"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이걸로 뭘 할 수 있을 것인가.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quality 별로 몇 번이나 기록되었는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count를 위해서 0 값을 전부 nan으로 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_counts = train_q_temp.groupby('user_id').count()\n",
    "test_qual_counts = test_q_temp.groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']\n",
    "test_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리더보드는 올랐습니다. 아주 미세하게."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fwver별로 quality 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>10229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  target\n",
       "229    10229       0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_b_p[train_b_p.user_id == 10229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10152</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.176338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.537695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10153</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.775532</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>10154</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>1.083625</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10154</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>114.374851</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>284.489936</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10158</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10160</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>10161</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>1.403459</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10163</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.698211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.846565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>10163</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>0.424744</td>\n",
       "      <td>0.424744</td>\n",
       "      <td>0.424744</td>\n",
       "      <td>1.090741</td>\n",
       "      <td>0.424744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.891661</td>\n",
       "      <td>0.424744</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>10165</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.513315</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>1.502379</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.421975</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>10166</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.337832</td>\n",
       "      <td>0.337832</td>\n",
       "      <td>0.337832</td>\n",
       "      <td>0.740887</td>\n",
       "      <td>0.337832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.337832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>10166</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>1155.695948</td>\n",
       "      <td>0.474713</td>\n",
       "      <td>0.769122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3670.702658</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>10167</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>0.447195</td>\n",
       "      <td>47.962925</td>\n",
       "      <td>0.447195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>257.546977</td>\n",
       "      <td>0.524375</td>\n",
       "      <td>0.772490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>10168</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10171</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.240894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.406952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10173</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>10173</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.279310</td>\n",
       "      <td>0.319990</td>\n",
       "      <td>0.279310</td>\n",
       "      <td>2.825605</td>\n",
       "      <td>8.587059</td>\n",
       "      <td>30.619143</td>\n",
       "      <td>0.437595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.374482</td>\n",
       "      <td>0.279310</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>10174</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>1.083625</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>10174</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.201941</td>\n",
       "      <td>0.201941</td>\n",
       "      <td>0.201941</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>61.318261</td>\n",
       "      <td>247.153498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.237706</td>\n",
       "      <td>0.201941</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>10175</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1475.799614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4474.846590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>10178</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>1151.823500</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3818.857552</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>10184</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>3.120468</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.596785</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>10187</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>1.690383</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.531579</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>10188</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.937437</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>10189</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.494535</td>\n",
       "      <td>0.494535</td>\n",
       "      <td>0.494535</td>\n",
       "      <td>1.075922</td>\n",
       "      <td>0.494535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494535</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>10191</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>30.310889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>10192</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>1.288057</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>10193</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>0.806450</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>10194</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.278718</td>\n",
       "      <td>0.278718</td>\n",
       "      <td>0.278718</td>\n",
       "      <td>1.112208</td>\n",
       "      <td>0.596364</td>\n",
       "      <td>1.613502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.955436</td>\n",
       "      <td>0.278718</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>10195</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.354154</td>\n",
       "      <td>0.778117</td>\n",
       "      <td>0.330550</td>\n",
       "      <td>0.441972</td>\n",
       "      <td>1.969092</td>\n",
       "      <td>6.279710</td>\n",
       "      <td>2.013990</td>\n",
       "      <td>0.326786</td>\n",
       "      <td>1.105692</td>\n",
       "      <td>0.311512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>10197</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>1.544786</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>10198</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.729862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>10198</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>10199</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.852803</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>10201</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2011.578485</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8274.567783</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>10203</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.442326</td>\n",
       "      <td>0.442326</td>\n",
       "      <td>0.442326</td>\n",
       "      <td>0.907896</td>\n",
       "      <td>0.637022</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.442326</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>10205</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.318728</td>\n",
       "      <td>0.318728</td>\n",
       "      <td>0.318728</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.368394</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.656157</td>\n",
       "      <td>0.318728</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>10206</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390205</td>\n",
       "      <td>0.390205</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.390205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806751</td>\n",
       "      <td>0.390205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>10207</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360085</td>\n",
       "      <td>0.360085</td>\n",
       "      <td>1.470616</td>\n",
       "      <td>0.360085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.735826</td>\n",
       "      <td>0.360085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>10208</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>10209</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.280306</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.280306</td>\n",
       "      <td>0.814550</td>\n",
       "      <td>0.280306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.912366</td>\n",
       "      <td>0.280306</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>10210</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10210</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.418657</td>\n",
       "      <td>0.418657</td>\n",
       "      <td>0.418657</td>\n",
       "      <td>0.963740</td>\n",
       "      <td>0.418657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581402</td>\n",
       "      <td>0.418657</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>10213</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>1.593698</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.626490</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10213</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>0.230669</td>\n",
       "      <td>0.230669</td>\n",
       "      <td>0.230669</td>\n",
       "      <td>0.882361</td>\n",
       "      <td>0.230669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230669</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>10214</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.738549</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>10215</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>1.114641</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>10217</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498825</td>\n",
       "      <td>0.443353</td>\n",
       "      <td>0.460972</td>\n",
       "      <td>0.443353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331295</td>\n",
       "      <td>0.546509</td>\n",
       "      <td>0.624695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>10218</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.624094</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.750604</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.532262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.532262</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>10218</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>10219</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>1.133543</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>10219</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.502432</td>\n",
       "      <td>0.502432</td>\n",
       "      <td>0.502432</td>\n",
       "      <td>2.270694</td>\n",
       "      <td>0.502432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.953484</td>\n",
       "      <td>0.502432</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>10222</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>10226</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>21.561048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>10227</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.883627</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.064523</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>10229</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.854493</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.723783</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>10229</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.385293</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.385293</td>\n",
       "      <td>0.719673</td>\n",
       "      <td>6.401231</td>\n",
       "      <td>23.418956</td>\n",
       "      <td>1.408115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.202407</td>\n",
       "      <td>0.385293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>10232</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.508977</td>\n",
       "      <td>0.508977</td>\n",
       "      <td>0.508977</td>\n",
       "      <td>1.090140</td>\n",
       "      <td>18.883654</td>\n",
       "      <td>46.989360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.532262</td>\n",
       "      <td>0.508977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>10234</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.476257</td>\n",
       "      <td>0.476257</td>\n",
       "      <td>0.476257</td>\n",
       "      <td>0.947317</td>\n",
       "      <td>0.476257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.205031</td>\n",
       "      <td>0.476257</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>10234</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>0.506309</td>\n",
       "      <td>0.506309</td>\n",
       "      <td>0.506309</td>\n",
       "      <td>1.236996</td>\n",
       "      <td>0.506309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.956183</td>\n",
       "      <td>0.506309</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>10235</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>10236</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.404669</td>\n",
       "      <td>0.414232</td>\n",
       "      <td>0.404669</td>\n",
       "      <td>59.842004</td>\n",
       "      <td>7.956816</td>\n",
       "      <td>32.702184</td>\n",
       "      <td>0.249791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.513062</td>\n",
       "      <td>0.404669</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>10237</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>1.083625</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>10238</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>10239</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.235317</td>\n",
       "      <td>0.235317</td>\n",
       "      <td>0.235317</td>\n",
       "      <td>11.357166</td>\n",
       "      <td>50.632654</td>\n",
       "      <td>303.198934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.016798</td>\n",
       "      <td>0.235317</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>10241</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>1.114641</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>10242</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>217.161161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>10243</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>10246</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>0.988408</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>47.159262</td>\n",
       "      <td>189.478623</td>\n",
       "      <td>1.237706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>10246</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.376409</td>\n",
       "      <td>1.878985</td>\n",
       "      <td>0.376409</td>\n",
       "      <td>0.397421</td>\n",
       "      <td>0.376409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.514794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400348</td>\n",
       "      <td>0.376409</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>10249</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>1.742102</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>10251</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.815240</td>\n",
       "      <td>0.200104</td>\n",
       "      <td>0.815240</td>\n",
       "      <td>2.307187</td>\n",
       "      <td>0.200104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.550875</td>\n",
       "      <td>8.292965</td>\n",
       "      <td>0.200104</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>10252</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>10253</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.175426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>10255</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.764550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>10256</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>10259</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>22.259341</td>\n",
       "      <td>55.672178</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>10262</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.427672</td>\n",
       "      <td>0.427672</td>\n",
       "      <td>0.427672</td>\n",
       "      <td>1.365157</td>\n",
       "      <td>0.427672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.014035</td>\n",
       "      <td>0.427672</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>10263</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334219</td>\n",
       "      <td>0.334219</td>\n",
       "      <td>0.976451</td>\n",
       "      <td>0.334219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.187975</td>\n",
       "      <td>0.334219</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>10264</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>10265</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>8218.649524</td>\n",
       "      <td>1702.862149</td>\n",
       "      <td>10.957036</td>\n",
       "      <td>50.051180</td>\n",
       "      <td>0.156206</td>\n",
       "      <td>37143.187585</td>\n",
       "      <td>5885.144688</td>\n",
       "      <td>0.184206</td>\n",
       "      <td>0.329707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>10266</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>1084.930067</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3388.556772</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>10268</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>10270</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>1.651446</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>10271</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.834058</td>\n",
       "      <td>13.726891</td>\n",
       "      <td>34.220512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.532262</td>\n",
       "      <td>0.414851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>10273</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.454257</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454257</td>\n",
       "      <td>1.472499</td>\n",
       "      <td>0.454257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.484236</td>\n",
       "      <td>0.454257</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>10275</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>10276</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>34.501976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>10277</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>1057.589831</td>\n",
       "      <td>0.453641</td>\n",
       "      <td>0.750587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3366.681304</td>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>10278</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.900337</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10279</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.891995</td>\n",
       "      <td>14.751477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>10280</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>1.443376</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>10281</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.474115</td>\n",
       "      <td>0.474115</td>\n",
       "      <td>0.474115</td>\n",
       "      <td>87.959727</td>\n",
       "      <td>0.474115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>700.370215</td>\n",
       "      <td>0.474115</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>10281</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>1.114641</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>10282</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.308709</td>\n",
       "      <td>0.308709</td>\n",
       "      <td>0.308709</td>\n",
       "      <td>0.665447</td>\n",
       "      <td>0.308709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308709</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>10285</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.572671</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>10287</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>10288</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>1.138180</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>10289</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.836262</td>\n",
       "      <td>13.790746</td>\n",
       "      <td>43.909318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.848276</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>10290</td>\n",
       "      <td>04.33.1185</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>1.075922</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id       fwver  quality_0  quality_1    quality_2    quality_5  \\\n",
       "100    10152  04.16.3553   0.000000   0.204124     0.000000    16.176338   \n",
       "101    10153  04.33.1261   0.380693   0.380693     0.380693     0.775532   \n",
       "102    10154  04.33.1185   0.492366   0.492366     0.492366     1.083625   \n",
       "103    10154  04.33.1261   0.503610   0.503610     0.503610   114.374851   \n",
       "104    10158  04.16.3553   0.000000   0.000000     0.000000     0.900337   \n",
       "105    10160  04.16.3553   0.000000   0.000000     0.000000     0.621582   \n",
       "106    10161  04.16.3553   0.522233   0.522233     0.522233     1.403459   \n",
       "107    10163  04.22.1750   0.000000   0.000000     0.000000     1.698211   \n",
       "108    10163  04.22.1778   0.424744   0.424744     0.424744     1.090741   \n",
       "109    10165  04.16.3553   0.467177   0.513315     0.467177     1.502379   \n",
       "110    10166  04.33.1185   0.337832   0.337832     0.337832     0.740887   \n",
       "111    10166  04.33.1261   0.408966   0.408966     0.408966  1155.695948   \n",
       "112    10167  03.11.1167   0.000000   0.464306     0.447195    47.962925   \n",
       "113    10168  03.11.1167   0.000000   0.000000     0.000000     0.288675   \n",
       "114    10171  03.11.1167   0.000000   0.000000     0.000000    29.240894   \n",
       "115    10173  04.16.3553   0.000000   0.000000     0.000000     0.721060   \n",
       "116    10173  04.33.1261   0.279310   0.319990     0.279310     2.825605   \n",
       "117    10174  04.33.1185   0.514929   0.514929     0.514929     1.083625   \n",
       "118    10174  04.33.1261   0.201941   0.201941     0.201941     0.503534   \n",
       "119    10175  04.16.3553   0.000000   0.000000     0.000000  1475.799614   \n",
       "120    10178  04.22.1750   0.436667   0.436667     0.436667  1151.823500   \n",
       "121    10184  05.15.2138   0.481543   0.481543     0.481543     3.120468   \n",
       "122    10187  04.16.3553   0.375293   0.375293     0.375293     1.690383   \n",
       "123    10188  04.16.3553   0.288675   0.288675     0.288675     0.937437   \n",
       "124    10189  04.22.1750   0.494535   0.494535     0.494535     1.075922   \n",
       "125    10191  05.15.2138   0.000000   0.000000     0.000000     0.866025   \n",
       "126    10192  04.33.1261   0.492366   0.492366     0.492366     1.288057   \n",
       "127    10193  05.15.2138   0.612372   0.414851     0.481543     0.806450   \n",
       "128    10194  04.16.3553   0.278718   0.278718     0.278718     1.112208   \n",
       "129    10195  05.15.2138   0.354154   0.778117     0.330550     0.441972   \n",
       "130    10197  04.16.3553   0.389249   0.389249     0.389249     1.544786   \n",
       "131    10198  04.33.1185   0.000000   0.000000     0.000000     1.729862   \n",
       "132    10198  04.33.1261   0.000000   0.000000     0.000000     0.577350   \n",
       "133    10199  04.22.1778   0.452267   0.452267     0.452267     0.852803   \n",
       "134    10201  04.22.1750   0.166667   0.166667     0.166667  2011.578485   \n",
       "135    10203  05.15.2138   0.442326   0.442326     0.442326     0.907896   \n",
       "136    10205  05.15.2138   0.318728   0.318728     0.318728     0.761682   \n",
       "137    10206  03.11.1167   0.000000   0.390205     0.390205     0.578328   \n",
       "138    10207  03.11.1167   0.000000   0.360085     0.360085     1.470616   \n",
       "139    10208  04.22.1750   0.000000   0.000000     0.000000     0.710939   \n",
       "140    10209  04.16.3553   0.280306   0.333333     0.280306     0.814550   \n",
       "141    10210  04.33.1185   0.000000   0.000000     0.000000     0.999094   \n",
       "142    10210  04.33.1261   0.418657   0.418657     0.418657     0.963740   \n",
       "143    10213  04.22.1750   0.109109   0.109109     0.109109     1.593698   \n",
       "144    10213  04.22.1778   0.230669   0.230669     0.230669     0.882361   \n",
       "145    10214  04.16.3553   0.389249   0.389249     0.389249     0.738549   \n",
       "146    10215  04.16.3553   0.514929   0.514929     0.514929     1.114641   \n",
       "147    10217  03.11.1167   0.000000   0.498825     0.443353     0.460972   \n",
       "148    10218  04.22.1750   0.380693   0.624094     0.380693     0.750604   \n",
       "149    10218  04.22.1778   0.514929   0.514929     0.514929     1.154701   \n",
       "150    10219  04.33.1185   0.467177   0.467177     0.467177     1.133543   \n",
       "151    10219  04.33.1261   0.502432   0.502432     0.502432     2.270694   \n",
       "152    10222  04.33.1261   0.000000   0.000000     0.000000     1.154701   \n",
       "153    10226  04.22.1750   0.000000   0.000000     0.000000     0.288675   \n",
       "154    10227  04.33.1185   0.414851   0.414851     0.414851     0.883627   \n",
       "155    10229  04.33.1185   0.401386   0.401386     0.401386     0.854493   \n",
       "156    10229  04.33.1261   0.385293   0.596774     0.385293     0.719673   \n",
       "157    10232  04.16.3553   0.508977   0.508977     0.508977     1.090140   \n",
       "158    10234  04.22.1750   0.476257   0.476257     0.476257     0.947317   \n",
       "159    10234  04.22.1778   0.506309   0.506309     0.506309     1.236996   \n",
       "160    10235  04.22.1778   0.000000   0.000000     0.000000     0.577350   \n",
       "161    10236  04.16.3553   0.404669   0.414232     0.404669    59.842004   \n",
       "162    10237  04.33.1185   0.492366   0.492366     0.492366     1.083625   \n",
       "163    10238  05.15.2138   0.000000   0.000000     0.000000     0.577350   \n",
       "164    10239  04.16.3553   0.235317   0.235317     0.235317    11.357166   \n",
       "165    10241  05.15.2138   0.514929   0.514929     0.514929     1.114641   \n",
       "166    10242  04.33.1261   0.000000   0.000000     0.000000     0.000000   \n",
       "167    10243  03.11.1167   0.000000   0.514929     0.514929     0.792961   \n",
       "168    10246  04.33.1185   0.503534   0.988408     0.503534     0.503534   \n",
       "169    10246  04.33.1261   0.376409   1.878985     0.376409     0.397421   \n",
       "170    10249  04.16.3553   0.478091   0.478091     0.478091     1.742102   \n",
       "171    10251  05.15.2138   0.815240   0.200104     0.815240     2.307187   \n",
       "172    10252  04.16.3553   0.000000   0.000000     0.000000     0.866025   \n",
       "173    10253  04.22.1750   0.000000   0.000000     0.000000     3.175426   \n",
       "174    10255  04.33.1185   0.000000   0.000000     0.000000     1.764550   \n",
       "175    10256  04.22.1778   0.000000   0.000000     0.000000     2.000000   \n",
       "176    10259  04.33.1185   0.204124   0.464306     0.204124     0.294884   \n",
       "177    10262  04.16.3553   0.427672   0.427672     0.427672     1.365157   \n",
       "178    10263  03.11.1167   0.000000   0.334219     0.334219     0.976451   \n",
       "179    10264  04.33.1261   0.000000   0.000000     0.000000     0.577350   \n",
       "180    10265  03.11.1167   0.000000   0.169031  8218.649524  1702.862149   \n",
       "181    10266  05.15.2138   0.251549   0.251549     0.251549  1084.930067   \n",
       "182    10268  03.11.1167   0.000000   0.000000     0.000000     0.000000   \n",
       "183    10270  04.22.1750   0.514929   0.514929     0.514929     1.651446   \n",
       "184    10271  04.22.1750   0.414851   0.414851     0.414851     0.834058   \n",
       "185    10273  05.15.2138   0.454257   0.500000     0.454257     1.472499   \n",
       "186    10275  04.22.1750   0.000000   0.000000     0.000000     1.154701   \n",
       "187    10276  04.22.1750   0.000000   0.000000     0.000000     0.389249   \n",
       "188    10277  04.16.3553   0.375293   0.375293     0.375293  1057.589831   \n",
       "189    10278  04.16.3553   0.452267   0.452267     0.452267     0.900337   \n",
       "190    10279  05.15.2138   0.288675   0.288675     0.288675     2.891995   \n",
       "191    10280  04.22.1750   0.452267   0.452267     0.452267     1.443376   \n",
       "192    10281  04.33.1185   0.474115   0.474115     0.474115    87.959727   \n",
       "193    10281  04.33.1261   0.514929   0.514929     0.514929     1.114641   \n",
       "194    10282  05.15.2138   0.308709   0.308709     0.308709     0.665447   \n",
       "195    10285  05.15.2138   0.500000   0.500000     0.500000     1.500000   \n",
       "196    10287  04.22.1750   0.000000   0.000000     0.000000     0.866025   \n",
       "197    10288  05.15.2138   0.522233   0.522233     0.522233     1.138180   \n",
       "198    10289  05.15.2138   0.117851   0.117851     0.117851     0.836262   \n",
       "199    10290  04.33.1185   0.464306   0.464306     0.464306     1.075922   \n",
       "\n",
       "      quality_6   quality_7  quality_8     quality_9   quality_10  quality_11  \\\n",
       "100    0.000000    0.000000   0.510754      0.000000    25.537695    0.000000   \n",
       "101    0.380693    0.000000   0.000000      0.000000     1.021508    0.380693   \n",
       "102    0.492366    0.000000   0.000000      0.000000     0.000000    0.492366   \n",
       "103    0.503610    0.000000   0.000000      0.000000   284.489936    0.503610   \n",
       "104    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "105    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "106    0.522233    0.000000   0.000000      0.000000     0.000000    0.522233   \n",
       "107    0.000000    0.000000   0.000000      0.000000     5.846565    0.000000   \n",
       "108    0.424744    0.000000   0.000000      0.000000     2.891661    0.424744   \n",
       "109    0.467177    0.000000   0.478091      0.000000     7.421975    0.467177   \n",
       "110    0.337832    0.000000   0.000000      0.000000     1.021508    0.337832   \n",
       "111    0.474713    0.769122   0.000000      0.000000  3670.702658    0.408966   \n",
       "112    0.447195    0.000000   0.354360      0.000000   257.546977    0.524375   \n",
       "113    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "114    0.000000    0.000000   0.000000      0.000000    97.406952    0.000000   \n",
       "115    0.000000    0.000000   0.000000      0.000000     0.510754    0.000000   \n",
       "116    8.587059   30.619143   0.437595      0.000000     7.374482    0.279310   \n",
       "117    0.514929    0.000000   0.000000      0.000000     0.000000    0.514929   \n",
       "118   61.318261  247.153498   0.000000      0.000000     1.237706    0.201941   \n",
       "119    0.000000    0.000000   0.000000      0.000000  4474.846590    0.000000   \n",
       "120    0.436667    0.000000   0.000000      0.000000  3818.857552    0.436667   \n",
       "121    0.481543    0.000000   0.000000      0.000000     4.596785    0.481543   \n",
       "122    0.375293    0.000000   0.000000      0.000000     4.531579    0.375293   \n",
       "123    0.288675    0.000000   0.000000      0.000000     0.000000    0.288675   \n",
       "124    0.494535    0.000000   0.000000      0.000000     0.000000    0.494535   \n",
       "125   30.310889    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "126    0.492366    0.000000   0.000000      0.000000     0.000000    0.492366   \n",
       "127    0.414851    0.000000   0.000000      0.510754     1.021508    0.414851   \n",
       "128    0.596364    1.613502   0.000000      0.000000     1.955436    0.278718   \n",
       "129    1.969092    6.279710   2.013990      0.326786     1.105692    0.311512   \n",
       "130    0.389249    0.000000   0.000000      0.000000     0.000000    0.389249   \n",
       "131    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "132    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "133    0.452267    0.000000   0.000000      0.000000     0.000000    0.452267   \n",
       "134    0.166667    0.000000   0.000000      0.000000  8274.567783    0.166667   \n",
       "135    0.637022    1.021508   0.000000      0.000000     0.510754    0.442326   \n",
       "136    0.368394    0.478091   0.000000      0.000000     1.656157    0.318728   \n",
       "137    0.390205    0.000000   0.000000      0.000000     0.806751    0.390205   \n",
       "138    0.360085    0.000000   0.000000      0.000000     2.735826    0.360085   \n",
       "139    0.000000    0.000000   0.000000      0.000000     0.510754    0.000000   \n",
       "140    0.280306    0.000000   0.478091      0.000000     1.912366    0.280306   \n",
       "141    0.000000    0.000000   0.000000      0.000000     0.510754    0.000000   \n",
       "142    0.418657    0.000000   0.000000      0.000000     0.581402    0.418657   \n",
       "143    0.109109    0.000000   0.000000      0.000000     2.626490    0.109109   \n",
       "144    0.230669    0.000000   0.000000      0.000000     0.000000    0.230669   \n",
       "145    0.389249    0.000000   0.000000      0.000000     0.000000    0.389249   \n",
       "146    0.514929    0.000000   0.000000      0.000000     0.000000    0.514929   \n",
       "147    0.443353    0.000000   0.493865      0.000000     0.331295    0.546509   \n",
       "148    0.380693    0.000000   1.532262      0.000000     1.532262    0.380693   \n",
       "149    0.514929    0.000000   0.000000      0.000000     0.000000    0.514929   \n",
       "150    0.467177    0.000000   0.000000      0.000000     0.478091    0.467177   \n",
       "151    0.502432    0.000000   0.000000      0.000000     4.953484    0.502432   \n",
       "152    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "153   21.561048    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "154    0.414851    0.000000   0.000000      0.000000     3.064523    0.414851   \n",
       "155    0.401386    0.000000   0.000000      0.000000     1.723783    0.401386   \n",
       "156    6.401231   23.418956   1.408115      0.000000     1.202407    0.385293   \n",
       "157   18.883654   46.989360   0.000000      0.000000     1.532262    0.508977   \n",
       "158    0.476257    0.000000   0.000000      0.000000     1.205031    0.476257   \n",
       "159    0.506309    0.000000   0.000000      0.000000     0.956183    0.506309   \n",
       "160    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "161    7.956816   32.702184   0.249791      0.000000   283.513062    0.404669   \n",
       "162    0.492366    0.000000   0.000000      0.000000     0.000000    0.492366   \n",
       "163    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "164   50.632654  303.198934   0.000000      0.000000    75.016798    0.235317   \n",
       "165    0.514929    0.000000   0.000000      0.000000     0.000000    0.514929   \n",
       "166  217.161161    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "167    0.514929    0.000000   0.000000      0.000000     0.000000    0.514929   \n",
       "168   47.159262  189.478623   1.237706      0.000000     0.000000    0.503534   \n",
       "169    0.376409    0.000000   7.514794      0.000000     0.400348    0.376409   \n",
       "170    0.478091    0.000000   0.000000      0.000000     1.264911    0.478091   \n",
       "171    0.200104    0.000000   0.000000      2.550875     8.292965    0.200104   \n",
       "172    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "173    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "174    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "175    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "176   22.259341   55.672178   1.021508      0.000000     0.510754    0.204124   \n",
       "177    0.427672    0.000000   0.000000      0.000000     2.014035    0.427672   \n",
       "178    0.334219    0.000000   0.000000      0.000000     2.187975    0.334219   \n",
       "179    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "180   10.957036   50.051180   0.156206  37143.187585  5885.144688    0.184206   \n",
       "181    0.251549    0.000000   0.000000      0.000000  3388.556772    0.251549   \n",
       "182    0.288675    0.000000   0.000000      0.000000     0.000000    0.288675   \n",
       "183    0.514929    0.000000   0.000000      0.000000     0.000000    0.514929   \n",
       "184   13.726891   34.220512   0.000000      0.000000     1.532262    0.414851   \n",
       "185    0.454257    0.000000   0.478091      0.000000     2.484236    0.454257   \n",
       "186    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "187   34.501976    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "188    0.453641    0.750587   0.000000      0.000000  3366.681304    0.375293   \n",
       "189    0.452267    0.000000   0.000000      0.000000     0.000000    0.452267   \n",
       "190   14.751477    0.000000   0.000000      0.000000     0.000000    0.288675   \n",
       "191    0.452267    0.000000   0.000000      0.000000     0.000000    0.452267   \n",
       "192    0.474115    0.000000   0.000000      0.000000   700.370215    0.474115   \n",
       "193    0.514929    0.000000   0.000000      0.000000     0.000000    0.514929   \n",
       "194    0.308709    0.000000   0.000000      0.000000     0.000000    0.308709   \n",
       "195    0.500000    0.000000   0.000000      0.000000     6.572671    0.500000   \n",
       "196    0.000000    0.000000   0.000000      0.000000     0.000000    0.000000   \n",
       "197    0.522233    0.000000   0.000000      0.000000     0.000000    0.522233   \n",
       "198   13.790746   43.909318   0.000000      0.000000     2.848276    0.117851   \n",
       "199    0.464306    0.000000   0.000000      0.000000     1.021508    0.464306   \n",
       "\n",
       "     quality_12  \n",
       "100    0.000000  \n",
       "101    0.000000  \n",
       "102    0.000000  \n",
       "103    0.000000  \n",
       "104    0.000000  \n",
       "105    0.000000  \n",
       "106    0.000000  \n",
       "107    0.000000  \n",
       "108    0.000000  \n",
       "109    0.000000  \n",
       "110    0.000000  \n",
       "111    0.000000  \n",
       "112    0.772490  \n",
       "113    0.000000  \n",
       "114    0.000000  \n",
       "115    0.000000  \n",
       "116    0.000000  \n",
       "117    0.000000  \n",
       "118    0.000000  \n",
       "119    0.000000  \n",
       "120    0.000000  \n",
       "121    0.000000  \n",
       "122    0.000000  \n",
       "123    0.000000  \n",
       "124    0.000000  \n",
       "125    0.000000  \n",
       "126    0.000000  \n",
       "127    0.000000  \n",
       "128    0.000000  \n",
       "129    0.000000  \n",
       "130    0.000000  \n",
       "131    0.000000  \n",
       "132    0.000000  \n",
       "133    0.000000  \n",
       "134    0.000000  \n",
       "135    0.000000  \n",
       "136    0.000000  \n",
       "137    0.000000  \n",
       "138    0.000000  \n",
       "139    0.000000  \n",
       "140    0.000000  \n",
       "141    0.000000  \n",
       "142    0.000000  \n",
       "143    0.000000  \n",
       "144    0.000000  \n",
       "145    0.000000  \n",
       "146    0.000000  \n",
       "147    0.624695  \n",
       "148    0.000000  \n",
       "149    0.000000  \n",
       "150    0.000000  \n",
       "151    0.000000  \n",
       "152    0.000000  \n",
       "153    0.000000  \n",
       "154    0.000000  \n",
       "155    0.000000  \n",
       "156    0.000000  \n",
       "157    0.000000  \n",
       "158    0.000000  \n",
       "159    0.000000  \n",
       "160    0.000000  \n",
       "161    0.000000  \n",
       "162    0.000000  \n",
       "163    0.000000  \n",
       "164    0.000000  \n",
       "165    0.000000  \n",
       "166    0.000000  \n",
       "167    0.000000  \n",
       "168    0.000000  \n",
       "169    0.000000  \n",
       "170    0.000000  \n",
       "171    0.000000  \n",
       "172    0.000000  \n",
       "173    0.000000  \n",
       "174    0.000000  \n",
       "175    0.000000  \n",
       "176    0.000000  \n",
       "177    0.000000  \n",
       "178    0.000000  \n",
       "179    0.000000  \n",
       "180    0.329707  \n",
       "181    0.000000  \n",
       "182    0.000000  \n",
       "183    0.000000  \n",
       "184    0.000000  \n",
       "185    0.000000  \n",
       "186    0.000000  \n",
       "187    0.000000  \n",
       "188    0.000000  \n",
       "189    0.000000  \n",
       "190    0.000000  \n",
       "191    0.000000  \n",
       "192    0.000000  \n",
       "193    0.000000  \n",
       "194    0.000000  \n",
       "195    0.000000  \n",
       "196    0.000000  \n",
       "197    0.000000  \n",
       "198    0.000000  \n",
       "199    0.000000  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q.groupby(['user_id', 'fwver']).std().reset_index()[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survived Features from Feature Collection 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from Error_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보유한 model의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_count = train_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()\n",
    "test_model_count = test_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보유한 fwver 의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fwver_count = train_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()\n",
    "test_fwver_count = test_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경험한 error 의 총 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_count = train_e.groupby('user_id')['errcode'].count()\n",
    "test_err_count = test_e.groupby('user_id')['errcode'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경험한 각 errtype의 values의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33호\n",
    "train_errcode_33 = train_e[train_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_33 = test_e[test_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']\n",
    "test_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23호\n",
    "train_errcode_23 = train_e[train_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_23 = test_e[test_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']\n",
    "test_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34호\n",
    "train_errcode_34 = train_e[train_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_34 = test_e[test_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']\n",
    "test_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from Quality_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 quality의 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_std = train_q.groupby(['user_id']).std()\n",
    "test_qual_std = test_q.groupby(['user_id']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기록한 quality log의 개수(12개당 1번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_log = train_q.groupby('user_id')['time'].count()/12\n",
    "test_qual_log = test_q.groupby('user_id')['time'].count()/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "y = test_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나 사라진 유저를 채워주는 코드입니다.\n",
    "y = y.reindex(pd.RangeIndex(y.index.max() + 1)).ffill(0)[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 41), (14999, 41))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 73)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,\n",
    "               train_err_count,\n",
    "               train_fwver_count,\n",
    "               train_model_count,\n",
    "               train_qual_std,\n",
    "               train_qual_log,\n",
    "               train_errcode_23,\n",
    "               train_errcode_33,\n",
    "               train_errcode_34], axis=1).fillna(0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 73)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat([y,\n",
    "               test_err_count,\n",
    "               test_fwver_count,\n",
    "               test_model_count,\n",
    "               test_qual_std,\n",
    "               test_qual_log,\n",
    "               test_errcode_23,\n",
    "               test_errcode_33,\n",
    "               test_errcode_34], axis=1).fillna(0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 84), (14999, 84))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = pd.concat([X, train_qual_counts], axis=1).fillna(0)\n",
    "y_temp = pd.concat([y, test_qual_counts], axis=1).fillna(0)\n",
    "\n",
    "X_temp.shape, y_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def s_fold_train_pred(train_x, train_y):\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'boosting_type' : 'gbdt',\n",
    "                    'objective'     : 'binary',\n",
    "                    'metric'        : 'auc',\n",
    "                    'learning_rate' : 0.027\n",
    "                    #, 'seed': 42\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True\n",
    "                            # ,random_state=42\n",
    "                            )    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        d_train= lgb.Dataset(X, y)\n",
    "        d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "\n",
    "        #run traning\n",
    "        model = lgb.train(\n",
    "                            params,\n",
    "                            train_set       = d_train,\n",
    "                            num_boost_round = 10000,\n",
    "                            valid_sets      = d_val,\n",
    "                            feval           = f_pr_auc,\n",
    "                            verbose_eval    = 100, \n",
    "                            early_stopping_rounds = 100\n",
    "                           )\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8437\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.824625\tvalid_0's pr_auc: 0.753418\n",
      "[200]\tvalid_0's auc: 0.826954\tvalid_0's pr_auc: 0.75765\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.827184\tvalid_0's pr_auc: 0.758623\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8394\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.839051\tvalid_0's pr_auc: 0.760674\n",
      "[200]\tvalid_0's auc: 0.838791\tvalid_0's pr_auc: 0.765098\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.839503\tvalid_0's pr_auc: 0.76352\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8420\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.829509\tvalid_0's pr_auc: 0.750077\n",
      "[200]\tvalid_0's auc: 0.833398\tvalid_0's pr_auc: 0.754796\n",
      "[300]\tvalid_0's auc: 0.832878\tvalid_0's pr_auc: 0.755133\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's auc: 0.833768\tvalid_0's pr_auc: 0.75618\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8385\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.80655\tvalid_0's pr_auc: 0.720824\n",
      "[200]\tvalid_0's auc: 0.809233\tvalid_0's pr_auc: 0.733931\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's auc: 0.809797\tvalid_0's pr_auc: 0.734516\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8399\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.820934\tvalid_0's pr_auc: 0.757181\n",
      "[200]\tvalid_0's auc: 0.822434\tvalid_0's pr_auc: 0.757999\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's auc: 0.822636\tvalid_0's pr_auc: 0.757324\n",
      "==========================================================\n",
      "0.8265775\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9968\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.844553\tvalid_0's pr_auc: 0.779143\n",
      "[200]\tvalid_0's auc: 0.846927\tvalid_0's pr_auc: 0.781522\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.847116\tvalid_0's pr_auc: 0.782575\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9958\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.818808\tvalid_0's pr_auc: 0.741598\n",
      "[200]\tvalid_0's auc: 0.820662\tvalid_0's pr_auc: 0.749467\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's auc: 0.820716\tvalid_0's pr_auc: 0.749897\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10088\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.81917\tvalid_0's pr_auc: 0.730153\n",
      "[200]\tvalid_0's auc: 0.820045\tvalid_0's pr_auc: 0.734009\n",
      "[300]\tvalid_0's auc: 0.820161\tvalid_0's pr_auc: 0.73342\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's auc: 0.820851\tvalid_0's pr_auc: 0.734369\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10169\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.828627\tvalid_0's pr_auc: 0.753385\n",
      "[200]\tvalid_0's auc: 0.830974\tvalid_0's pr_auc: 0.759149\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.831631\tvalid_0's pr_auc: 0.759024\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10090\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.819847\tvalid_0's pr_auc: 0.728806\n",
      "[200]\tvalid_0's auc: 0.822344\tvalid_0's pr_auc: 0.743223\n",
      "[300]\tvalid_0's auc: 0.822111\tvalid_0's pr_auc: 0.744231\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's auc: 0.822447\tvalid_0's pr_auc: 0.743687\n",
      "==========================================================\n",
      "0.8285522999999999\n"
     ]
    }
   ],
   "source": [
    "# 학습용\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서 새로운 사실을 발견합니다. 모델의 성능을 높이는 33호, 23호, 34호가 유니크 밸류가 많은 변수들입니다. 심지어 34호는 많은 유저에게 발견된 에러가 아니지만 성능을 높였습니다.\n",
    "# 즉 단순히 에러타입의 카운트만으로는 설명할 수 없는 정보를 보전해준 것입니다.\n",
    "# 이런 측면에서는 모수는 적더라도 유니크 밸류가 많은 에러타입들이 성능을 높여줄 수도 있을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.82842749 -> quality's counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(y_temp)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.903527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.257115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.528882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.644911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.885481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.187132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.308061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.762255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.872077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.352012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.903527\n",
       "1        30001  0.257115\n",
       "2        30002  0.528882\n",
       "3        30003  0.644911\n",
       "4        30004  0.885481\n",
       "...        ...       ...\n",
       "14994    44994  0.187132\n",
       "14995    44995  0.308061\n",
       "14996    44996  0.762255\n",
       "14997    44997  0.872077\n",
       "14998    44998  0.352012\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv(r'C:\\Users\\Wyatt\\wyatt37/Comp/LG_edge_detect/king/submission/king_210121_3_fc2-q-c.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1,2차 합본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8075 -> 0.8161로 상승했습니다. 그래도 0.9% 오른거면 꽤나 올랐네요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1,2차 합본 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터 튜닝을 해줬는데, 0.8161 -> 0.8222\t로 상승했습니다. lgbm 만세! 0.6% 올랐습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바꾼 파라미터\n",
    "\n",
    "1. lr {'default' : 0.027}\n",
    "2. num_boost_round {1000:10000}\n",
    "3. early_stopping_rounds {3 :100}\n",
    "\n",
    "미세하게 많이 개선하도록 바꿨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3차 합본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specific error count 를 넣으니 성능이 오히려 떨어졌습니다.\n",
    "\n",
    "0.8217로 큰 차이는 없으나 Loss를 따라가는 것 같습니다.\n",
    "\n",
    "하나씩 줄여가면서 다시 학습을 시켜보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나씩 학습시켜보았으나, 기존의 로스를 넘는 변수는 없었음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4차 합본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8222 -> 0.8228 로 아주 미세하게 상승 0.0006 상승했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5차 합본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8228 -> 0.8230 으로 아주 미세하게 0.0002 상승했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conn, robot 전부 떨어졌지만, android만 올랐습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오버샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smote-b 로 오버샘플링을 해주었으나, 점수는 떨어졌습니다. 로스보고 깜짝 놀랐네요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6차 합본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31호와 41호를 더해봤지만, 41호는 로스가 좋지 않아 기각하였고, 31호는 제출했으나 오르지 않았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33호에서 0.8230 -> 0.8260 으로 상승했습니다. 효과가 있는 것 같습니다.\t0.003 상승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17호는 노이즈입니다. 33호와 23호를 동시에 넣었을 때 가장 로스가 적었고, 성능이 대폭 올랐습니다. 0.8260 -> 0.8323 으로 0.0063이나 올랐습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가로 7호, 40호, 37호, 14호 까지 시험해 보았으나, 14호만 로스가 줄었음, 그러나 리더보드는 오르지 않았음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
