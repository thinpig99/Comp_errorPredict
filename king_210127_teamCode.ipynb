{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 팀 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 노트북은 지금까지 했던 과정을 간략히 정리한 것입니다. 참고용으로 보시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 기록\n",
    "\n",
    "1. D-6\n",
    " - 파생 변수 생성 확인\n",
    "    1. errtype을 var로 생성 : 0.83068(기각)\n",
    "    2. errtype, errcode 유니크 개수: 0.83235(기각)\n",
    "    3. errtype 유니크 개수: 0.83261(기각)\n",
    "    \n",
    "\n",
    "2. D-5\n",
    " - 파생 변수 생성 확인\n",
    "    1. err, qual의 time을 second으로 하고 std 로 groupby : 0.83490(상승)\n",
    "    2. 혜인이가 추천한 중요도 높은 errcode 추가: 0.83447(기각)\n",
    "    3. quality-groupby-sum: 0.83518(상승)\n",
    "\n",
    "3. D-4\n",
    " - 베스트 모델 확인\n",
    "    1. catb: 0.83552(상승)(2위)\n",
    "    2. gbc: 0.82778(기각)(3위)\n",
    "    3. ~~lgbm-1: 0.83239(기각)~~\n",
    "\n",
    "4. D-3\n",
    " - 베스트 모델 확인\n",
    "    1. lgbm-2: 0.83569(상승)(1위)\n",
    "    2. xtree: 0.81803(기각)(6위)\n",
    "    3. rf: 0.82260(기각)(5위)\n",
    "\n",
    "5. D-2\n",
    " - 앙상블 제출\n",
    "    1. ngb: 0.82469(기각)(4위)\n",
    "    2. 최고모델에 혜인이 변수 조정 버전: \t0.83746(상승)\n",
    "    3. best-6: \t0.83395(기각)\n",
    "\n",
    "6. D-1\n",
    " - 앙상블 제출\n",
    "    1. best-5(xtree 제외): \n",
    "    2. best-4(xtree, rf 제외):\n",
    "    3. best-3(xtree, rf, ngb 제외):\n",
    "\n",
    "7. D-Day\n",
    " - 보류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_dtypes as ld\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, precision_recall_curve, recall_score, precision_score\n",
    "\n",
    "from ngboost import NGBClassifier\n",
    "from ngboost.distns import k_categorical, Bernoulli\n",
    "from ngboost.scores import LogScore, CRPScore\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_P_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv'\n",
    "TRAIN_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv'\n",
    "TRAIN_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv'\n",
    "TEST_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv'\n",
    "TEST_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv'\n",
    "SUBMISSION_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = ld.load_dtypes(TRAIN_P_PATH)\n",
    "train_q = ld.load_dtypes(TRAIN_Q_PATH)\n",
    "train_e = ld.load_dtypes(TRAIN_E_PATH)\n",
    "test_q = ld.load_dtypes(TEST_Q_PATH)\n",
    "test_e = ld.load_dtypes(TEST_E_PATH)\n",
    "submission = pd.read_csv(SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5429, 2),\n",
       " (828624, 16),\n",
       " (16554663, 6),\n",
       " (747972, 16),\n",
       " (16532648, 6),\n",
       " (14999, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape, train_q.shape, train_e.shape, test_q.shape, test_e.shape, submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_problem(df, object_='binary'):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    train_problem 테이블을 받아서 target 값으로 변환\n",
    "    1. {0, 1}의 binary로 변환\n",
    "    2. {0 ~ n}의 multiclass로 변환\n",
    "    \"\"\"\n",
    "    \n",
    "    # 10001부터 24999까지의 index를 만들어줍니다.\n",
    "    user_id_idx = np.array(range(10000, 25000, 1))\n",
    "    \n",
    "    # train_new_p라는 새로운 df를 만들고 index는 위에서 만든 user_id_idx 로 지정해줍니다.\n",
    "    new_p = pd.DataFrame(index = user_id_idx)\n",
    "    new_p['target'] = 0\n",
    "    \n",
    "    if object_ == 'binary':\n",
    "        new_p.iloc[df.user_id.unique()-10000] = 1\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    elif object_ == 'multi':\n",
    "        # multi는 count()로 집계를 해줍니다.\n",
    "        new_p['target'] = df.groupby('user_id')['time'].count()\n",
    "        new_p = new_p.fillna(0)\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b_p = preprocessing_problem(train_p, 'binary')\n",
    "train_m_p = preprocessing_problem(train_p, 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_quality(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    EDA를 통해 알아낸 정보로 train_q, test_q를 정리해서 내뿜어줍니다.\n",
    "    1. qaulity_3, quality_4 를 drop 합니다.(단일 value)\n",
    "    2. qaulity_k 변수들을 정수로 encoding 합니다.\n",
    "    \"\"\"\n",
    "    # 먼저 3, 4번을 drop 합니다.\n",
    "    df.drop(['quality_3', 'quality_4'], axis=1, inplace=True)\n",
    "    \n",
    "    # qual 변수만 할당해주고, 정수로 형변환 해줍니다.\n",
    "    columns = train_q.columns[train_q.columns.str.contains('quality')]\n",
    "    # for문을 통해 각 column을 반복 작업해줍니다.\n",
    "    for col in columns:\n",
    "        try:\n",
    "            if df[col].dtype == 'float32': # 기존에 float은 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "            elif df[col].dtype == 'int8' or df[col].dtype == 'int16': # 기존에 int도 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "                #print(col)\n",
    "            else:\n",
    "                df[col] = df[col].astype('object')\n",
    "                # nan값이 있으면 float으로 갈 수 없으니 '-2' 으로 채워줍니다.\n",
    "                df[col] = df[col].fillna('-2')\n",
    "                df[col] = df[col].apply(lambda x: x.replace(',' , ''))\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # fwver 에서 null 값이 꽤 있습니다. missing으로 채우겠습니다.\n",
    "    df.fwver = df.fwver.astype('object')\n",
    "    df.fwver = df.fwver.fillna('missing')\n",
    "    df.fwver = df.fwver.astype('category')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = preprocessing_quality(train_q)\n",
    "test_q = preprocessing_quality(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fwver(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    별건 아니고, e-set에 fwver 변수에서 '10' 이라는 값이 있는데, 이게 errtype이랑 겹쳐요.\n",
    "    그래서 10을 -> 8.5.2 으로 바꿔줄 겁니다.\n",
    "    굳이 이렇게 바꾸는 이유는, 해당 fw가 8.5.3버전과 같은 model_nm을 공유하기 때문입니다.\n",
    "    \"\"\"\n",
    "    df.fwver = df.fwver.replace('10', '8.5.2')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = preprocessing_fwver(train_e)\n",
    "test_e = preprocessing_fwver(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    'time' column이 str로 되어 있으니, datetime으로 바꿔주는 함수입니다.\n",
    "    다만 'time'양식이 pandas함수에 적용이 안되니, 강제로 슬라이싱해서 만들어줘야 합니다.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df['year'] = df['time'].apply(lambda x: str(x)[:4])\n",
    "    df['month'] = df['time'].apply(lambda x: str(x)[4:6])\n",
    "    df['day'] = df['time'].apply(lambda x: str(x)[6:8])\n",
    "    df['hour'] = df['time'].apply(lambda x: str(x)[8:10])\n",
    "    df['minute'] = '00' # minute을 넣어주지 않으면 datetime이 완성이 안되니, 00으로 넣어줍니다.\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df.year + df.month + df.day + df.hour + df.minute)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = make_datetime(train_p)\n",
    "train_q = make_datetime(train_q)\n",
    "test_q = make_datetime(test_q)\n",
    "train_e = make_datetime(train_e)\n",
    "test_e = make_datetime(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 연산에서 왜 문제가 생기나 했더니 category로 되어 있어서였습니다.\n",
    "\n",
    "train_e['errtype'] = train_e.errtype.astype('object')\n",
    "test_e['errtype'] = test_e.errtype.astype('object')\n",
    "\n",
    "train_e['errcode'] = train_e.errcode.astype('object')\n",
    "test_e['errcode'] = test_e.errcode.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwver도 object로 잡아줍니다.\n",
    "\n",
    "train_q.fwver = train_q.fwver.astype('object')\n",
    "test_q.fwver = test_q.fwver.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from Error_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용한 model의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_count = train_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()\n",
    "test_model_count = test_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용한 fwver 의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fwver_count = train_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()\n",
    "test_fwver_count = test_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경험한 error 의 총 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_count = train_e.groupby('user_id')['errcode'].count()\n",
    "test_err_count = test_e.groupby('user_id')['errcode'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경험한 각 errtype의 value별 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33호\n",
    "train_errcode_33 = train_e[train_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_33 = test_e[test_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']\n",
    "test_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23호\n",
    "train_errcode_23 = train_e[train_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_23 = test_e[test_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']\n",
    "test_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34호\n",
    "train_errcode_34 = train_e[train_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_34 = test_e[test_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']\n",
    "test_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from Quality_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 quality의 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_std = train_q.groupby(['user_id']).std()\n",
    "test_qual_std = test_q.groupby(['user_id']).std()\n",
    "\n",
    "new_columns = ['q_std_0', 'q_std_1', 'q_std_2', 'q_std_5', 'q_std_6', 'q_std_7', 'q_std_8', 'q_std_9', 'q_std_10','q_std_11', 'q_std_12']\n",
    "\n",
    "train_qual_std.columns = new_columns\n",
    "test_qual_std.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기록한 quality log의 개수(12개당 1번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_log = train_q.groupby('user_id')['time'].count()/12\n",
    "test_qual_log = test_q.groupby('user_id')['time'].count()/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality당 순수 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값을 만들기 위해 새로운 df를 받아옵니다.\n",
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()\n",
    "\n",
    "# 0 값을 전부 nan 값으로 바꿔줍니다.\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "\n",
    "# 필요없는 변수들을 버려줍니다.\n",
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "\n",
    "# 그룹바이 카운트 해줍니다.\n",
    "train_qual_counts = train_q_temp.groupby('user_id').count()\n",
    "test_qual_counts = test_q_temp.groupby('user_id').count()\n",
    "\n",
    "# 겹치는 컬럼명을 바꿔줍니다.\n",
    "train_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']\n",
    "test_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality당 음수, 0에 대한 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 값만 count를 위해서 음수와 양수를 전부 nan으로 만들겠습니다.\n",
    "\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] < 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] < 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] > 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] > 0, 'quality_{}'.format(i)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_zeroCount = train_q_temp.groupby('user_id').count()\n",
    "test_qual_zeroCount = test_q_temp.groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['q_z_c_0', 'q_z_c_1', 'q_z_c_2', 'q_z_c_5', 'q_z_c_6', 'q_z_c_7', 'q_z_c_8', 'q_z_c_9', 'q_z_c_10','q_z_c_11', 'q_z_c_12']\n",
    "\n",
    "train_qual_zeroCount.columns = new_columns\n",
    "test_qual_zeroCount.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음수 값만 count를 위해서 음수와 0을 전부 nan으로 만들겠습니다.\n",
    "\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] >= 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] >= 0, 'quality_{}'.format(i)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_negaCount = train_q_temp.groupby('user_id').count()\n",
    "test_qual_negaCount = test_q_temp.groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['q_n_c_0', 'q_n_c_1', 'q_n_c_2', 'q_n_c_5', 'q_n_c_6', 'q_n_c_7', 'q_n_c_8', 'q_n_c_9', 'q_n_c_10','q_n_c_11', 'q_n_c_12']\n",
    "\n",
    "train_qual_negaCount.columns = new_columns\n",
    "test_qual_negaCount.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time에 대한 유저별 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "def time_to_seconds(x):\n",
    "    return time.mktime(x.timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_e.time = train_e.time.apply(lambda x: time_to_seconds(x))\n",
    "test_e.time = test_e.time.apply(lambda x: time_to_seconds(x))\n",
    "train_q.time = train_q.time.apply(lambda x: time_to_seconds(x))\n",
    "test_q.time = test_q.time.apply(lambda x: time_to_seconds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 528 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_err_timestd = train_e.groupby(['user_id'])['time'].std()\n",
    "test_err_timestd = test_e.groupby(['user_id'])['time'].std()\n",
    "train_err_timestd = train_err_timestd.rename(level = 0, index = 't_e_std') \n",
    "test_err_timestd = test_err_timestd.rename(level = 0, index = 't_e_std') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 95 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qual_timestd = (train_q[['user_id', 'time']].drop_duplicates()).groupby(['user_id']).std()\n",
    "test_qual_timestd = (test_q[['user_id', 'time']].drop_duplicates()).groupby(['user_id']).std()\n",
    "train_qual_timestd.columns = ['t_q_std']\n",
    "test_qual_timestd.columns = ['t_q_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality를 sum으로 groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_each_quality_sum = train_q.groupby('user_id').sum().loc[:, 'quality_0':]\n",
    "test_each_quality_sum = test_q.groupby('user_id').sum().loc[:, 'quality_0':]\n",
    "\n",
    "quality_sum_colnms = ['quality_0_sum', 'quality_1_sum', 'quality_2_sum', 'quality_5_sum', 'quality_6_sum', \n",
    "                      'quality_7_sum', 'quality_8_sum', 'quality_9_sum','quality_10_sum', 'quality_11_sum', \n",
    "                      'quality_12_sum']\n",
    "\n",
    "train_each_quality_sum.columns = quality_sum_colnms\n",
    "test_each_quality_sum.columns = quality_sum_colnms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errtype을 유저별로 카운트 해줍니다.\n",
    "\n",
    "X = train_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "y = test_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "\n",
    "X.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']\n",
    "y.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나 사라진 유저를 채워주는 코드입니다.\n",
    "y = y.reindex(pd.RangeIndex(y.index.max() + 1)).ffill(0)[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 41), (14999, 41))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 106)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,\n",
    "               train_err_count, # 유저가 기록한 총 err수\n",
    "               train_fwver_count, # 유저가 사용한 fw수\n",
    "               train_model_count, # 유저가 사용한 model 수\n",
    "               train_qual_std, # 각 퀄리티에 대한 유저별 편차\n",
    "               train_qual_log, # 유저별 퀄리티 로그의 수\n",
    "               train_errcode_23, # 23호 에러타입의 밸류별 개수\n",
    "               train_errcode_33, # 33호 상동\n",
    "               train_errcode_34, # 34호 상동\n",
    "               train_qual_counts, # 각 퀄리티에서 0을 제외한 카운트\n",
    "               train_qual_negaCount, # 각 퀄리티에 대해 음수만 카운트\n",
    "               train_qual_zeroCount # 각 퀄리티에 대해 0.만 카운트\n",
    "              ], axis=1).fillna(0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 106)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat([y,\n",
    "               test_err_count,\n",
    "               test_fwver_count,\n",
    "               test_model_count,\n",
    "               test_qual_std,\n",
    "               test_qual_log,\n",
    "               test_errcode_23,\n",
    "               test_errcode_33,\n",
    "               test_errcode_34,\n",
    "               test_qual_counts,\n",
    "               test_qual_negaCount,\n",
    "               test_qual_zeroCount\n",
    "              ], axis=1).fillna(0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3차 합격생들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 119), (14999, 119))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X, train_err_timestd, train_qual_timestd, train_each_quality_sum], axis=1).fillna(0)\n",
    "y = pd.concat([y, test_err_timestd, test_qual_timestd, test_each_quality_sum], axis=1).fillna(0)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3차 면접중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혜인이 다시 제안한 조건부 31호.\n",
    "train_errcode_31 = train_e[train_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "                            groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_31 = test_e[test_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "                            groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "train_errcode_31.columns = ['err_31_0', 'err_31_1']\n",
    "test_errcode_31.columns =['err_31_0', 'err_31_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_e['day_2'] = train_e['time'].apply(lambda x: str(x)[:10])\n",
    "\n",
    "train_meanDay = (train_e\n",
    "                 .groupby(['user_id','day_2'])['day_2']\n",
    "                 .count()\n",
    "                 .unstack()\n",
    "                 .fillna(0)\n",
    "                 .loc[:, '2020-11-01':'2020-11-30']\n",
    "                 .mean(axis=1))\n",
    "\n",
    "train_maxDay = (train_e\n",
    "                .groupby(['user_id','day_2'])['day_2']\n",
    "                .count()\n",
    "                .unstack()\n",
    "                .fillna(0)\n",
    "                .loc[:, '2020-11-01':'2020-11-30']\n",
    "                .max(axis=1))\n",
    "\n",
    "train_maxBymean = pd.Series(data = np.array(train_maxDay) / np.array(train_meanDay),\n",
    "                            index = train_e.user_id.unique(),\n",
    "                            name = 'mbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_e['day_2'] = test_e['time'].apply(lambda x: str(x)[:10])\n",
    "\n",
    "test_meanDay = (test_e\n",
    "                .groupby(['user_id','day_2'])['day_2']\n",
    "                .count()\n",
    "                .unstack()\n",
    "                .fillna(0)\n",
    "                .loc[:, '2020-11-01':'2020-11-30']\n",
    "                .mean(axis=1))\n",
    "\n",
    "test_maxDay = (test_e\n",
    "               .groupby(['user_id','day_2'])['day_2']\n",
    "               .count()\n",
    "               .unstack()\n",
    "               .fillna(0)\n",
    "               .loc[:, '2020-11-01':'2020-11-30']\n",
    "               .max(axis=1))\n",
    "\n",
    "test_maxBymean = pd.Series(data = np.array(test_maxDay) / np.array(test_meanDay),\n",
    "                           index = test_e.user_id.unique(),\n",
    "                           name = 'mbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 120), (14999, 120))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = pd.concat([X, train_errcode_31, train_maxBymean], axis=1).fillna(0)\n",
    "y_temp = pd.concat([y, test_errcode_31, test_maxBymean], axis=1).fillna(0)\n",
    "\n",
    "X_temp.drop(['et_20', 'et_36'], axis=1, inplace = True)\n",
    "y_temp.drop(['et_20', 'et_36'], axis=1, inplace = True)\n",
    "\n",
    "X_temp.shape, y_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [0.00001, 0.0001, 0.001, 0.01,\n",
    "          0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha:  0.9\n",
      "feature selected:  117\n",
      "R^2 is:  0.21684725538690441\n",
      "auc:  0.77278074\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "ridge = RidgeCV(alphas=a_list)\n",
    "ridge.fit(X_new_scaled, train_b_p.target)\n",
    "\n",
    "print('best alpha: ', ridge.alpha_)\n",
    "print('feature selected: ', ridge.coef_.nonzero()[0].size)\n",
    "print('R^2 is: ', ridge.score(X_new_scaled, train_b_p.target))\n",
    "print('auc: ', roc_auc_score(train_b_p.target, ridge.predict(X_new_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha:  0.0001\n",
      "feature selected:  44\n",
      "R^2 is:  0.21534357615160604\n",
      "auc:  0.76866168\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "lasso = LassoCV(alphas=a_list)\n",
    "lasso.fit(X_new_scaled, train_b_p.target)\n",
    "\n",
    "print('best alpha: ', lasso.alpha_)\n",
    "print('feature selected: ', lasso.coef_.nonzero()[0].size)\n",
    "print('R^2 is: ', lasso.score(X_new_scaled, train_b_p.target))\n",
    "print('auc: ', roc_auc_score(train_b_p.target, lasso.predict(X_new_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha:  0.0001\n",
      "feature selected:  72\n",
      "R^2 is:  0.2141987748183607\n",
      "auc:  0.7707219\n"
     ]
    }
   ],
   "source": [
    "# elastic\n",
    "elastic = ElasticNetCV(alphas=a_list)\n",
    "elastic.fit(X_new_scaled, train_b_p.target)\n",
    "\n",
    "print('best alpha: ', elastic.alpha_)\n",
    "print('feature selected: ', elastic.coef_.nonzero()[0].size)\n",
    "print('R^2 is: ', elastic.score(X_new_scaled, train_b_p.target))\n",
    "print('auc: ', roc_auc_score(train_b_p.target, elastic.predict(X_new_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   4,   5,   6,   7,  10,  11,  12,  14,  15,  16,  17,  18,\n",
       "        19,  20,  21,  22,  24,  25,  26,  27,  28,  30,  32,  33,  34,\n",
       "        35,  37,  38,  39,  40,  41,  42,  43,  47,  48,  52,  53,  54,\n",
       "        57,  61,  62,  63,  64,  65,  66,  67,  68,  70,  73,  74,  76,\n",
       "        78,  79,  82,  84,  85,  86,  87,  88,  93,  95,  97,  98, 106,\n",
       "       107, 111, 112, 113, 116, 117, 121], dtype=int64)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.coef_.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['et_1', 'et_5', 'et_6', 'et_7', 'et_8', 'et_11', 'et_12', 'et_13',\n",
       "       'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22',\n",
       "       'et_23', 'et_25', 'et_26', 'et_27', 'et_28', 'et_30', 'et_32', 'et_34',\n",
       "       'et_35', 'et_36', 'et_37', 'et_39', 'et_40', 'et_41', 'et_42',\n",
       "       'errcode', 'fwver', 'model_nm', 'q_std_5', 'q_std_6', 'q_std_10',\n",
       "       'q_std_11', 'q_std_12', 'ACTIVE', 'connLOCAL', 'STANDBY', 'TERMINATE',\n",
       "       'err_33_1', 'err_33_2', 'err_33_3', 'err_34_1', 'err_34_2', 'err_34_4',\n",
       "       'q_c_0', 'q_c_1', 'q_c_5', 'q_c_7', 'q_c_8', 'q_c_11', 'q_n_c_0',\n",
       "       'q_n_c_1', 'q_n_c_2', 'q_n_c_5', 'q_n_c_6', 'q_n_c_11', 'q_z_c_0',\n",
       "       'q_z_c_2', 'q_z_c_5', 't_e_std', 't_q_std', 'quality_5_sum',\n",
       "       'quality_6_sum', 'quality_7_sum', 'quality_10_sum', 'quality_11_sum',\n",
       "       'user_max_by_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.iloc[:, elastic.coef_.nonzero()[0]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = X_new.iloc[:, elastic.coef_.nonzero()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def s_fold_train_pred(train_x, train_y):\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'boosting_type' : 'gbdt',\n",
    "                    'objective'     : 'binary',\n",
    "                    'metric'        : 'auc',\n",
    "                    'learning_rate' : 0.027,\n",
    "                    'seed': 42\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        d_train= lgb.Dataset(X, y)\n",
    "        d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "\n",
    "        #run traning\n",
    "        model = lgb.train(\n",
    "                            params,\n",
    "                            train_set       = d_train,\n",
    "                            num_boost_round = 10000,\n",
    "                            valid_sets      = d_val,\n",
    "                            feval           = f_pr_auc,\n",
    "                            verbose_eval    = 100, \n",
    "                            early_stopping_rounds = 100\n",
    "                           )\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13551\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.826428\tvalid_0's pr_auc: 0.747213\n",
      "[200]\tvalid_0's auc: 0.826504\tvalid_0's pr_auc: 0.74872\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's auc: 0.827018\tvalid_0's pr_auc: 0.748922\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13646\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.836547\tvalid_0's pr_auc: 0.780875\n",
      "[200]\tvalid_0's auc: 0.837776\tvalid_0's pr_auc: 0.782188\n",
      "[300]\tvalid_0's auc: 0.835811\tvalid_0's pr_auc: 0.782262\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.837837\tvalid_0's pr_auc: 0.782444\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13983\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.825725\tvalid_0's pr_auc: 0.749735\n",
      "[200]\tvalid_0's auc: 0.829299\tvalid_0's pr_auc: 0.753172\n",
      "[300]\tvalid_0's auc: 0.828318\tvalid_0's pr_auc: 0.752243\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's auc: 0.829453\tvalid_0's pr_auc: 0.753319\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13988\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.830888\tvalid_0's pr_auc: 0.7521\n",
      "[200]\tvalid_0's auc: 0.831584\tvalid_0's pr_auc: 0.754752\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.83146\tvalid_0's pr_auc: 0.756563\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13700\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.818549\tvalid_0's pr_auc: 0.7325\n",
      "[200]\tvalid_0's auc: 0.819637\tvalid_0's pr_auc: 0.74097\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.820055\tvalid_0's pr_auc: 0.739915\n",
      "==========================================================\n",
      "0.82916455\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16104\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 115\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.826164\tvalid_0's pr_auc: 0.745748\n",
      "[200]\tvalid_0's auc: 0.827937\tvalid_0's pr_auc: 0.750056\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's auc: 0.828017\tvalid_0's pr_auc: 0.750058\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16214\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 115\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.838664\tvalid_0's pr_auc: 0.782017\n",
      "[200]\tvalid_0's auc: 0.838982\tvalid_0's pr_auc: 0.783078\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's auc: 0.83902\tvalid_0's pr_auc: 0.784045\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16565\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 115\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.826206\tvalid_0's pr_auc: 0.752282\n",
      "[200]\tvalid_0's auc: 0.829574\tvalid_0's pr_auc: 0.754067\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.829179\tvalid_0's pr_auc: 0.756047\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16569\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 115\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.830047\tvalid_0's pr_auc: 0.749459\n",
      "[200]\tvalid_0's auc: 0.831777\tvalid_0's pr_auc: 0.75605\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.831366\tvalid_0's pr_auc: 0.757728\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16256\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 115\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.819703\tvalid_0's pr_auc: 0.729213\n",
      "[200]\tvalid_0's auc: 0.820968\tvalid_0's pr_auc: 0.736842\n",
      "[300]\tvalid_0's auc: 0.820866\tvalid_0's pr_auc: 0.739563\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's auc: 0.821355\tvalid_0's pr_auc: 0.738308\n",
      "==========================================================\n",
      "0.8297874499999999\n"
     ]
    }
   ],
   "source": [
    "# 학습용\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X_new2, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10214\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 72\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.821905\tvalid_0's pr_auc: 0.734777\n",
      "[200]\tvalid_0's auc: 0.822917\tvalid_0's pr_auc: 0.741858\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's auc: 0.823461\tvalid_0's pr_auc: 0.74203\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10299\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 72\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.834349\tvalid_0's pr_auc: 0.777696\n",
      "[200]\tvalid_0's auc: 0.834496\tvalid_0's pr_auc: 0.778228\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.834827\tvalid_0's pr_auc: 0.779688\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10613\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 72\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.82285\tvalid_0's pr_auc: 0.74325\n",
      "[200]\tvalid_0's auc: 0.825963\tvalid_0's pr_auc: 0.745608\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's auc: 0.825843\tvalid_0's pr_auc: 0.747592\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10629\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 72\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.82694\tvalid_0's pr_auc: 0.747522\n",
      "[200]\tvalid_0's auc: 0.829179\tvalid_0's pr_auc: 0.750119\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's auc: 0.82852\tvalid_0's pr_auc: 0.751311\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10371\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 72\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.815294\tvalid_0's pr_auc: 0.727515\n",
      "[200]\tvalid_0's auc: 0.815893\tvalid_0's pr_auc: 0.731079\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's auc: 0.81667\tvalid_0's pr_auc: 0.731536\n",
      "==========================================================\n",
      "0.82586435\n"
     ]
    }
   ],
   "source": [
    "# 학습용\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X_selected, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base 0.8292073  0.8266209  0.82655950\n",
    "# ec   0.8296051  0.8269322  0.82608215\n",
    "# et   0.8291249  0.8269684  0.82844335\n",
    "# etc  0.8291123  0.8272698  0.82821499\n",
    "#          42         43        44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(y_temp)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.920044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.221513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.505086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.735106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.880764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.203552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.320443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.741580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.884766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.339916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.920044\n",
       "1        30001  0.221513\n",
       "2        30002  0.505086\n",
       "3        30003  0.735106\n",
       "4        30004  0.880764\n",
       "...        ...       ...\n",
       "14994    44994  0.203552\n",
       "14995    44995  0.320443\n",
       "14996    44996  0.741580\n",
       "14997    44997  0.884766\n",
       "14998    44998  0.339916\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'./submission/team_210129_3_qual-sum-added.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def catb_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'nan_mode': 'Min',\n",
    "                    'eval_metric': 'Logloss',\n",
    "                    'iterations': 1000,\n",
    "                    'sampling_frequency': 'PerTree',\n",
    "                    'leaf_estimation_method': 'Newton',\n",
    "                    'grow_policy': 'SymmetricTree',\n",
    "                    'penalties_coefficient': 1,\n",
    "                    'boosting_type': 'Plain',\n",
    "                    'model_shrink_mode': 'Constant',\n",
    "                    'feature_border_type': 'GreedyLogSum',\n",
    "                    #'bayesian_matrix_reg': 0.10000000149011612,\n",
    "                    'l2_leaf_reg': 3,\n",
    "                    'random_strength': 1,\n",
    "                    'rsm': 1,\n",
    "                    'boost_from_average': False,\n",
    "                    'model_size_reg': 0.5,\n",
    "                    'subsample': 0.800000011920929,\n",
    "                    'use_best_model': False,\n",
    "                    'class_names': [0, 1],\n",
    "                    'random_seed': 2584,\n",
    "                    'depth': 6,\n",
    "                    'posterior_sampling': False,\n",
    "                    'border_count': 254,\n",
    "                    'classes_count': 0,\n",
    "                    'auto_class_weights': 'None',\n",
    "                    'sparse_features_conflict_fraction': 0,\n",
    "                    'leaf_estimation_backtracking': 'AnyImprovement',\n",
    "                    'best_model_min_trees': 1,\n",
    "                    'model_shrink_rate': 0,\n",
    "                    'min_data_in_leaf': 1,\n",
    "                    'loss_function': 'Logloss',\n",
    "                    'learning_rate': 0.028116999194025993,\n",
    "                    'score_function': 'Cosine',\n",
    "                    'task_type': 'CPU',\n",
    "                    'leaf_estimation_iterations': 10,\n",
    "                    'bootstrap_type': 'MVS',\n",
    "                    'max_leaves': 64\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = CatBoostClassifier(**params, verbose=0)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7311500000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = catb_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y_temp)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_catb = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94895007],\n",
       "       [0.22181754],\n",
       "       [0.48093417],\n",
       "       ...,\n",
       "       [0.71755727],\n",
       "       [0.89595603],\n",
       "       [0.41866161]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.953445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.237317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.474520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.838170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.913806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.208481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.302758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.727264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.911754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.423947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.953445\n",
       "1        30001  0.237317\n",
       "2        30002  0.474520\n",
       "3        30003  0.838170\n",
       "4        30004  0.913806\n",
       "...        ...       ...\n",
       "14994    44994  0.208481\n",
       "14995    44995  0.302758\n",
       "14996    44996  0.727264\n",
       "14997    44997  0.911754\n",
       "14998    44998  0.423947\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission.problem = pred_ensemble\n",
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv(r'./submission/team_210130_2_pycaret-catb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def lgbm_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'boosting_type':'gbdt', \n",
    "                    'class_weight':None,\n",
    "                    'colsample_bytree':1.0,\n",
    "                    'importance_type':'split',\n",
    "                    'learning_rate':0.1,\n",
    "                    'max_depth':-1,\n",
    "                    'min_child_samples':20,\n",
    "                    'min_child_weight':0.001,\n",
    "                    'min_split_gain':0.0,\n",
    "                    'n_estimators':100,\n",
    "                    'n_jobs':-1,\n",
    "                    'num_leaves':31,\n",
    "                    'objective':None,\n",
    "                    'random_state':2584,\n",
    "                    'reg_alpha':0.0,\n",
    "                    'reg_lambda':0.0,\n",
    "                    'silent':True,\n",
    "                    'subsample':1.0,\n",
    "                    'subsample_for_bin':200000,\n",
    "                    'subsample_freq':0\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343500000000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = lgbm_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y_temp)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_lgbm = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9627417 ],\n",
       "       [0.23273525],\n",
       "       [0.51332842],\n",
       "       ...,\n",
       "       [0.7930191 ],\n",
       "       [0.91029832],\n",
       "       [0.38532945]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.problem = pred_ensemble\n",
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv(r'./submission/team_210201_2_add-feature-made-by-hi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                           max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='deprecated',\n",
    "                           random_state=2584, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GBC\n",
    "#-------------------------------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#-------------------------------------------------------------------------------------\n",
    "def gbc_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_idx, val_idx in k_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = gbc.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        print(auc_score)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "    \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73125\n",
      "0.73425\n",
      "0.7155\n",
      "0.72125\n",
      "0.7200000000000001\n",
      "0.72445\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = gbc_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y_temp)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_gbc = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93918089],\n",
       "       [0.22982864],\n",
       "       [0.51424097],\n",
       "       ...,\n",
       "       [0.68564711],\n",
       "       [0.87796247],\n",
       "       [0.36983057]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_gbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned NGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ngboost\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels = y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score = auc(r, p)\n",
    "    return \"pr_auc\", score, True\n",
    "\n",
    "def ngb_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    models = []\n",
    "    recalls = []\n",
    "    precisions =[]\n",
    "    auc_scores = []\n",
    "    threshold = 0.5\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in k_fold.split(train_x, train_y):\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx].astype(np.int)\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx].astype(np.int)\n",
    "\n",
    "        model = NGBClassifier(\n",
    "                                Dist = k_categorical(2),\n",
    "                                n_estimators = 1000,\n",
    "                                learning_rate = 0.02\n",
    "                            )\n",
    "        model.fit(X, y, X_val=valid_x, Y_val = valid_y, early_stopping_rounds = 3)\n",
    "        valid_prob = model.predict_proba(valid_x)[:,1]\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        recall = recall_score(valid_y, valid_pred)\n",
    "        precision = precision_score(valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(valid_y, valid_prob)\n",
    "\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6365 val_loss=0.6266 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4631 val_loss=0.4741 scale=2.0000 norm=3.6735\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL170 (val_loss=0.4679)\n",
      "[iter 0] loss=0.6365 val_loss=0.6263 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4649 val_loss=0.4612 scale=2.0000 norm=3.6630\n",
      "[iter 200] loss=0.4534 val_loss=0.4543 scale=1.0000 norm=1.8491\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL215 (val_loss=0.4540)\n",
      "[iter 0] loss=0.6365 val_loss=0.6271 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4605 val_loss=0.4801 scale=2.0000 norm=3.6648\n",
      "[iter 200] loss=0.4457 val_loss=0.4720 scale=2.0000 norm=3.7158\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL211 (val_loss=0.4716)\n",
      "[iter 0] loss=0.6365 val_loss=0.6267 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4633 val_loss=0.4725 scale=1.0000 norm=1.8378\n",
      "[iter 200] loss=0.4470 val_loss=0.4623 scale=1.0000 norm=1.8602\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL253 (val_loss=0.4603)\n",
      "[iter 0] loss=0.6365 val_loss=0.6273 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4595 val_loss=0.4855 scale=1.0000 norm=1.8372\n",
      "[iter 200] loss=0.4443 val_loss=0.4775 scale=1.0000 norm=1.8610\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL206 (val_loss=0.4773)\n",
      "0.8201127500000001\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = ngb_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y_temp)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_ngb = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97145546],\n",
       "       [0.22713096],\n",
       "       [0.45922968],\n",
       "       ...,\n",
       "       [0.62442086],\n",
       "       [0.88451926],\n",
       "       [0.27311474]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_ngb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Xtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def xtree_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    model = ExtraTreesClassifier(\n",
    "                                    bootstrap=False,\n",
    "                                    ccp_alpha=0.0,\n",
    "                                    class_weight=None,\n",
    "                                    criterion='gini',\n",
    "                                    max_depth=None,\n",
    "                                    max_features='auto',\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    max_samples=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_impurity_split=None,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_samples_split=2,\n",
    "                                    min_weight_fraction_leaf=0.0, \n",
    "                                    n_estimators=2000,\n",
    "                                    n_jobs=-1,\n",
    "                                    oob_score=False,\n",
    "                                    random_state=2584,\n",
    "                                    verbose=1,\n",
    "                                    warm_start=False\n",
    "                                )\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = xtree_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=24)]: Done 2000 out of 2000 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y_temp)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_xtree = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.906 ],\n",
       "       [0.181 ],\n",
       "       [0.5225],\n",
       "       ...,\n",
       "       [0.598 ],\n",
       "       [0.6755],\n",
       "       [0.4555]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_xtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=7367, verbose=0,\n",
    "                       warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_fold_train_pred(train_x, train_y):\n",
    "    \n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    oob_scores   = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "    \n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "        \n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = rfc.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "        \n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7246999999999999\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = rf_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y_temp)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble_rf = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89],\n",
       "       [0.2 ],\n",
       "       [0.5 ],\n",
       "       ...,\n",
       "       [0.53],\n",
       "       [0.72],\n",
       "       [0.38]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94895007],\n",
       "       [0.22181754],\n",
       "       [0.48093417],\n",
       "       ...,\n",
       "       [0.71755727],\n",
       "       [0.89595603],\n",
       "       [0.41866161]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93918089],\n",
       "       [0.22982864],\n",
       "       [0.51424097],\n",
       "       ...,\n",
       "       [0.68564711],\n",
       "       [0.87796247],\n",
       "       [0.36983057]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9627417 ],\n",
       "       [0.23273525],\n",
       "       [0.51332842],\n",
       "       ...,\n",
       "       [0.7930191 ],\n",
       "       [0.91029832],\n",
       "       [0.38532945]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97145546],\n",
       "       [0.22713096],\n",
       "       [0.45922968],\n",
       "       ...,\n",
       "       [0.62442086],\n",
       "       [0.88451926],\n",
       "       [0.27311474]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_ngb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89],\n",
       "       [0.2 ],\n",
       "       [0.5 ],\n",
       "       ...,\n",
       "       [0.53],\n",
       "       [0.72],\n",
       "       [0.38]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.906 ],\n",
       "       [0.181 ],\n",
       "       [0.5225],\n",
       "       ...,\n",
       "       [0.598 ],\n",
       "       [0.6755],\n",
       "       [0.4555]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_xtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble_best_6 = (\n",
    "                            pred_ensemble_catb +\n",
    "                            pred_ensemble_gbc  +\n",
    "                            pred_ensemble_lgbm +\n",
    "                            pred_ensemble_ngb  +\n",
    "                            pred_ensemble_rf   +\n",
    "                            pred_ensemble_xtree\n",
    "                        ) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93638802],\n",
       "       [0.21541873],\n",
       "       [0.49837221],\n",
       "       ...,\n",
       "       [0.65810739],\n",
       "       [0.82737268],\n",
       "       [0.38040606]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble_best_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.936388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.215419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.498372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.729066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.861503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.223375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.287214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.658107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.827373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.380406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.936388\n",
       "1        30001  0.215419\n",
       "2        30002  0.498372\n",
       "3        30003  0.729066\n",
       "4        30004  0.861503\n",
       "...        ...       ...\n",
       "14994    44994  0.223375\n",
       "14995    44995  0.287214\n",
       "14996    44996  0.658107\n",
       "14997    44997  0.827373\n",
       "14998    44998  0.380406\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble_best_6\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'./submission/team_210201_3_ensemble-best6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 창고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 형록이가 제안한 var 모델\n",
    "\n",
    "# X = pd.concat([train_e.user_id, pd.get_dummies(train_e.errtype)], axis=1).groupby('user_id').var().fillna(0)\n",
    "# y = pd.concat([test_e.user_id, pd.get_dummies(test_e.errtype)], axis=1).groupby('user_id').var().fillna(0)\n",
    "\n",
    "# X.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    "#  'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    "#  'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    "#  'et_39', 'et_40', 'et_41', 'et_42']\n",
    "# y.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    "#  'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    "#  'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    "#  'et_39', 'et_40', 'et_41', 'et_42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혜인이가 제안한 errcode\n",
    "\n",
    "# # 8호\n",
    "# train_ecode_14 = train_e[train_e.errtype == 14][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_14 = test_e[test_e.errtype == 14][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_14.columns = ['err_14_1', 'err_14_13','err_14_14']\n",
    "# test_ecode_14.columns =  ['err_14_1', 'err_14_13','err_14_14']\n",
    "\n",
    "# # 30호\n",
    "# train_ecode_30 = train_e[train_e.errtype == 30][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_30 = test_e[test_e.errtype == 30][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_30.columns = ['err_30_0','err_30_1','err_30_2', 'err_30_3','err_30_4']\n",
    "# test_ecode_30.columns =  ['err_30_0','err_30_1','err_30_2', 'err_30_3','err_30_4']\n",
    "\n",
    "# # 9호\n",
    "# train_ecode_9 = train_e[train_e.errtype == 9][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_9 = test_e[test_e.errtype == 9][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_9.columns = ['err_9_1','err_9_C-11020', 'err_9_C-12032','err_9_C-13039','err_9_C-14014',\n",
    "#                           'err_9_V-21002','err_9_V-21004','err_9_V-21005','err_9_V-21008']\n",
    "# test_ecode_9.columns = ['err_9_1','err_9_C-11020', 'err_9_C-12032','err_9_C-13039','err_9_C-14014',\n",
    "#                           'err_9_V-21002','err_9_V-21004','err_9_V-21005','err_9_V-21008']\n",
    "\n",
    "# # 37호\n",
    "# train_ecode_37 = train_e[train_e.errtype == 37][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_37 = test_e[test_e.errtype == 37][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_37.columns = ['err_37_1', 'err_37_2']\n",
    "# test_ecode_37.columns = ['err_37_1', 'err_37_2']\n",
    "\n",
    "\n",
    "# # 5호\n",
    "# train_ecode_5 = train_e[train_e.errtype == 5][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)[('time', 'E-59902')]\n",
    "# test_ecode_5 = test_e[test_e.errtype == 5][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)[('time', 'E-59902')]\n",
    "# #train_ecode_5.columns = ['err_5_E-59902']\n",
    "# #test_ecode_5.columns = ['err_5_E-59902']\n",
    "# train_ecode_5 = train_ecode_5.rename(level = 0, index = 'err_5_E-59902') \n",
    "# test_ecode_5 = test_ecode_5.rename(level = 0, index = 'err_5_E-59902') \n",
    "\n",
    "# # 31호\n",
    "# train_ecode_31 = train_e[train_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_31 = test_e[test_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_31.columns = ['err_31_0', 'err_31_1']\n",
    "# test_ecode_31.columns =['err_31_0', 'err_31_1']\n",
    "\n",
    "# # 7호\n",
    "# train_ecode_7 = train_e[train_e.errtype == 7][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_7 = test_e[test_e.errtype == 7][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_7.columns = ['err_7_1', 'err_7_14']\n",
    "# test_ecode_7.columns =['err_7_1', 'err_7_14']\n",
    "\n",
    "# # 25호\n",
    "# train_ecode_25 = train_e[train_e.errtype == 25][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_25 = test_e[test_e.errtype == 25][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "# train_ecode_25.columns =  ['err_25_1', 'err_25_2', 'err_25_L2CAP connection cancelled', 'err_25_UNKNOWN', \n",
    "#                             'err_25_connection fail to establish',\n",
    "#                              'err_25_connection timeout', 'err_25_connectionterminated by local host',\n",
    "#                             'err_25_scanning timeout', 'err_25_terminate by peer user']\n",
    "\n",
    "# test_ecode_25.columns = ['err_25_1', 'err_25_2', 'err_25_L2CAP connection cancelled', 'err_25_UNKNOWN', \n",
    "#                            'connection fail for LMP response timout',\n",
    "#                             'err_25_connection fail to establish',\n",
    "#                              'err_25_connection timeout', 'err_25_connectionterminated by local host',\n",
    "#                             'err_25_scanning timeout', 'err_25_terminate by peer user']\n",
    "\n",
    "# test_ecode_25.drop('connection fail for LMP response timout', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
