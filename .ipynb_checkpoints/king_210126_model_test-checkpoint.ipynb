{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT & LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_dtypes as ld\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, precision_recall_curve, recall_score, precision_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_P_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv'\n",
    "TRAIN_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv'\n",
    "TRAIN_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv'\n",
    "TEST_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv'\n",
    "TEST_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv'\n",
    "SUBMISSION_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = ld.load_dtypes(TRAIN_P_PATH)\n",
    "train_q = ld.load_dtypes(TRAIN_Q_PATH)\n",
    "train_e = ld.load_dtypes(TRAIN_E_PATH)\n",
    "test_q = ld.load_dtypes(TEST_Q_PATH)\n",
    "test_e = ld.load_dtypes(TEST_E_PATH)\n",
    "submission = pd.read_csv(SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5429, 2),\n",
       " (828624, 16),\n",
       " (16554663, 6),\n",
       " (747972, 16),\n",
       " (16532648, 6),\n",
       " (14999, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape, train_q.shape, train_e.shape, test_q.shape, test_e.shape, submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_problem(df, object_='binary'):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    train_problem 테이블을 받아서 target 값으로 변환\n",
    "    1. {0, 1}의 binary로 변환\n",
    "    2. {0 ~ n}의 multiclass로 변환\n",
    "    \"\"\"\n",
    "    \n",
    "    # 10001부터 24999까지의 index를 만들어줍니다.\n",
    "    user_id_idx = np.array(range(10000, 25000, 1))\n",
    "    \n",
    "    # train_new_p라는 새로운 df를 만들고 index는 위에서 만든 user_id_idx 로 지정해줍니다.\n",
    "    new_p = pd.DataFrame(index = user_id_idx)\n",
    "    new_p['target'] = 0\n",
    "    \n",
    "    if object_ == 'binary':\n",
    "        new_p.iloc[df.user_id.unique()-10000] = 1\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    elif object_ == 'multi':\n",
    "        # multi는 count()로 집계를 해줍니다.\n",
    "        new_p['target'] = df.groupby('user_id')['time'].count()\n",
    "        new_p = new_p.fillna(0)\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b_p = preprocessing_problem(train_p, 'binary')\n",
    "train_m_p = preprocessing_problem(train_p, 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_quality(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    EDA를 통해 알아낸 정보로 train_q, test_q를 정리해서 내뿜어줍니다.\n",
    "    1. qaulity_3, quality_4 를 drop 합니다.(단일 value)\n",
    "    2. qaulity_k 변수들을 정수로 encoding 합니다.\n",
    "    \"\"\"\n",
    "    # 먼저 3, 4번을 drop 합니다.\n",
    "    df.drop(['quality_3', 'quality_4'], axis=1, inplace=True)\n",
    "    \n",
    "    # qual 변수만 할당해주고, 정수로 형변환 해줍니다.\n",
    "    columns = train_q.columns[train_q.columns.str.contains('quality')]\n",
    "    # for문을 통해 각 column을 반복 작업해줍니다.\n",
    "    for col in columns:\n",
    "        try:\n",
    "            if df[col].dtype == 'float32': # 기존에 float은 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "            elif df[col].dtype == 'int8' or df[col].dtype == 'int16': # 기존에 int도 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "                #print(col)\n",
    "            else:\n",
    "                df[col] = df[col].astype('object')\n",
    "                # nan값이 있으면 float으로 갈 수 없으니 '-2' 으로 채워줍니다.\n",
    "                df[col] = df[col].fillna('-2')\n",
    "                df[col] = df[col].apply(lambda x: x.replace(',' , ''))\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # fwver 에서 null 값이 꽤 있습니다. missing으로 채우겠습니다.\n",
    "    df.fwver = df.fwver.astype('object')\n",
    "    df.fwver = df.fwver.fillna('missing')\n",
    "    df.fwver = df.fwver.astype('category')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = preprocessing_quality(train_q)\n",
    "test_q = preprocessing_quality(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fwver(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    별건 아니고, e-set에 fwver 변수에서 '10' 이라는 값이 있는데, 이게 errtype이랑 겹쳐요.\n",
    "    그래서 10을 -> 8.5.2 으로 바꿔줄 겁니다.\n",
    "    굳이 이렇게 바꾸는 이유는, 해당 fw가 8.5.3버전과 같은 model_nm을 공유하기 때문입니다.\n",
    "    \"\"\"\n",
    "    df.fwver = df.fwver.replace('10', '8.5.2')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = preprocessing_fwver(train_e)\n",
    "test_e = preprocessing_fwver(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    'time' column이 str로 되어 있으니, datetime으로 바꿔주는 함수입니다.\n",
    "    다만 'time'양식이 pandas함수에 적용이 안되니, 강제로 슬라이싱해서 만들어줘야 합니다.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df['year'] = df['time'].apply(lambda x: str(x)[:4])\n",
    "    df['month'] = df['time'].apply(lambda x: str(x)[4:6])\n",
    "    df['day'] = df['time'].apply(lambda x: str(x)[6:8])\n",
    "    df['hour'] = df['time'].apply(lambda x: str(x)[8:10])\n",
    "    df['minute'] = '00' # minute을 넣어주지 않으면 datetime이 완성이 안되니, 00으로 넣어줍니다.\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df.year + df.month + df.day + df.hour + df.minute)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = make_datetime(train_p)\n",
    "train_q = make_datetime(train_q)\n",
    "test_q = make_datetime(test_q)\n",
    "train_e = make_datetime(train_e)\n",
    "test_e = make_datetime(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 연산에서 왜 문제가 생기나 했더니 category로 되어 있어서였습니다.\n",
    "\n",
    "train_e['errtype'] = train_e.errtype.astype('object')\n",
    "test_e['errtype'] = test_e.errtype.astype('object')\n",
    "\n",
    "train_e['errcode'] = train_e.errcode.astype('object')\n",
    "test_e['errcode'] = test_e.errcode.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwver도 object로 잡아줍니다.\n",
    "\n",
    "train_q.fwver = train_q.fwver.astype('object')\n",
    "test_q.fwver = test_q.fwver.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING: Survived Features from Feature Collection 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from Error_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보유한 model의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_count = train_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()\n",
    "test_model_count = test_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보유한 fwver 의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fwver_count = train_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()\n",
    "test_fwver_count = test_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경험한 error 의 총 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_count = train_e.groupby('user_id')['errcode'].count()\n",
    "test_err_count = test_e.groupby('user_id')['errcode'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경험한 각 errtype의 values의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33호\n",
    "train_errcode_33 = train_e[train_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_33 = test_e[test_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']\n",
    "test_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23호\n",
    "train_errcode_23 = train_e[train_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_23 = test_e[test_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']\n",
    "test_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34호\n",
    "train_errcode_34 = train_e[train_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_34 = test_e[test_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']\n",
    "test_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from Quality_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 quality의 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_std = train_q.groupby(['user_id']).std()\n",
    "test_qual_std = test_q.groupby(['user_id']).std()\n",
    "\n",
    "new_columns = ['q_std_0', 'q_std_1', 'q_std_2', 'q_std_5', 'q_std_6', 'q_std_7', 'q_std_8', 'q_std_9', 'q_std_10','q_std_11', 'q_std_12']\n",
    "\n",
    "train_qual_std.columns = new_columns\n",
    "test_qual_std.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기록한 quality log의 개수(12개당 1번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_log = train_q.groupby('user_id')['time'].count()/12\n",
    "test_qual_log = test_q.groupby('user_id')['time'].count()/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quality당 순수 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값을 만들기 위해 새로운 df를 받아옵니다.\n",
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()\n",
    "\n",
    "# 0 값을 전부 nan 값으로 바꿔줍니다.\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "\n",
    "# 필요없는 변수들을 버려줍니다.\n",
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "\n",
    "# 그룹바이 카운트 해줍니다.\n",
    "train_qual_counts = train_q_temp.groupby('user_id').count()\n",
    "test_qual_counts = test_q_temp.groupby('user_id').count()\n",
    "\n",
    "# 겹치는 컬럼명을 바꿔줍니다.\n",
    "train_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']\n",
    "test_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN_TEST_SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "y = test_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "\n",
    "X.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']\n",
    "y.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나 사라진 유저를 채워주는 코드입니다.\n",
    "y = y.reindex(pd.RangeIndex(y.index.max() + 1)).ffill(0)[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 41), (14999, 41))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 73)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,\n",
    "               train_err_count,\n",
    "               train_fwver_count,\n",
    "               train_model_count,\n",
    "               train_qual_std,\n",
    "               train_qual_log,\n",
    "               train_errcode_23,\n",
    "               train_errcode_33,\n",
    "               train_errcode_34], axis=1).fillna(0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 73)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat([y,\n",
    "               test_err_count,\n",
    "               test_fwver_count,\n",
    "               test_model_count,\n",
    "               test_qual_std,\n",
    "               test_qual_log,\n",
    "               test_errcode_23,\n",
    "               test_errcode_33,\n",
    "               test_errcode_34], axis=1).fillna(0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 84), (14999, 84))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X, train_qual_counts], axis=1).fillna(0)\n",
    "y = pd.concat([y, test_qual_counts], axis=1).fillna(0)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비교 할 모델\n",
    "\n",
    "1. RFC\n",
    "2. LR\n",
    "3. CATC\n",
    "4. XGBC\n",
    "5. ~~LGBC~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_y = scaler.fit_transform(y)\n",
    "\n",
    "scaled_X = pd.DataFrame(scaled_X, columns=X.columns)\n",
    "scaled_y = pd.DataFrame(scaled_y, columns=y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_fold_train_pred(MODEL, train_x, train_y, N_SPLIT=5):\n",
    "    \n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    s_fold = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = MODEL.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "       \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier( random_state=42,\n",
    "                              n_jobs=10)\n",
    "\n",
    "lr = LogisticRegression(      random_state=42,\n",
    "                              n_jobs=10)\n",
    "\n",
    "catc = CatBoostClassifier(    learning_rate=0.027,\n",
    "                              random_state=42,\n",
    "                              verbose=0)\n",
    "\n",
    "xgbc = XGBClassifier(         learning_rate=0.027,\n",
    "                              random_state=42,\n",
    "                              n_jobs=10)\n",
    "\n",
    "svc = SVC(                    random_state=42,\n",
    "                              probability=True,\n",
    "                              verbose=0)\n",
    "\n",
    "lgbc = LGBMClassifier(        random_state=42,\n",
    "                              learning_rate=0.027,\n",
    "                              verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7239000000000001\n"
     ]
    }
   ],
   "source": [
    "rfc_models, rfc_auc_scores, _, _ = sk_fold_train_pred(rfc, X, train_b_p.target)\n",
    "print(np.mean(rfc_auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73055\n"
     ]
    }
   ],
   "source": [
    "catc_models, catc_auc_scores, _, _ = sk_fold_train_pred(catc, X, train_b_p.target)\n",
    "print(np.mean(catc_auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7194499999999999\n"
     ]
    }
   ],
   "source": [
    "xgbc_models, xgbc_auc_scores, _, _ = sk_fold_train_pred(xgbc, X, train_b_p.target)\n",
    "print(np.mean(xgbc_auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "0.7251\n"
     ]
    }
   ],
   "source": [
    "lgbc_models, lgbc_auc_scores, _, _ = sk_fold_train_pred(lgbc, X, train_b_p.target)\n",
    "print(np.mean(lgbc_auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6529\n"
     ]
    }
   ],
   "source": [
    "lr_models, lr_auc_scores, _, _ = sk_fold_train_pred(lr, scaled_X, train_b_p.target)\n",
    "print(np.mean(lr_auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6759999999999999\n"
     ]
    }
   ],
   "source": [
    "svc_models, svc_auc_scores, _, _ = sk_fold_train_pred(svc, scaled_X, train_b_p.target)\n",
    "print(np.mean(svc_auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_submission(models, MODEL_NAME, y):\n",
    "    \n",
    "    pred_y_list = []\n",
    "    for model in models:\n",
    "        pred_y = model.predict_proba(y)\n",
    "        pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "\n",
    "    submission.problem = np.mean(pred_y_list, axis = 0)\n",
    "    \n",
    "    submission.to_csv(r'C:\\Users\\Wyatt\\wyatt37/Comp/LG_edge_detect/king/submission/king_210126_0_{}_test.csv'.format(MODEL_NAME), index=False)\n",
    "    \n",
    "    print(submission.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  problem\n",
      "0    30000     0.91\n",
      "1    30001     0.20\n",
      "2    30002     0.50\n"
     ]
    }
   ],
   "source": [
    "predict_submission(rfc_models, 'rfc', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   problem\n",
      "0    30000  0.950933\n",
      "1    30001  0.218906\n",
      "2    30002  0.586400\n"
     ]
    }
   ],
   "source": [
    "predict_submission(catc_models, 'catb', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   problem\n",
      "0    30000  0.864862\n",
      "1    30001  0.254616\n",
      "2    30002  0.476300\n"
     ]
    }
   ],
   "source": [
    "predict_submission(xgbc_models, 'xgb', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   problem\n",
      "0    30000  0.826354\n",
      "1    30001  0.246112\n",
      "2    30002  0.517472\n"
     ]
    }
   ],
   "source": [
    "predict_submission(lgbc_models, 'lgbc', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   problem\n",
      "0    30000  0.990016\n",
      "1    30001  0.769678\n",
      "2    30002  0.849987\n"
     ]
    }
   ],
   "source": [
    "predict_submission(lr_models, 'lr', scaled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   problem\n",
      "0    30000  0.906503\n",
      "1    30001  0.872138\n",
      "2    30002  0.914127\n"
     ]
    }
   ],
   "source": [
    "predict_submission(svc_models, 'svc', scaled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
