{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 팀 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 노트북은 지금까지 했던 과정을 간략히 정리한 것입니다. 참고용으로 보시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 기록\n",
    "\n",
    "1. D-6\n",
    " - 파생 변수 생성 확인\n",
    "    1. errtype을 var로 생성 : 0.83068(기각)\n",
    "    2. errtype, errcode 유니크 개수: 0.83235(기각)\n",
    "    3. errtype 유니크 개수: 0.83261(기각)\n",
    "    \n",
    "\n",
    "2. D-5\n",
    " - 파생 변수 생성 확인\n",
    "    1. err, qual의 time을 second으로 하고 std 로 groupby : 0.83490(상승)\n",
    "    2. 혜인이가 추천한 중요도 높은 errcode 추가: 0.83447(기각)\n",
    "    3. quality-groupby-sum: 0.83518(상승)\n",
    "\n",
    "3. D-4\n",
    " - 베스트 모델 확인\n",
    "\n",
    "4. D-3\n",
    " - 베스트 모델 확인\n",
    "\n",
    "5. D-2\n",
    " - 앙상블 제출\n",
    "\n",
    "6. D-1\n",
    " - 보류\n",
    "\n",
    "7. D-Day\n",
    " - 스태킹을 할 수도 있으니 마지막 날은 남겨 둠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_dtypes as ld\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, precision_recall_curve, recall_score, precision_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_P_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv'\n",
    "TRAIN_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv'\n",
    "TRAIN_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv'\n",
    "TEST_Q_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv'\n",
    "TEST_E_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv'\n",
    "SUBMISSION_PATH = r'C:\\Users\\Wyatt\\wyatt37/Data/systemError/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_problem_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/train_err_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_quality_data.csv\n",
      "C:\\Users\\Wyatt\\wyatt37/Data/systemError/test_err_data.csv\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = ld.load_dtypes(TRAIN_P_PATH)\n",
    "train_q = ld.load_dtypes(TRAIN_Q_PATH)\n",
    "train_e = ld.load_dtypes(TRAIN_E_PATH)\n",
    "test_q = ld.load_dtypes(TEST_Q_PATH)\n",
    "test_e = ld.load_dtypes(TEST_E_PATH)\n",
    "submission = pd.read_csv(SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5429, 2),\n",
       " (828624, 16),\n",
       " (16554663, 6),\n",
       " (747972, 16),\n",
       " (16532648, 6),\n",
       " (14999, 2))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape, train_q.shape, train_e.shape, test_q.shape, test_e.shape, submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_problem(df, object_='binary'):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    train_problem 테이블을 받아서 target 값으로 변환\n",
    "    1. {0, 1}의 binary로 변환\n",
    "    2. {0 ~ n}의 multiclass로 변환\n",
    "    \"\"\"\n",
    "    \n",
    "    # 10001부터 24999까지의 index를 만들어줍니다.\n",
    "    user_id_idx = np.array(range(10000, 25000, 1))\n",
    "    \n",
    "    # train_new_p라는 새로운 df를 만들고 index는 위에서 만든 user_id_idx 로 지정해줍니다.\n",
    "    new_p = pd.DataFrame(index = user_id_idx)\n",
    "    new_p['target'] = 0\n",
    "    \n",
    "    if object_ == 'binary':\n",
    "        new_p.iloc[df.user_id.unique()-10000] = 1\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    elif object_ == 'multi':\n",
    "        # multi는 count()로 집계를 해줍니다.\n",
    "        new_p['target'] = df.groupby('user_id')['time'].count()\n",
    "        new_p = new_p.fillna(0)\n",
    "        new_p = new_p.reset_index()\n",
    "        new_p.rename({'index':'user_id'}, axis=1, inplace=True)\n",
    "        \n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b_p = preprocessing_problem(train_p, 'binary')\n",
    "train_m_p = preprocessing_problem(train_p, 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_quality(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    EDA를 통해 알아낸 정보로 train_q, test_q를 정리해서 내뿜어줍니다.\n",
    "    1. qaulity_3, quality_4 를 drop 합니다.(단일 value)\n",
    "    2. qaulity_k 변수들을 정수로 encoding 합니다.\n",
    "    \"\"\"\n",
    "    # 먼저 3, 4번을 drop 합니다.\n",
    "    df.drop(['quality_3', 'quality_4'], axis=1, inplace=True)\n",
    "    \n",
    "    # qual 변수만 할당해주고, 정수로 형변환 해줍니다.\n",
    "    columns = train_q.columns[train_q.columns.str.contains('quality')]\n",
    "    # for문을 통해 각 column을 반복 작업해줍니다.\n",
    "    for col in columns:\n",
    "        try:\n",
    "            if df[col].dtype == 'float32': # 기존에 float은 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "            elif df[col].dtype == 'int8' or df[col].dtype == 'int16': # 기존에 int도 패스\n",
    "                df[col] = df[col].fillna(-2)\n",
    "                #print(col)\n",
    "            else:\n",
    "                df[col] = df[col].astype('object')\n",
    "                # nan값이 있으면 float으로 갈 수 없으니 '-2' 으로 채워줍니다.\n",
    "                df[col] = df[col].fillna('-2')\n",
    "                df[col] = df[col].apply(lambda x: x.replace(',' , ''))\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # fwver 에서 null 값이 꽤 있습니다. missing으로 채우겠습니다.\n",
    "    df.fwver = df.fwver.astype('object')\n",
    "    df.fwver = df.fwver.fillna('missing')\n",
    "    df.fwver = df.fwver.astype('category')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = preprocessing_quality(train_q)\n",
    "test_q = preprocessing_quality(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fwver(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    별건 아니고, e-set에 fwver 변수에서 '10' 이라는 값이 있는데, 이게 errtype이랑 겹쳐요.\n",
    "    그래서 10을 -> 8.5.2 으로 바꿔줄 겁니다.\n",
    "    굳이 이렇게 바꾸는 이유는, 해당 fw가 8.5.3버전과 같은 model_nm을 공유하기 때문입니다.\n",
    "    \"\"\"\n",
    "    df.fwver = df.fwver.replace('10', '8.5.2')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = preprocessing_fwver(train_e)\n",
    "test_e = preprocessing_fwver(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(df):\n",
    "    \"\"\"\n",
    "    definition:\n",
    "    'time' column이 str로 되어 있으니, datetime으로 바꿔주는 함수입니다.\n",
    "    다만 'time'양식이 pandas함수에 적용이 안되니, 강제로 슬라이싱해서 만들어줘야 합니다.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df['year'] = df['time'].apply(lambda x: str(x)[:4])\n",
    "    df['month'] = df['time'].apply(lambda x: str(x)[4:6])\n",
    "    df['day'] = df['time'].apply(lambda x: str(x)[6:8])\n",
    "    df['hour'] = df['time'].apply(lambda x: str(x)[8:10])\n",
    "    df['minute'] = '00' # minute을 넣어주지 않으면 datetime이 완성이 안되니, 00으로 넣어줍니다.\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df.year + df.month + df.day + df.hour + df.minute)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p = make_datetime(train_p)\n",
    "train_q = make_datetime(train_q)\n",
    "test_q = make_datetime(test_q)\n",
    "train_e = make_datetime(train_e)\n",
    "test_e = make_datetime(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 연산에서 왜 문제가 생기나 했더니 category로 되어 있어서였습니다.\n",
    "\n",
    "train_e['errtype'] = train_e.errtype.astype('object')\n",
    "test_e['errtype'] = test_e.errtype.astype('object')\n",
    "\n",
    "train_e['errcode'] = train_e.errcode.astype('object')\n",
    "test_e['errcode'] = test_e.errcode.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwver도 object로 잡아줍니다.\n",
    "\n",
    "train_q.fwver = train_q.fwver.astype('object')\n",
    "test_q.fwver = test_q.fwver.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from Error_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용한 model의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_count = train_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()\n",
    "test_model_count = test_e[['user_id', 'model_nm']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용한 fwver 의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fwver_count = train_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()\n",
    "test_fwver_count = test_e[['user_id', 'fwver']].drop_duplicates().groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경험한 error 의 총 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_count = train_e.groupby('user_id')['errcode'].count()\n",
    "test_err_count = test_e.groupby('user_id')['errcode'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경험한 각 errtype의 value별 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33호\n",
    "train_errcode_33 = train_e[train_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_33 = test_e[test_e.errtype == 33][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']\n",
    "test_errcode_33.columns = ['err_33_1', 'err_33_2', 'err_33_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23호\n",
    "train_errcode_23 = train_e[train_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_23 = test_e[test_e.errtype == 23][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']\n",
    "test_errcode_23.columns = ['UNKNOWN', 'ACTIVE', 'connLMP', 'connESTA', 'connTO', 'connLOCAL', 'STANDBY', 'TERMINATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34호\n",
    "train_errcode_34 = train_e[train_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "test_errcode_34 = test_e[test_e.errtype == 34][['user_id', 'errcode', 'hour']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "train_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']\n",
    "test_errcode_34.columns = ['err_34_1', 'err_34_2', 'err_34_3', 'err_34_4', 'err_34_5', 'err_34_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from Quality_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 quality의 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_std = train_q.groupby(['user_id']).std()\n",
    "test_qual_std = test_q.groupby(['user_id']).std()\n",
    "\n",
    "new_columns = ['q_std_0', 'q_std_1', 'q_std_2', 'q_std_5', 'q_std_6', 'q_std_7', 'q_std_8', 'q_std_9', 'q_std_10','q_std_11', 'q_std_12']\n",
    "\n",
    "train_qual_std.columns = new_columns\n",
    "test_qual_std.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기록한 quality log의 개수(12개당 1번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_log = train_q.groupby('user_id')['time'].count()/12\n",
    "test_qual_log = test_q.groupby('user_id')['time'].count()/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality당 순수 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값을 만들기 위해 새로운 df를 받아옵니다.\n",
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()\n",
    "\n",
    "# 0 값을 전부 nan 값으로 바꿔줍니다.\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] == 0, 'quality_{}'.format(i)] = np.nan\n",
    "\n",
    "# 필요없는 변수들을 버려줍니다.\n",
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "\n",
    "# 그룹바이 카운트 해줍니다.\n",
    "train_qual_counts = train_q_temp.groupby('user_id').count()\n",
    "test_qual_counts = test_q_temp.groupby('user_id').count()\n",
    "\n",
    "# 겹치는 컬럼명을 바꿔줍니다.\n",
    "train_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']\n",
    "test_qual_counts.columns = ['q_c_0', 'q_c_1', 'q_c_2', 'q_c_5', 'q_c_6',\n",
    "                             'q_c_7', 'q_c_8', 'q_c_9', 'q_c_10', 'q_c_11', 'q_c_12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality당 음수, 0에 대한 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 값만 count를 위해서 음수와 양수를 전부 nan으로 만들겠습니다.\n",
    "\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] < 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] < 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] > 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] > 0, 'quality_{}'.format(i)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_zeroCount = train_q_temp.groupby('user_id').count()\n",
    "test_qual_zeroCount = test_q_temp.groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['q_z_c_0', 'q_z_c_1', 'q_z_c_2', 'q_z_c_5', 'q_z_c_6', 'q_z_c_7', 'q_z_c_8', 'q_z_c_9', 'q_z_c_10','q_z_c_11', 'q_z_c_12']\n",
    "\n",
    "train_qual_zeroCount.columns = new_columns\n",
    "test_qual_zeroCount.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp = train_q.copy()\n",
    "test_q_temp = test_q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n",
    "test_q_temp.drop(['time', 'fwver', 'year', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음수 값만 count를 위해서 음수와 0을 전부 nan으로 만들겠습니다.\n",
    "\n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    train_q_temp.loc[train_q_temp['quality_{}'.format(i)] >= 0, 'quality_{}'.format(i)] = np.nan\n",
    "    \n",
    "for i in [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    test_q_temp.loc[test_q_temp['quality_{}'.format(i)] >= 0, 'quality_{}'.format(i)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_negaCount = train_q_temp.groupby('user_id').count()\n",
    "test_qual_negaCount = test_q_temp.groupby('user_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['q_n_c_0', 'q_n_c_1', 'q_n_c_2', 'q_n_c_5', 'q_n_c_6', 'q_n_c_7', 'q_n_c_8', 'q_n_c_9', 'q_n_c_10','q_n_c_11', 'q_n_c_12']\n",
    "\n",
    "train_qual_negaCount.columns = new_columns\n",
    "test_qual_negaCount.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time에 대한 유저별 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "def time_to_seconds(x):\n",
    "    return time.mktime(x.timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_e.time = train_e.time.apply(lambda x: time_to_seconds(x))\n",
    "test_e.time = test_e.time.apply(lambda x: time_to_seconds(x))\n",
    "train_q.time = train_q.time.apply(lambda x: time_to_seconds(x))\n",
    "test_q.time = test_q.time.apply(lambda x: time_to_seconds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 545 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_err_timestd = train_e.groupby(['user_id'])['time'].std()\n",
    "test_err_timestd = test_e.groupby(['user_id'])['time'].std()\n",
    "train_err_timestd = train_err_timestd.rename(level = 0, index = 't_e_std') \n",
    "test_err_timestd = test_err_timestd.rename(level = 0, index = 't_e_std') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qual_timestd = (train_q[['user_id', 'time']].drop_duplicates()).groupby(['user_id']).std()\n",
    "test_qual_timestd = (test_q[['user_id', 'time']].drop_duplicates()).groupby(['user_id']).std()\n",
    "train_qual_timestd.columns = ['t_q_std']\n",
    "test_qual_timestd.columns = ['t_q_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality를 sum으로 groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_each_quality_sum = train_q.groupby('user_id').sum().loc[:, 'quality_0':]\n",
    "test_each_quality_sum = test_q.groupby('user_id').sum().loc[:, 'quality_0':]\n",
    "\n",
    "quality_sum_colnms = ['quality_0_sum', 'quality_1_sum', 'quality_2_sum', 'quality_5_sum', 'quality_6_sum', \n",
    "                      'quality_7_sum', 'quality_8_sum', 'quality_9_sum','quality_10_sum', 'quality_11_sum', \n",
    "                      'quality_12_sum']\n",
    "\n",
    "train_each_quality_sum.columns = quality_sum_colnms\n",
    "test_each_quality_sum.columns = quality_sum_colnms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errtype을 유저별로 카운트 해줍니다.\n",
    "\n",
    "X = train_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "y = test_e.groupby(['user_id', 'errtype'])['errcode'].count().unstack().fillna(0)\n",
    "\n",
    "X.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']\n",
    "y.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    " 'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    " 'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    " 'et_39', 'et_40', 'et_41', 'et_42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나 사라진 유저를 채워주는 코드입니다.\n",
    "y = y.reindex(pd.RangeIndex(y.index.max() + 1)).ffill(0)[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 41), (14999, 41))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 106)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,\n",
    "               train_err_count, # 유저가 기록한 총 err수\n",
    "               train_fwver_count, # 유저가 사용한 fw수\n",
    "               train_model_count, # 유저가 사용한 model 수\n",
    "               train_qual_std, # 각 퀄리티에 대한 유저별 편차\n",
    "               train_qual_log, # 유저별 퀄리티 로그의 수\n",
    "               train_errcode_23, # 23호 에러타입의 밸류별 개수\n",
    "               train_errcode_33, # 33호 상동\n",
    "               train_errcode_34, # 34호 상동\n",
    "               train_qual_counts, # 각 퀄리티에서 0을 제외한 카운트\n",
    "               train_qual_negaCount, # 각 퀄리티에 대해 음수만 카운트\n",
    "               train_qual_zeroCount # 각 퀄리티에 대해 0.만 카운트\n",
    "              ], axis=1).fillna(0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 106)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat([y,\n",
    "               test_err_count,\n",
    "               test_fwver_count,\n",
    "               test_model_count,\n",
    "               test_qual_std,\n",
    "               test_qual_log,\n",
    "               test_errcode_23,\n",
    "               test_errcode_33,\n",
    "               test_errcode_34,\n",
    "               test_qual_counts,\n",
    "               test_qual_negaCount,\n",
    "               test_qual_zeroCount\n",
    "              ], axis=1).fillna(0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3차 합격생들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 119), (14999, 119))"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X, train_err_timestd, train_qual_timestd, train_each_quality_sum], axis=1).fillna(0)\n",
    "y = pd.concat([y, test_err_timestd, test_qual_timestd, test_each_quality_sum], axis=1).fillna(0)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3차 면접중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_temp.columns).difference(X_temp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def s_fold_train_pred(train_x, train_y):\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'boosting_type' : 'gbdt',\n",
    "                    'objective'     : 'binary',\n",
    "                    'metric'        : 'auc',\n",
    "                    'learning_rate' : 0.027,\n",
    "                    'seed': 42\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        d_train= lgb.Dataset(X, y)\n",
    "        d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "\n",
    "        #run traning\n",
    "        model = lgb.train(\n",
    "                            params,\n",
    "                            train_set       = d_train,\n",
    "                            num_boost_round = 10000,\n",
    "                            valid_sets      = d_val,\n",
    "                            feval           = f_pr_auc,\n",
    "                            verbose_eval    = 100, \n",
    "                            early_stopping_rounds = 100\n",
    "                           )\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13551\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.826428\tvalid_0's pr_auc: 0.747213\n",
      "[200]\tvalid_0's auc: 0.826504\tvalid_0's pr_auc: 0.74872\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's auc: 0.827018\tvalid_0's pr_auc: 0.748922\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13646\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.836547\tvalid_0's pr_auc: 0.780875\n",
      "[200]\tvalid_0's auc: 0.837776\tvalid_0's pr_auc: 0.782188\n",
      "[300]\tvalid_0's auc: 0.835811\tvalid_0's pr_auc: 0.782262\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.837837\tvalid_0's pr_auc: 0.782444\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13983\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.825725\tvalid_0's pr_auc: 0.749735\n",
      "[200]\tvalid_0's auc: 0.829299\tvalid_0's pr_auc: 0.753172\n",
      "[300]\tvalid_0's auc: 0.828318\tvalid_0's pr_auc: 0.752243\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's auc: 0.829453\tvalid_0's pr_auc: 0.753319\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13988\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.830888\tvalid_0's pr_auc: 0.7521\n",
      "[200]\tvalid_0's auc: 0.831584\tvalid_0's pr_auc: 0.754752\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.83146\tvalid_0's pr_auc: 0.756563\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13700\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.818549\tvalid_0's pr_auc: 0.7325\n",
      "[200]\tvalid_0's auc: 0.819637\tvalid_0's pr_auc: 0.74097\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.820055\tvalid_0's pr_auc: 0.739915\n",
      "==========================================================\n",
      "0.82916455\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15353\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.826194\tvalid_0's pr_auc: 0.747272\n",
      "[200]\tvalid_0's auc: 0.825833\tvalid_0's pr_auc: 0.747534\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.826596\tvalid_0's pr_auc: 0.748283\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15464\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.83714\tvalid_0's pr_auc: 0.78143\n",
      "[200]\tvalid_0's auc: 0.837932\tvalid_0's pr_auc: 0.783884\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's auc: 0.838168\tvalid_0's pr_auc: 0.784035\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15813\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.826239\tvalid_0's pr_auc: 0.75134\n",
      "[200]\tvalid_0's auc: 0.830028\tvalid_0's pr_auc: 0.753236\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's auc: 0.83016\tvalid_0's pr_auc: 0.754845\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15818\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.830035\tvalid_0's pr_auc: 0.748889\n",
      "[200]\tvalid_0's auc: 0.832094\tvalid_0's pr_auc: 0.756259\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's auc: 0.832219\tvalid_0's pr_auc: 0.757417\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15506\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.818216\tvalid_0's pr_auc: 0.729845\n",
      "[200]\tvalid_0's auc: 0.817782\tvalid_0's pr_auc: 0.73359\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.81927\tvalid_0's pr_auc: 0.732511\n",
      "==========================================================\n",
      "0.8292826\n"
     ]
    }
   ],
   "source": [
    "# 학습용\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X_temp, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base 0.8292073  0.8266209  0.82655950\n",
    "# ec   0.8296051  0.8269322  0.82608215\n",
    "# et   0.8291249  0.8269684  0.82844335\n",
    "# etc  0.8291123  0.8272698  0.82821499\n",
    "#          42         43        44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(y_temp)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.920044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.221513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.505086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.735106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.880764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.203552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.320443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.741580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.884766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.339916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.920044\n",
       "1        30001  0.221513\n",
       "2        30002  0.505086\n",
       "3        30003  0.735106\n",
       "4        30004  0.880764\n",
       "...        ...       ...\n",
       "14994    44994  0.203552\n",
       "14995    44995  0.320443\n",
       "14996    44996  0.741580\n",
       "14997    44997  0.884766\n",
       "14998    44998  0.339916\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'./submission/team_210129_3_qual-sum-added.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def catb_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'nan_mode': 'Min',\n",
    "                    'eval_metric': 'Logloss',\n",
    "                    'iterations': 1000,\n",
    "                    'sampling_frequency': 'PerTree',\n",
    "                    'leaf_estimation_method': 'Newton',\n",
    "                    'grow_policy': 'SymmetricTree',\n",
    "                    'penalties_coefficient': 1,\n",
    "                    'boosting_type': 'Plain',\n",
    "                    'model_shrink_mode': 'Constant',\n",
    "                    'feature_border_type': 'GreedyLogSum',\n",
    "                    #'bayesian_matrix_reg': 0.10000000149011612,\n",
    "                    'l2_leaf_reg': 3,\n",
    "                    'random_strength': 1,\n",
    "                    'rsm': 1,\n",
    "                    'boost_from_average': False,\n",
    "                    'model_size_reg': 0.5,\n",
    "                    'subsample': 0.800000011920929,\n",
    "                    'use_best_model': False,\n",
    "                    'class_names': [0, 1],\n",
    "                    'random_seed': 2584,\n",
    "                    'depth': 6,\n",
    "                    'posterior_sampling': False,\n",
    "                    'border_count': 254,\n",
    "                    'classes_count': 0,\n",
    "                    'auto_class_weights': 'None',\n",
    "                    'sparse_features_conflict_fraction': 0,\n",
    "                    'leaf_estimation_backtracking': 'AnyImprovement',\n",
    "                    'best_model_min_trees': 1,\n",
    "                    'model_shrink_rate': 0,\n",
    "                    'min_data_in_leaf': 1,\n",
    "                    'loss_function': 'Logloss',\n",
    "                    'learning_rate': 0.028116999194025993,\n",
    "                    'score_function': 'Cosine',\n",
    "                    'task_type': 'CPU',\n",
    "                    'leaf_estimation_iterations': 10,\n",
    "                    'bootstrap_type': 'MVS',\n",
    "                    'max_leaves': 64\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = CatBoostClassifier(**params, verbose=0)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13551\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.826428\tvalid_0's pr_auc: 0.747213\n",
      "[200]\tvalid_0's auc: 0.826504\tvalid_0's pr_auc: 0.74872\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's auc: 0.827018\tvalid_0's pr_auc: 0.748922\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13646\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.836547\tvalid_0's pr_auc: 0.780875\n",
      "[200]\tvalid_0's auc: 0.837776\tvalid_0's pr_auc: 0.782188\n",
      "[300]\tvalid_0's auc: 0.835811\tvalid_0's pr_auc: 0.782262\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.837837\tvalid_0's pr_auc: 0.782444\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13983\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.825725\tvalid_0's pr_auc: 0.749735\n",
      "[200]\tvalid_0's auc: 0.829299\tvalid_0's pr_auc: 0.753172\n",
      "[300]\tvalid_0's auc: 0.828318\tvalid_0's pr_auc: 0.752243\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's auc: 0.829453\tvalid_0's pr_auc: 0.753319\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13988\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.830888\tvalid_0's pr_auc: 0.7521\n",
      "[200]\tvalid_0's auc: 0.831584\tvalid_0's pr_auc: 0.754752\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.83146\tvalid_0's pr_auc: 0.756563\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13700\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.818549\tvalid_0's pr_auc: 0.7325\n",
      "[200]\tvalid_0's auc: 0.819637\tvalid_0's pr_auc: 0.74097\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.820055\tvalid_0's pr_auc: 0.739915\n",
      "==========================================================\n",
      "0.82916455\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n",
      "0.73065\n"
     ]
    }
   ],
   "source": [
    "# 학습용\n",
    "models, auc_scores, _, _ = catb_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.953445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.237317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.474520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.838170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.913806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.208481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.302758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.727264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.911754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.423947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.953445\n",
       "1        30001  0.237317\n",
       "2        30002  0.474520\n",
       "3        30003  0.838170\n",
       "4        30004  0.913806\n",
       "...        ...       ...\n",
       "14994    44994  0.208481\n",
       "14995    44995  0.302758\n",
       "14996    44996  0.727264\n",
       "14997    44997  0.911754\n",
       "14998    44998  0.423947\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'./submission/team_210130_2_pycaret-catb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "def s_fold_train_pred(train_x, train_y):\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'boosting_type':'gbdt', \n",
    "                    'class_weight':None,\n",
    "                    'colsample_bytree':1.0,\n",
    "                    'importance_type':'split',\n",
    "                    'learning_rate':0.1,\n",
    "                    'max_depth':-1,\n",
    "                    'min_child_samples':20,\n",
    "                    'min_child_weight':0.001,\n",
    "                    'min_split_gain':0.0,\n",
    "                    'n_estimators':100,\n",
    "                    'n_jobs':-1,\n",
    "                    'num_leaves':31,\n",
    "                    'objective':None,\n",
    "                    'random_state':2584,\n",
    "                    'reg_alpha':0.0,\n",
    "                    'reg_lambda':0.0,\n",
    "                    'silent':True,\n",
    "                    'subsample':1.0,\n",
    "                    'subsample_for_bin':200000,\n",
    "                    'subsample_freq':0\n",
    "                    }\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        #run traning\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n",
      "0.73245\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7402500000000001, 0.7475, 0.7285, 0.7285, 0.7175]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict_proba(y)\n",
    "    pred_y_list.append(pred_y[:, 1].reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.959609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.273480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.517156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.712508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.863260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.200855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.297753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.827408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.909884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.361192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.959609\n",
       "1        30001  0.273480\n",
       "2        30002  0.517156\n",
       "3        30003  0.712508\n",
       "4        30004  0.863260\n",
       "...        ...       ...\n",
       "14994    44994  0.200855\n",
       "14995    44995  0.297753\n",
       "14996    44996  0.827408\n",
       "14997    44997  0.909884\n",
       "14998    44998  0.361192\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv(r'./submission/team_210130_3_pycaret-lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_fold_train_pred(train_x, train_y):\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    # Train\n",
    "    models     = []\n",
    "    recalls    = []\n",
    "    precisions = []\n",
    "    auc_scores   = []\n",
    "    threshold = 0.5\n",
    "    # 파라미터 설정\n",
    "    params =      {\n",
    "                    'boosting_type'     : 'gbdt',\n",
    "                    'class_weight'      : 'None',\n",
    "                    'colsample_bytree'  : 1.0,\n",
    "                    'importance_type'   : 'split',\n",
    "                    'learning_rate'     : 0.1,\n",
    "                    #'seed'              : 42,\n",
    "                    'max_depth'         : -1,\n",
    "                    'min_child_samples' : 20,\n",
    "                    'min_child_weight'  : 0.001,\n",
    "                    'min_split_gain'    : 0.0,\n",
    "                    'n_estimators'      : 100,\n",
    "                    'n_jobs'            : -1,\n",
    "                    'num_leaves'        : 31,\n",
    "                    'metric'            : 'auc',\n",
    "                    'objective'         : 'binary',\n",
    "                    'random_state'      : 2584,\n",
    "                    'reg_alpha'         : 0.0,\n",
    "                    'reg_lambda'        : 0.0,\n",
    "                    'silent'            : 'True',\n",
    "                    'subsample'         : 1.0,\n",
    "                    'subsample_for_bin' : 200000,\n",
    "                    'subsample_freq'    : 0\n",
    "                    }\n",
    "#-----------------------------------------------------------------------------#\n",
    "# 5 Kfold cross validation\n",
    "    s_fold = StratifiedKFold(n_splits=5, shuffle=True ,random_state=42)    \n",
    "\n",
    "    for train_idx, val_idx in s_fold.split(train_x, train_y):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train_x.iloc[train_idx]\n",
    "        y = train_y.iloc[train_idx]\n",
    "        valid_x = train_x.iloc[val_idx]\n",
    "        valid_y = train_y.iloc[val_idx]\n",
    "\n",
    "        d_train= lgb.Dataset(X, y)\n",
    "        d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "\n",
    "        #run traning\n",
    "        model = lgb.train(\n",
    "                            params,\n",
    "                            train_set       = d_train,\n",
    "                            num_boost_round = 10000,\n",
    "                            valid_sets      = d_val,\n",
    "                            feval           = f_pr_auc,\n",
    "                            verbose_eval    = 100,\n",
    "                            early_stopping_rounds = 100\n",
    "                           )\n",
    "        \n",
    "        # cal valid prediction\n",
    "        valid_prob = model.predict(valid_x)\n",
    "        valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "\n",
    "        # cal scores\n",
    "        recall    = recall_score(    valid_y, valid_pred)\n",
    "        precision = precision_score( valid_y, valid_pred)\n",
    "        auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "        # append scores\n",
    "        models.append(model)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "        print('==========================================================')\n",
    "        \n",
    "    return models, auc_scores, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'boosting_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-331-b1ab6d93d395>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# loss 비교를 위해 지우지 않습니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 최고점 모델입니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_fold_train_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_b_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-330-49a982d9c07a>\u001b[0m in \u001b[0;36ms_fold_train_pred\u001b[1;34m(train_x, train_y)\u001b[0m\n\u001b[0;32m     56\u001b[0m                             \u001b[0mfeval\u001b[0m           \u001b[1;33m=\u001b[0m \u001b[0mf_pr_auc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                             \u001b[0mverbose_eval\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                             \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                            )\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'boosting_type'"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15353\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.821953\tvalid_0's pr_auc: 0.750276\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[29]\tvalid_0's auc: 0.825765\tvalid_0's pr_auc: 0.744852\n",
      "==========================================================\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15464\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.833879\tvalid_0's pr_auc: 0.77981\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[40]\tvalid_0's auc: 0.838027\tvalid_0's pr_auc: 0.782623\n",
      "==========================================================\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15813\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.827706\tvalid_0's pr_auc: 0.752402\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[79]\tvalid_0's auc: 0.829817\tvalid_0's pr_auc: 0.754811\n",
      "==========================================================\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15818\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.830829\tvalid_0's pr_auc: 0.753924\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.830829\tvalid_0's pr_auc: 0.753924\n",
      "==========================================================\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15506\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 114\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.814392\tvalid_0's pr_auc: 0.730555\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[40]\tvalid_0's auc: 0.817173\tvalid_0's pr_auc: 0.73253\n",
      "==========================================================\n",
      "0.8283221999999999\n"
     ]
    }
   ],
   "source": [
    "# loss 비교를 위해 지우지 않습니다.\n",
    "# 최고점 모델입니다.\n",
    "models, auc_scores, _, _ = s_fold_train_pred(X, train_b_p.target)\n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.82576475,\n",
       " 0.8380267499999999,\n",
       " 0.8298175,\n",
       " 0.8308292499999999,\n",
       " 0.8171727499999999]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(y)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.928173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.250156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.528290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.740373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.882834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.191757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.303551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.775778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.883276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.308180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.928173\n",
       "1        30001  0.250156\n",
       "2        30002  0.528290\n",
       "3        30003  0.740373\n",
       "4        30004  0.882834\n",
       "...        ...       ...\n",
       "14994    44994  0.191757\n",
       "14995    44995  0.303551\n",
       "14996    44996  0.775778\n",
       "14997    44997  0.883276\n",
       "14998    44998  0.308180\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.problem = pred_ensemble\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 창고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 형록이가 제안한 var 모델\n",
    "\n",
    "# X = pd.concat([train_e.user_id, pd.get_dummies(train_e.errtype)], axis=1).groupby('user_id').var().fillna(0)\n",
    "# y = pd.concat([test_e.user_id, pd.get_dummies(test_e.errtype)], axis=1).groupby('user_id').var().fillna(0)\n",
    "\n",
    "# X.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    "#  'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    "#  'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    "#  'et_39', 'et_40', 'et_41', 'et_42']\n",
    "# y.columns = ['et_1', 'et_2', 'et_3', 'et_4', 'et_5', 'et_6', 'et_7', 'et_8', 'et_9', 'et_10', 'et_11', 'et_12', 'et_13',\n",
    "#  'et_14', 'et_15', 'et_16', 'et_17', 'et_18', 'et_19', 'et_20', 'et_21', 'et_22', 'et_23', 'et_24', 'et_25',\n",
    "#  'et_26', 'et_27', 'et_28', 'et_30', 'et_31', 'et_32', 'et_33', 'et_34', 'et_35', 'et_36', 'et_37', 'et_38',\n",
    "#  'et_39', 'et_40', 'et_41', 'et_42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혜인이가 제안한 errcode\n",
    "\n",
    "# # 8호\n",
    "# train_ecode_14 = train_e[train_e.errtype == 14][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_14 = test_e[test_e.errtype == 14][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_14.columns = ['err_14_1', 'err_14_13','err_14_14']\n",
    "# test_ecode_14.columns =  ['err_14_1', 'err_14_13','err_14_14']\n",
    "\n",
    "# # 30호\n",
    "# train_ecode_30 = train_e[train_e.errtype == 30][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_30 = test_e[test_e.errtype == 30][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_30.columns = ['err_30_0','err_30_1','err_30_2', 'err_30_3','err_30_4']\n",
    "# test_ecode_30.columns =  ['err_30_0','err_30_1','err_30_2', 'err_30_3','err_30_4']\n",
    "\n",
    "# # 9호\n",
    "# train_ecode_9 = train_e[train_e.errtype == 9][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_9 = test_e[test_e.errtype == 9][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_9.columns = ['err_9_1','err_9_C-11020', 'err_9_C-12032','err_9_C-13039','err_9_C-14014',\n",
    "#                           'err_9_V-21002','err_9_V-21004','err_9_V-21005','err_9_V-21008']\n",
    "# test_ecode_9.columns = ['err_9_1','err_9_C-11020', 'err_9_C-12032','err_9_C-13039','err_9_C-14014',\n",
    "#                           'err_9_V-21002','err_9_V-21004','err_9_V-21005','err_9_V-21008']\n",
    "\n",
    "# # 37호\n",
    "# train_ecode_37 = train_e[train_e.errtype == 37][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_37 = test_e[test_e.errtype == 37][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_37.columns = ['err_37_1', 'err_37_2']\n",
    "# test_ecode_37.columns = ['err_37_1', 'err_37_2']\n",
    "\n",
    "\n",
    "# # 5호\n",
    "# train_ecode_5 = train_e[train_e.errtype == 5][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)[('time', 'E-59902')]\n",
    "# test_ecode_5 = test_e[test_e.errtype == 5][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)[('time', 'E-59902')]\n",
    "# #train_ecode_5.columns = ['err_5_E-59902']\n",
    "# #test_ecode_5.columns = ['err_5_E-59902']\n",
    "# train_ecode_5 = train_ecode_5.rename(level = 0, index = 'err_5_E-59902') \n",
    "# test_ecode_5 = test_ecode_5.rename(level = 0, index = 'err_5_E-59902') \n",
    "\n",
    "# # 31호\n",
    "# train_ecode_31 = train_e[train_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_31 = test_e[test_e.errtype == 31][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_31.columns = ['err_31_0', 'err_31_1']\n",
    "# test_ecode_31.columns =['err_31_0', 'err_31_1']\n",
    "\n",
    "# # 7호\n",
    "# train_ecode_7 = train_e[train_e.errtype == 7][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_7 = test_e[test_e.errtype == 7][['user_id', 'errcode', 'time']].\\\n",
    "#                             groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# train_ecode_7.columns = ['err_7_1', 'err_7_14']\n",
    "# test_ecode_7.columns =['err_7_1', 'err_7_14']\n",
    "\n",
    "# # 25호\n",
    "# train_ecode_25 = train_e[train_e.errtype == 25][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "# test_ecode_25 = test_e[test_e.errtype == 25][['user_id', 'errcode', 'time']].groupby(['user_id', 'errcode']).count().unstack().fillna(0)\n",
    "\n",
    "# train_ecode_25.columns =  ['err_25_1', 'err_25_2', 'err_25_L2CAP connection cancelled', 'err_25_UNKNOWN', \n",
    "#                             'err_25_connection fail to establish',\n",
    "#                              'err_25_connection timeout', 'err_25_connectionterminated by local host',\n",
    "#                             'err_25_scanning timeout', 'err_25_terminate by peer user']\n",
    "\n",
    "# test_ecode_25.columns = ['err_25_1', 'err_25_2', 'err_25_L2CAP connection cancelled', 'err_25_UNKNOWN', \n",
    "#                            'connection fail for LMP response timout',\n",
    "#                             'err_25_connection fail to establish',\n",
    "#                              'err_25_connection timeout', 'err_25_connectionterminated by local host',\n",
    "#                             'err_25_scanning timeout', 'err_25_terminate by peer user']\n",
    "\n",
    "# test_ecode_25.drop('connection fail for LMP response timout', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
